---
date: "15.04.2025"
generate_toc: true
subtitle: phd thesis work-in-progress
title: Evolution of social institutions from "animal conventions" with complex signaling
---

<!--# Introduction-->
<!--What is a convention? As @goodman1989 notes, this term is intricately ambiguous.-->
<!--Social conventions, the unwritten rules that govern our interactions, present a fundamental puzzle in understanding social order. How do shared patterns of behavior emerge and persist within a population when no explicit agreement dictates them? The term "convention" itself carries a dual meaning, referring both to the ordinary and expected, and to the artificial and optional, highlighting the complexity of this phenomenon 1. Philosophers have long been interested in conventions, recognizing their foundational role in various aspects of social life, including language, law, and morality 1.-->
<!--* [[@rescorla2019] ]-->

# **Chapter 1.** Social conventions: Hume, Lewis and game theory
The tradition of understanding social coordination as a source of social order is historically rich. Aristotle grounded social conventions in human nature and the pursuit of *eudaimonia*, or flourishing. He viewed humans as "political animals" who naturally form communities to achieve collective well-being. Justice and virtue, central to his ethics, were seen as the basis for political order. Unlike later followers of the social contract theory, Aristotle saw social organization as intrinsic to human rationality rather than a deliberate agreement [@aristotle1998].

Hobbes reimagined social conventions as constructs invoked by humanity’s violent "state of nature." He argued that self-preservation drives individuals to surrender freedoms to an absolute sovereign via a social contract resulting from explicit *agreement* [@hobbes2016]. Conventions thus arise from fear and rational self-interest, not innate sociability.

According to @epstein2018, a notion of *convention* was first explicitly used as an alternative to agreement by Pufendorf [-@pufendorf1673], to refer to language and law. He synthesized Hobbesian ideas with theological natural law. While agreeing that humans are self-interested, he attributed the "law of sociality" to divine mandate, requiring peaceful coexistence despite innate corruption. For Pufendorf, natural law obligates humans to form civil societies, with God as the ultimate author of social conventions. This introduced a moral dimension absent in Hobbes’s instrumentalist framework, suggesting that conventions are not merely utilitarian but also morally justified. His point was that conventions do not need to be explicitly agreed to and might exist and work without their intentional design. This intuition has remained largely  unchanged.

Hume’s theory of social conventions, articulated most prominently in *A Treatise of Human Nature* [@hume2003] and *An Enquiry Concerning the Principles of Morals* (1751), offers a groundbreaking empiricist account of how social norms and institutions emerge organically from human interaction rather than rational design or divine mandate. Hume’s analysis hinges on three core premises: 

- the role of custom in shaping behavior
- the centrality of mutual benefit in solving coordination problems
- the artificiality of conventions

These are seen as products of collective habit rather than explicit agreement. The components form the scaffolding of his theory, which bridges psychology, ethics, and political philosophy.

Hume’s empiricist framework posits that human understanding arises from sensory impressions and ideas derived from them. This extends to social behavior: conventions emerge not from reason but from repeated experiences that cultivate habits. For instance, Hume’s iconic example of two individuals rowing a boat illustrates how synchronization arises through trial and error, not prior negotiation:

> “Two men who pull at the oars of a boat, do it by an agreement or convention, tho’ they have never given promises to each other”[@hume2003]. 

However, @schliesser2024 stipulates that this kind of coordination is not backed by "Humean conventions" as they, according to Hume himself[^humean-conventions], require "positive social externality", whereas two burglars could effectively row away from a crime scene. We will not focus on this morally-driven notion of conventions.

[^humean-conventions]: As @hume1998 writes, "It has been asserted by some, that justice arises from human conventions, and proceeds from the voluntary choice, consent, or combination of mankind … if by convention be meant a sense of common interest; which sense each man feels in his own breast, which he remarks in his fellows, and which carries him, in concurrence with others, into a general plan or system of actions, which tends to public utility; it must be owned, that, in this sense, justice arises from human conventions. For if it be allowed (what is, indeed, evident) that the particular consequences of a particular act of justice may be hurtful to the public as well as to individuals; it follows, that every man, in embracing that virtue, must have an eye to the whole plan or system, and must expect the concurrence of his fellows in the same conduct and behaviour. Did all his views terminate in the consequences of each act of his own, his benevolence and humanity, as well as his self-love, might often prescribe to him measures of conduct very different from those, which are agreeable to the strict rules of right and justice …". @schliesser2024 notes that positive social externality is a requirement for a purely "Humean" convention.

Over time, repeating patterns solidify into conventions because they resolve practical problems (coordinating labor, establishing property rights) while minimizing friction. Custom, as Hume writes, “renders our experience useful to us” by creating stable expectations about others’ behavior, even in the absence of formal rules [@hume2003] . This emphasis on habit challenges rationalist theories like Hobbes’s by showing how conventions evolve *unconsciously* through iterative adjustments.

Hume highlights four key features of conventions:

- Mutual benefit: all parties gain from adhering to the convention (e.g., synchronized rowing ensures progress; standardized currency facilitates trade)
- Multiple potential solutions: different solutions could theoretically work (e.g., rowing fast or slow), but consistency matters more than the specific choice
- Unplanned agreement: conventions develop spontaneously through “a slow progression” of trial and error, not deliberate contract
- Reciprocity: adherence depends on the expectation that others will reciprocate, creating a self-reinforcing cycle of trust.

For Hume, conventions like property rights arise because humans recognize the “common interest” in stabilizing possessions to avoid conflict, even if their natural inclinations lean toward self-interest [@hume1998]. This pragmatic focus distinguishes his theory from moralistic accounts, framing conventions as tools for managing inherent human partiality.

Hume classifies conventions as *artificial virtues*, social constructs developed to counteract humanity’s “limited generosity”. Unlike natural virtues like benevolence, which arise instinctively, conventions like justice or promise-keeping require cultivation. Their artificiality, however, does not make them arbitrary. Instead, they gain normative force through collective sentiment: individuals approve of conventions that promote social utility, and disapproval of violations strengthens adherence over time. This process explains how conventions acquire moral weight, transforming into norms that feel binding even when rational self-interest might suggest defiance. Experimental studies inspired by Hume’s (or rather Lewis's [-@lewis2008]) work confirm that conventions stabilize behavior even when incentives to defect arise, underscoring the interplay of habit and normativity [@guala2010].

Hume’s theory diverges sharply from social contract models. While Hobbes root conventions in deliberate agreements to escape chaos or secure rights, Hume dismisses the notion of a primordial “state of nature” requiring such pacts. Instead, he argues that conventions emerge incrementally from lived experience, reflecting his broader skepticism toward rationalist abstractions. His framework also anticipates modern game theory, particularly David Lewis’s analysis of conventions as coordination equilibria [@lewis2008], though Hume places greater emphasis on psychology.  

Crucially, Hume’s account bridges descriptive and normative domains. By showing how conventions evolve from practical needs to moral norms, he offers a naturalistic explanation for social order that avoids appeals to divine law or metaphysical necessity. This aligns with his rejection of causation as anything beyond observed regularity, reinforcing his view that human institutions are contingent products of custom rather than eternal truths.

After Hume, philosophers in the Scottish Enlightenment held that social order is an emergent product of individuals' interactions, however, no such order has been specifically intended by individuals. As @ferguson1980 writes, “nations stumble on establishments which are, indeed, the result of human action, but not the execution of any human design”. Afterwards, however, the study of conventions has quieten. 

Lewis has revived and operationalized Hume’s insights into a theory of conventions using game theory and treating conventions as equilibria sustained by common knowledge and precedent. While Hume emphasizes historical contingency and gradual emergence, Lewis imposes stricter criteria of rationality and mutual expectations [@lewis2008]. He sees conventions as solutions to coordination problems, a class of problem in game theory, a branch of mathematics dealing with strategic behavior, which require two or more agents to align their actions to produce a jointly optimal outcome. In the next section, we will briefly tour game theory and its main concepts before getting back to Lewis's theory of conventions as game theory will be crucially important in the remainder of the thesis.

## Game theory background
Game theory is a mathematical framework used to analyze situations of strategic interaction between rational decision-makers. Originally developed by John von Neumann and Oskar Morgenstern in their seminal work *Theory of Games and Economic Behavior* [@morgenstern1944], game theory has since evolved to encompass a wide range of applications in economics, biology, political science, and sociology [@gintis2009; @osborne2004]. It provides the tools to study how individuals or groups make choices when their outcomes depend not only on their own decisions but also on the decisions of others. The fundamental building blocks of game theory are games, players, strategies, payoffs, and equilibria [@zamir2013].

A strategic game in game theory is defined as a formal model $G = (N, S, P)$ where:

- $N$ represents the set of players involved in the game
- $S = (S_1, S_2, \dots, S_n)$ denotes the strategy sets of each player, where $S_i$ is the set of strategies available to player $i$
- $P = (P_1, P_2, \dots, P_n)$ specifies the payoff functions, where $P_i: S_1 \times S_2 \times \dots S_n \rightarrow \mathbb{R}$ gives the utility for player $i$ given the chosen strategy profile [@myerson1991].

A strategy $s_i \in S_i$ is a complete plan of action a player will follow in any situation they might face within the game. Payoffs represent the rewards or utilities that players receive based on the combination of strategies chosen by all involved.

One of the central concepts in game theory is equilibrium, where no player has an incentive to unilaterally change their strategy given the strategies of others. The most well-known equilibrium concept is the Nash equilibrium (NE), introduced by John Nash in the early 1950s [@nash1950]. A strategy profile $(s_1^*, s_2^*, \dots, s_n^*)$ forms a Nash equilibrium if for every player $i$, the following condition holds:

$$
P_i(s_i^*, s_{-i}^*) \geq P_i(s_i, s_{-i}^*) \quad \forall s_i \in S_i.
$$

Here,

- $P_i$ represents the payoff function for player $i$
- $s_i^*$ denotes the strategy chosen by player $i$ at equilibrium
- $s_{-i}^*$ represents the combination of strategies chosen by all other players except player $i$
- The inequality states that player $i$ cannot increase their payoff by unilaterally changing their strategy from $s_i^*$ to any other available strategy $s_i$.

Shortly after Nash’s work, Robert Aumann introduced the concept of *correlated equilibrium* (CE) in 1974 [@aumann1974]. This generalization of Nash equilibrium allows players to coordinate their strategies through signals from a trusted mediator. Unlike Nash equilibrium, where players act independently, correlated equilibrium enables communication or correlation of strategies, capturing coordination through shared information. In a correlated equilibrium, a random signal suggests a strategy to each player, and players follow the recommendation if it is in their best interest to do so. Formally, a correlated equilibrium satisfies:

$$
\sum_{s'_{-i}} q(s_i, s'_{-i}) \cdot [P_i(s_i, s'_{-i}) - P_i(s'_i, s'_{-i})] \geq 0 \quad \forall s_i, s'_i.
$$

Here,

- $q(s_i, s'_{-i})$ represents the probability that the mediator recommends strategy $s_i$ to player $i$ and $s'_{-i}$ to the other players
- $P_i(s_i, s'_{-i})$ is the payoff to player $i$ when they play $s_i$ and the others play $s'_{-i}$
- The inequality ensures that the expected payoff from following the recommendation is at least as great as from deviating.

As Roger Myerson has reportedly observed, "If there is intelligent life on other planets, in a majority of them, they would have discovered correlated equilibrium before Nash equilibrium" [@solan1999]. Correlated equilibrium can be a more natural concept than Nash equilibrium, as its mathematical simplicity and reliance on cooperation make it easier to discover. He argued that humanity's prioritization of Nash equilibrium may have been an accident of history rather than a reflection of its fundamental importance. In societies or civilizations where cooperative behavior is emphasized or external mediators are prevalent, correlated equilibrium could emerge as a more intuitive starting point for understanding strategic interactions.

In the realm of evolutionary biology, John Maynard Smith introduced the concept of *evolutionarily stable strategy* (ESS) in 1973 [@maynard1973]. An ESS is a strategy $s^*$ that is robust against invasion by mutant strategies and satisfies the following condition:

$$
P(s^*, s^*) > P(s', s^*) \quad or \quad [P(s^*, s^*) = P(s', s^*) \quad and \quad P(s^*, s') > P(s', s')].
$$

Here,

- $P(s^*, s^*)$ is the payoff when both the incumbent and the invader use strategy $s^*$.
- $P(s', s^*)$ is the payoff when the invader uses strategy $s'$ while the incumbent sticks to $s^*$.

Beyond Nash, correlated, and ESS equilibria, game theory explores other equilibrium concepts, including subgame perfect equilibrium, trembling hand perfect equilibrium, and proper equilibrium, among others. These refinements address limitations of the NE, particularly in dynamic and extensive-form games. Notable equilibrium refinements include:

- *Subgame Perfect Equilibrium*: introduced by Selten [-@selten1965], it ensures rational behavior at every stage of a dynamic game by requiring equilibrium strategies in every subgame. It refines NE by eliminating non-credible threats and is particularly relevant in sequential games.

- *Trembling Hand Perfect Equilibrium*: proposed also by Selten [@selten1975], it accounts for the possibility of small, unintended mistakes (or trembles) by requiring that strategies remain optimal even if there is a slight probability of error. This refinement helps to eliminate equilibria that are not robust to slight deviations.

- *Proper Equilibrium*: introduced by Myerson [-@myerson1978], this concept strengthens trembling hand equilibrium by further penalizing less likely mistakes. It ensures that less probable errors are assigned proportionally smaller probabilities, reinforcing stability.

- *Sequential Equilibrium*: developed by Kreps and Wilson [@kreps1982], this refinement addresses the problem of imperfect information by combining strategies with beliefs about what has happened earlier in the game. It is particularly useful in signaling games and dynamic strategic interactions.

- *Perfect Bayesian Equilibrium*: extending the Bayesian framework, it requires that players update their beliefs consistently using Bayes’ rule and choose optimal strategies given their beliefs. It is widely applied in games with incomplete information [@fudenberg1991].

These equilibrium refinements aim to ensure stability and plausibility in strategic settings by accounting for dynamic aspects, imperfect information, and potential errors.

Coordination and cooperation problems are fundamental challenges in social philosophy since Hobbes [-@hobbes2016], and game theory has been an indispensable tool for tackling these problems due to its clarity and rigor.

- **Coordination problems** arise when individuals or groups need to choose between multiple possible equilibria, creating ambiguity about which solution will be selected. These problems are central to strategic interaction because they reflect situations where all parties would benefit from making compatible choices but may struggle to agree on a single option. 

- **Cooperation problems**, on the other hand, highlight the conflict between individual rationality and collective benefit, where mutual cooperation yields a better outcome for all, but self-interest may lead to suboptimal results. Such challenges often require mechanisms to facilitate coordination or encourage cooperation, including social conventions or equilibrium selection techniques. Consequently, equilibrium concepts are fundamentally linked to coordination and cooperation problems because they model how rational agents arrive at stable solutions given others' strategies.

Examples of coordination and cooperation problems include classic games like the Battle of the Sexes and the Prisoner's Dilemma. In the former, a husband and a wife coordinate on choosing a leisure activity where everyone is satisfied with the choice, and in the latter, two prisoners independently either defect or cooperate with each other by uncovering her partner in crime to an officer. The payoff matrices of these games are shown below[^payoff-matrix].

[^payoff-matrix]: A payoff matrix is a mathematical representation that shows the possible outcomes for each combination of strategies chosen by the players. Achieving coordination often requires stabilizing communication to arrive at mutual agreement, especially when different individuals or groups have conflicting preferences. This need for a reliable mechanism to resolve coordination issues is crucial in many social contexts.

$$
\begin{array}{|c|c|c|}
\hline
& Football & Ballet\\
\hline
Football & 2,1 & 0,0 \\
\hline
Ballet & 0,0 & 1,2 \\
\hline
\end{array}
$$

**Battle of the Sexes**

$$
\begin{array}{|c|c|c|}
\hline
& Cooperate & Defect \\
\hline
Cooperate & -1,-1 & -3,0 \\
\hline
Defect & 0,-3 & -2,-2 \\
\hline
\end{array}
$$

**Prisoner's Dilemma**

These matrices model real-world problems such as social dilemmas and negotiations. For instance, the Battle of the Sexes often represents situations where partners must choose between competing preferences, while the Prisoner's Dilemma models the challenge of mutual cooperation versus self-interest in scenarios like arms races or public goods provision.

To illustrate the practical difference of equilibrium concepts in solving coordination problems, let us consider the Battle of the Sexes with pure Nash, mixed Nash and correlated equilibria.

In pure Nash, two pure strategy equilibria exist: both players attend either Ballet or Football. These equilibria ensure perfect coordination but are inherently unfair, as one player always prefers the chosen event over the other. 

A mixed strategy Nash equilibrium also exists, where players randomize their choices independently, but it risks miscoordination. Let the Husband choose Ballet with probability $p$ and Football with $1-p$, and let the Wife choose Ballet with probability $q$ and Football with $1-q$. Using the *indifference principle* according to which a player randomizes her strategies in a way that the opponent is indifferent between their own available strategies, we calculate probabilities:

1. For the Husband to be indifferent, the Wife's mixed strategy must make his expected payoff from Ballet equal to that from Football:
   $$2q + 0(1-q) = 0q + 1(1-q) \implies 2q = 1 - q \implies q = \frac{1}{3}$$

2. For the Wife to be indifferent, the Husband's mixed strategy must make her expected payoff from Ballet equal to that from Football:
   $$1p + 0(1-p) = 0p + 2(1-p) \implies p = 2(1-p) \implies p = \frac{2}{3}$$

Thus, in the mixed strategy Nash equilibrium:

- The **Husband** chooses Ballet with probability $p = \frac{2}{3}$ and Football with $1-p = \frac{1}{3}$.
- The **Wife** chooses Ballet with probability $q = \frac{1}{3}$ and Football with $1-q = \frac{2}{3}$.

The expected payoffs for both players in this equilibrium are:

- **Husband**: $2q + 0(1-q) = 2\left(\frac{1}{3}\right) + 0 = \frac{2}{3}$,
- **Wife**: $1p + 0(1-p) = 1\left(\frac{2}{3}\right) + 0 = \frac{2}{3}$.

This mixed strategy equilibrium represents a compromise balancing fairness and coordination through randomization, albeit less efficient than pure Nash equilibria due to inherent miscoordination risks.

In contrast, correlated equilibria utilize external signals to coordinate actions effectively. For instance, a public signal such as a coin flip can recommend both players attend Ballet with 50% probability and Football with 50% probability. This mechanism eliminates miscoordination entirely and ensures equal expected payoffs for both players (1.5 each). Correlated equilibria can achieve higher payoffs and fairness compared to both pure and mixed Nash equilibria by leveraging shared randomness or communication.

To demonstrate how external signal affects the payoff structure, we add a new strategy **"Follow Signal (FS)"**, where players choose based on a fair coin flip (Heads = Ballet, Tails = Football). The payoffs depend on actual coordination, not just expectations: we can calculate expected payoffs when one player uses FS and the other does not.

**FS (H) vs. Ballet (W)**:  

  - Signal = Heads (50%): Both choose Ballet → $(2, 1)$.  
  - Signal = Tails (50%): H chooses Prize Fight, W stays at Ballet → $(0, 0)$.  
  - **Expected payoff**: $0.5 \times (2, 1) + 0.5 \times (0, 0)  =  (1, 0.5)$.  

**FS (H) vs. Football (W)**:

  - Signal = Heads (50%): H chooses Ballet, W stays at Prize Fight → $(0, 0)$.  
  - Signal = Tails (50%): Both choose Prize Fight → $(1, 2)$.  
  - **Expected payoff**: $0.5 \times (0, 0) + 0.5 \times (1, 2)  =  (0.5, 1)$.  

Thus, the augmented game matrix becomes:  

$$
\begin{array}{|c|c|c|c|}
\hline
 & Ballet (W) & Football (W) & FS (W) \\
\hline
Ballet (H) & (2, 1) & (0, 0) & (1, 0.5) \\
\hline
Football (H) & (0, 0) & (1, 2) & (0.5, 1) \\
\hline
FS (H) & (1, 0.5) & (0.5, 1) & (1.5, 1.5) \\
\hline
\end{array}
$$

The strategy profile of $(FS, FS)$ represents a Nash equilibrium because neither player has an incentive to deviate. If the Man switches to Ballet, he would only receive $1$, a decrease from his current payoff of $1.5$ when the Woman remains at $FS$. Similarly, if the Woman switches to Prize Fight, she would receive only $1$, a decrease from her current payoff of $1.5$ when the Man stays at $FS$. Since no profitable deviation exists for either player, the strategy profile **$(1.5, 1.5)$** is stable. Thus, the CE strategy is as an NE strategy of an augmented game. The difference is that CE are computationally simpler to compute than NE and model real-world scenarios where external signals (e.g., traffic lights) guide decisions. In summary, CE expand the solution space of a game, offering improvements over Nash equilibria when players can leverage a coordination device.

Getting back to coordination problems, @oconnor2019 distinguishes two classes of them:

* correlative problems (same choice to coordinate)
* complementary problems (different choices to coordinate)

In correlative coordination problems, agents need to converge on the same choice to coordinate successfully. For example, consider a driving game, where two players drive towards each other and each can choose the left or right side to drive on. If they both are on the same side and no one swerves, they might crash, and if each of them chooses a different side, they will stay safe. One important feature of this and other coordination problems is arbitrariness, meaning that it does not matter on what side both players would converge. Instead, what matters is that they either coordinate by choosing the same action, for example, swerving to the right. On the game matrix, it is represented as two non-unique equilibria. It means that either of them solves the coordination problem.

$$
\begin{array}{|c|c|c|}
\hline
& Swerve \quad left & Swerve \quad right \\
\hline
Swerve \quad left & 1,1 & -1,-1 \\
\hline
Swerve \quad right & -1,-1 & 1,1 \\
\hline
\end{array}
$$

Complementary coordination problems, as opposed to correlative ones, require from agents different actions, or strategies, to coordinate successfully. As @oconnor2019 points out, division of labor or resources is an example of this class of games. For instance, two roommates want to organize a party and invite guests. To proceed, they need to tidy up the house and order pizza delivery. If they both do the cleaning, there will be no food when the guests come, and if they both order pizza delivery, they will have plenty of food but be embarrassed by the mess at the house.

$$
\begin{array}{|c|c|c|}
\hline
& Order pizza & Tidy room \\
\hline
Order pizza & -1,-1 & 1,1 \\
\hline
Tidy room & 1,1 & -1,-1 \\
\hline
\end{array}
$$

The only difference between the two classes of coordination problems is either choosing same or different actions to coordinate successfully.

Coordination problems and conventions are intrinsically linked as former ones emerge when individuals or groups require aligned action for mutual benefit, necessitating communication and shared understanding to stabilize interactions. *Conventions function as a mechanism for predictable coordination by encapsulating mutual expectations*, thereby reducing ambiguity and establishing stable behavioral patterns within a social context. David Lewis’s theory of conventions as coordination equilibria, explored in the subsequent section, provides a central treatment of this relationship.

## Intellectual influences of Lewis's "Convention"
The intellectual atmosphere in which Lewis’s *Convention* was developed was mostly engaged with questions of language, meaning, and social behavior. Several intellectual movements and concerns shaped the development of his theory.

In the mid-20th century, the interest in influence of social practice on linguistic meaning kept growing, as philosophers like Quine [-@quine1960] and Wittgenstein [-0@wittgenstein] argued that meaning arises from shared use within a community. Wittgenstein highlighted that language's meaning emerges through public usage, rather than inherent semantic properties. For instance, "game" has no fixed definition but derives its meaning from the activities associated with it. Building on this tradition, Lewis sought to explain how linguistic conventions form, stabilize, and persist in communities by providing a systematic account of their development over time. By conceptualizing meaning as coordinated behavior, Lewis laid a foundation for viewing language as a socially orchestrated activity rather than an innate or purely individualistic construct. Consequently, communication relies not on objective meanings but on mutual expectations about usage, emphasizing convention's crucial role in language [@lewis1969].

The Zeitgeist of analytic philosophy in the 1960s grappled with the legacy of Logical Positivism, which, through formal logic and empirical verification, defined meaning based on analytically true statements or verifiable empirical claims [@godfrey-smith2003]. However, by the 1960s, critiques from Quine, Putnam, and others challenged this framework, particularly the distinction of analytic/synthetic truths, the former being true in virtue of their meaning and the latter in virtue of their relationship to the world. 

Quine rejected traditional notions of necessity and analyticity, asserting ontological commitments are embedded within theories and language [@quine1951; @quine1960; @quine1969], emphasizing empirical evidence and pragmatic considerations in shaping beliefs. His critique of analyticity underscored the revisability of language, highlighting conventions as mutable rather than fixed. Putnam’s “Twin Earth” thought experiment[^twin-earth] further developed these ideas, advocating semantic externalism—the view that word meaning depends on external facts, not solely on mental states—challenging internalist accounts of meaning and emphasizing the role of external factors in linguistic practices. Consequently, conventions are understood as influenced by contextual and environmental factors, moving beyond purely internal or necessary determinations.

[^twin-earth]: On a planet identical to Earth in almost all respects but featuring water composed of XYZ rather than H₂O, inhabitants use the term "water" yet refer to different substance. According to Putnam, this illustrates that psychological states alone do not determine meaning; external factors like chemical composition and environmental acquisition influence linguistic reference. His assertion is encapsulated by his famous statement: "meanings just ain't in the head."

Lewis’s theory of convention was a way to address this intellectual shift by emphasizing the contingent nature of meaning. Rather than being dictated by any necessity, conventions arise as arbitrary but stable solutions to coordination problems, reflecting a more pragmatic and flexible understanding of linguistic meaning and social practices. It highlights that even the most strict traditions started as flexible behavioral patterns which might have been otherwise but have been amplified more and more with each iteration. This perspective is deeply rooted in Quinean ideas about language as being subject to revision, adaptation, and negotiation within a community or culture.

Another major philosophical concern that Lewis addressed was the ontology of social rules and norms, profoundly influenced by Hume's work. Lewis developed Hume's idea of conventions emerging and persisting even in the absence of centralized enforcement. Lewis argued that conventions are self-reinforcing: once established, individuals have no reason to deviate as long as others continue to conform. The major deviation from Hume's thought was accent on rationality of agents as the source of such conformity, whereas Hume emphasized psychological custom. 

An example of this can be seen in the development of money as a medium of exchange. Initially, various objects—such as cattle, shells, or metal coins—served as currency. Over time, paper money became widely accepted, not because of any intrinsic value, but because people expected others to accept it in transactions. This insight was later influential in discussions of spontaneous order and decentralized systems in political philosophy and economics, particularly in the work of Hayek [@hayek1973]. By explaining conventions as natural outcomes of repeated social interactions, Lewis contributed to a broader understanding of how norms, institutions, and linguistic practices can arise organically without explicit design or coercion.

Furthermore, Hume’s skepticism about moral realism, a position stating that objective moral norms exist, played a role in shaping Lewis’s view of conventions as arbitrary yet stable[^alexander]. Hume argued that moral distinctions are not grounded in objective properties but in human sentiment and social conditioning. Similarly, Lewis contends that conventions are not determined by any intrinsic necessity but arise contingently through social practices. For instance, the choice of driving on the right or left side of the road is arbitrary, yet once established, it becomes self-reinforcing because all individuals benefit from adherence to the norm. This reflects Hume’s broader thesis that social order emerges not from absolute principles but from shared expectations and learned behaviors.

[^alexander]: The emergence of objective yet relative moral norms in accordance with Lewisian approach and rigor was developed by @mackenzie2007, which echoes "arbitrary yet stable" notion of instrumental conventions.

If the problems of meaning, language and conventionality served as the issue Lewis wanted to attack and Hume's notion of convention was resource to build upon, Lewis still needed a tool to construct his argument with. He found it in game theory [@vonneumann1944] and, in particular, in Schelling’s approach to strategic interaction in "mixed motive" games. [@schelling1980]. 

Game theory offered a structured mathematical framework for analyzing strategic interactions among individuals conceived as rational actors. Lewis's engagement with game theory and decision theory was facilitated by this prevailing intellectual trend. The emphasis on formal models and rational choice provided a common language and conceptual framework for discussing social behavior across diverse disciplines, making it a natural progression for a philosopher like Lewis to explore these powerful analytical tools in his own work.

Schelling’s work represented a significant departure from prevailing game theory’s emphasis on zero-sum conflict (when there is always a winner and a loser), recognizing that real-world interactions frequently exhibit “mixed motives” or simultaneous conflicting and converging interests. He critiqued the limitations of purely mathematical analysis of strategic interaction and advocated for empirical research to illuminate the conditions shaping behavior, specifically considering opportunities for communication and the presence of attractive alternatives. This expanded scope featuring both conflict and cooperation included the very phenomena of cooperation and coordination that drew Lewis's attention in the context of the problem of social conventions.

Schelling argued that conflict and cooperation are not necessarily opposing forces but are deeply intertwined in strategic interactions. One of his key contributions was the concept of *credible commitment*, where the ability to commit to a particular strategy in advance can influence an opponent’s decisions [@schelling1960, p. 22]. A fundamental aspect of this is *self-binding*, where a player deliberately restricts her own options to strengthen bargaining position.

Another crucial insight was the concept of *focal points* (also known as Schelling points), which are solutions that individuals naturally gravitate toward in coordination games without explicit communication. Schelling demonstrated this through experiments where participants, when asked to choose a meeting place in New York City without coordination, overwhelmingly selected noon at Grand Central Terminal, although it was a location with no inherent payoff advantage but high cultural prominence [@schelling1960, p. 57].

In the study of *pure coordination games*, Schelling examined interactions where players share interests but lack communication, such as selecting matching integers for a reward. Participants often converged on salient choices, such as the number 1, due to its distinctiveness as the smallest positive integer [@schelling1960, p. 102]. His work also refined the Nash equilibrium by demonstrating how focal points can help identify stable and salient outcomes among multiple NE [@lewis1969, p. 78]. Furthermore, for conflict scenarios, he introduced the concept of *"threats that leave something to chance"*, showing that probabilistic threats, such as partial mobilization, can deter adversaries more effectively than deterministic ones by leveraging uncertainty to maintain deterrence [@schelling1960, p. 187].

Lewis formalized Schelling’s insights into a theory of conventions, defining them as solutions to recurrent coordination problems where agents align on focal points due to mutual expectations [@lewis1969, p. 43]. Conventions rely on extrinsic incentives, such as avoiding coordination failure, rather than intrinsic obligations. Lewis also emphasized that communication itself is a coordination game, where signals, such as Paul Revere’s lanterns, derive Meaning from shared conventions [@lewis1969, p. 95].

One of the central ideas Lewis took from Schelling is the concept of focal point, or salience. He showed that social conventions arise as focal points for coordination. For instance, in many societies, people drive on one designated side of the road not because of an inherent preference for that side, but because universal adherence to a single convention ensures safety and predictability. Building on that idea, Lewis argues that agents select the most salient convention which “stands out” from alternatives, either through precedent, explicit agreement, or intrinsic properties. According to Lewis, salience, a subjective psychological trait independent of the strategic situation, governs convention emergence and conformity. Specifically, Lewis addresses how conventions arise (dynamics – through initial selection and subsequent salience amplification) and why people conform (statics – due to the overwhelming salience of a pre-existing convention, fostering an expectation of adherence). Subsequent refinements of Lewis's theory reimagine and formalize the notion of salience mostly through evolutionary lens [@oconnor2019; @oconnor2020, @skyrms2014; @gintis2007a].

Another crucial concept Lewis adopts from Schelling is the role of expectation and self-enforcement in strategic equilibrium. Schelling showed that in many coordination scenarios, once an equilibrium is established, deviation becomes irrational since the costs of uncoordinated action outweigh potential individual gains. Lewis builds on this by defining conventions as self-perpetuating: once a convention is in place, individuals follow it not because of external enforcement, but because mutual expectations make deviation costly. This is evident in linguistic conventions, where the use of certain words and grammatical structures persists because everyone expects others to conform to them.

Furthermore, Lewis’s notion of *common knowledge*, foundational to his theory of conventions, derives from Schelling’s emphasis on mutual awareness within strategic interaction which is tightly connected with salience. Though Schelling lacked formalization, he highlighted the crucial role of shared understanding for successful coordination. Lewis expanded upon this, asserting that convention stability necessitates not just adherence, but also recognition as the expected behavior within a group, thereby enabling convention maintenance across generations and large populations.

By drawing on Schelling’s work, Lewis was able to provide a game-theoretic foundation for the study of conventions, demonstrating how they emerge, stabilize, and persist over time. Whereas Schelling’s focus was on strategic choices in conflict and negotiation, Lewis extended these principles to the domain of language, social norms, and epistemic coordination, thus broadening the applicability of game-theoretic insights to philosophy and social science. As a result, Schelling’s *The Strategy of Conflict* remains one of the key intellectual influences behind Lewis’s *Convention* and its enduring impact on theories of social coordination.

## Lewis's theory of conventions
Lewis’s analysis focuses on coordination problems—strategic situations where agents share a common interest in a mutually acceptable outcome, which necessitates matching choices predicated on expectations of others. Such problems involve multiple equilibria achievable through identical or different actions (as in correlative and complementary game classes of @oconnor2019), which demand agents to act solely based on anticipated behavior of others and are characterized by interdependent decision-making between at least two agents with a prevailing coincidence of interest.

Conventions, according to Lewis, solve coordination problems via salient and mutually-beneficial strategic choice options. 

Lewis defines social conventions as an arbitrary yet self-sustaining behavioral pattern emerging from repeated coordination problems between two or more players. Its distinctive feature is players' conformity to these behavioral patterns, for they expect others to do so, and it is *common knowledge* that every player is expected to conform. Deviation from a conventional choice of action leads to lower payoff, so players do not have incentives to deviate unilaterally which is on their own. For example, if everyone drives on the right side of the road, it is rational for each driver to do the same to avoid collisions. Lewis [@lewis1969, p. 76] formulates convention as follows:

A behavioral regularity $R$ within a population $P$ in a repeated situation $S$ qualifies as a convention if and only if:

1. Every member of $P$ conforms to $R$.
2. Each individual expects others to conform to $R$.
3. All members have similar preferences regarding possible behavioral patterns.
4. Each person prefers universal conformity to $R$, provided that nearly everyone else adheres to it.
5. Members would also prefer an alternative regularity $R'$ under the same conditions, as long as $R'$ and $R$ are mutually exclusive.

Lewis later refines his analysis to accommodate occasional deviations from convention and @skyrms2023 even introduces *quasi-conventions* as unstable conventions based on yet another equilibrium concept of *coarse correlated equilibrium*. Despite this, much of the academic discourse focuses on the strict version of his definition.

Lewisian convention is a particular instance of NE (Nash equilibrium). In NE, no participant can improve their outcome by unilaterally changing their strategy. If deviation strictly reduces payoff, the equilibrium is considered strict. In this sense, NE represents a "steady state," where each individual acts optimally given the actions of others. However, Lewisian convention extends beyond NE by emphasizing collective preference for conformity, even when minor deviations occur. Such equilibria are referred to as *coordination equilibria*.

Lewis's framework highlights *arbitrariness* in conventions, where $R$ is defined as a convention only if an alternative $R'$ could serve equally well. This acknowledges that conventions are contingent choices among possible solutions rather than inherent necessities which continues the insights of Quine [@quine1969], Putnam [@putnam1975] and others.

Additionally, Lewis introduced the concept of *common knowledge* and made it a condition for a regularity to be a convention, where a fact $p$ is common knowledge if:

- Everyone knows $p$.
- Everyone knows that everyone knows $p$.
- Everyone knows that everyone knows that everyone knows $p$, and so on.

This recursive understanding of knowledge has spurred extensive discussion in both philosophical and game-theoretic literature. Aumann [@aumann1976] and Schiffer [@schiffer1972] have developed formalizations of common knowledge, diverging from Lewis’s original informal approach. 

As we will tour this and other aspects of Lewis's theory in detail later in this chapter, it suffices to mention that further reception of his theory saw the common knowledge requirement too cognitively demanding and unrealistic [@gilbert1992; @binmore2008; @camerer2003; @bicchieri2005; @vanderschraaf1998].

As Lewis's theory uses game theory, rationality plays a fundamental role in Lewis's framework. He assumes that agents are instrumentally rational, meaning they choose actions that maximize their expected utility given their beliefs and expectations about the world and the behavior of others. Although the entire metaphor of humans as maximizing agents has been questioned [@paternotte2020a], it still serves as guidance in economic theory [@gintis2007; @gintis2013], biology [@okasha2017; @okasha2012; @engel2008] and human ecology [@mouden2012a; @sterelny2012]. However, there are alternative views on the requirement of agent's rationality for conventions to exist. @millikan2022 suggests that conventions stabilize only by the weight of precedent, thus not requiring any rationality or consciousness. We will look closer at such alternative in the third chapter of the thesis while discussing complex signaling as a source of the transition from 'animal conventions' to human social institutions.

Lewis's notion of conventions weaves behavior, beliefs, preferences, and expectations into a framework of common knowledge and rationality to explain the stability of conventions. Each part of the definition is vital: common knowledge ensures a shared understanding of the convention, the preference for conformity incentivizes adherence given others' cooperation, and rationality guides individual choices within the context of shared expectations.

As a primary motivation for Lewis's analysis was to address the philosophical problem of linguistic meaning, he aimed to argue that language is grounded in conventions which do not require up-front agreement on terms. Just as drivers coordinate on a side to drive without a formal contract, speakers of a language develop conventions of using sounds or gestures to refer to specific things through repeated interaction and mutual expectations. Lewis viewed language as a system of signaling, where meaning arises from the conventional association between signals (words, phrases) and states of the world. For example, the word "cat" conventionally signals the presence of a feline. This convention is sustained because speakers generally intend to be truthful and listeners generally trust that they are being told the truth. This mutual expectation and reliance on the regularity of signal-meaning pairings allows for effective communication, which is a form of coordination.

This led Lewis to delineate *behavioral* and *signaling* conventions [@lewis2008, 147-150], where the former coordinate actions and the former coordinate meaning. As a prototypical example of a signaling convention, Lewis gives a story of Paul Revere and the lanterns hung in the steeple of the Old North Church used to warn colonial militia about approaching British Troops in 1775. Two hung lanterns conveyed that troops are advancing by sea, one—by land. Additionally, the actions of the receiver of the message, given each of these signals, would differ. In other words, senders and receivers of a message coordinate on following a pre-established pattern of "if X, do Y" like in the example with lanterns[^skyrms-learning].

[^skyrms-learning]: As Skyrms has shown [-@skyrms2010; -@skyrms2010a], the pattern can be learned dynamically in iterated games: both X and Y can be established and recognized with trial-and-error via reinforcement learning.

For Lewis, signaling conventions are a special case, or a subclass, of behavioral conventions as they share basic properties like arbitrariness, conformity and being common knowledge. Signaling conventions differ in that they involve communication and interpretation of meaning and solve coordination problems by *information transfer*. They require encoding/decoding which is producing and interpreting signals. 

An important feature of the relationship between these two classes of conventions is that, according to Lewis, signaling conventions fundamentally rely upon and are shaped by pre-existing behavioral conventions. For example, language meanings of words depend on both parties' adherence to established norms of pronunciation and grammar. Signaling systems frequently exhibit nesting, where specific conventions are embedded within larger behavioral regularities. For instance, raising one’s hand to speak during a meeting is a signaling conventions nested within a broader behavioral convention of turn-taking.

There is a formal distinction between behavioral, or "general" as Lewis call it, and signaling conventions. In signaling games, the players can be either senders or receivers, where the former owns private information about the world state and send a signal about it and the latter observes the signal and acts on it. More formally, it looks like the following:

1. **World states**: L (left) and R (right)
2. **Signals**: V₁ and V₂
3. **Actions**: Aᴸ (left action) and Aᴿ (right action)

| Role       | Strategy | Description                           |
|------------|----------|---------------------------------------|
| **Sender** | S₁       | Signal V₁ if L, V₂ if R               |
|            | S₂       | Signal V₂ if L, V₁ if R               |
| **Receiver** | R₁      | Choose Aᴸ if V₁, Aᴿ if V₂            |
|            | R₂       | Choose Aᴿ if V₁, Aᴸ if V₂            |

$$
\begin{array}{|c|c|c|}
\hline
 & R₁ & R₂ \\
\hline
S₁ & (1,1) & (0,0) \\
\hline
S₂ & (0,0) & (1,1) \\
\hline
\end{array}
$$

If a sender's signal representing a world state is correctly acted upon by receiver, both parties get the payoff of $(1, 1)$ and if either party fails to map ("encode" or "decode") information, they get $(0, 0)$. There is a plethora of possible options within this informational "layer" of signaling system extensively studied primarily by philosophers of biology [@skyrms2010a; @skyrms2010; @huttegger2008; @godfrey-smith1991; @shea2018a].

@godfrey-smith2014 refined Lewis's model by distinguishing *state-act* and *act-act* coordination, where in the former signals map states to receiver action and in the latter they synchronize action between agents without any external events. *Act-act* coordination allows to view Hume's boat rowers as an act-act signaling system: the rowers’ rhythmic strokes serve as imperative signals (“Row now!”) that directly coordinate mutual actions rather than conveying information about external conditions [@martinez2016]. The absence of an exogenous state reduces the system to a pure coordination game employing Nash or coordination equilibrium, where the “signal” (stroke rhythm) functions as a self-reinforcing convention stabilized by common interest and reciprocal expectations. Unlike state-dependent signaling of *state-act* coordination, which requires alignment between acts and external facts, *act-act* systems like the rowboat prioritize *interpersonal synchronization* through real-time behavioral feedback, illustrating how communication can organize joint action without representational content.

A paradigmatic real-world example of a *state-act* signaling system is alarm calls specific for each type of predator. For example, vervet monkeys have a call for for seeing eagles which conveys hiding in the grass and a call for seeing a snake conveying climbing on a tree [@seyfarth1990]. A perfect connection between a world state, signal and action comprises a signaling system. 

Although formally similar, as both behavioral and signaling conventions can be described as games with players and payoffs, they differ in that the latter have an additional "layer" of information between players. And although Lewis himself proclaimed signaling conventions a subcategory of behavioral ones, the relationship between them is not clear. For Skyrms, signals *inform* action, and signaling networks *coordinate* action, which implicitly conveys signaling conventions as underpinning behavioral ones. Skyrms further suggests that signaling is responsible for the evolution of teamwork itself [@skyrms2010], which questions Lewis's hierarchical categorization and creates a version of a chicken-and-egg problem. We will look closer at the relationship between behavioral and signaling  conventions and its role in emergence of social institutions in the third chapter.

## Criticisms and problems Lewis's theory generated 
Lewis's theory has been criticized on many grounds, and, as @rescorla2024 notes, virtually every component of his theory has been under attack: from imprecise notion of equilibrium concept to the very necessity of conventions for solving coordination problems. Many criticisms have been met in refinements and extensions of Lewis's theory by later scholars. 

There are five main areas of criticism of Lewis's account of conventions:

1. conformity requirement and hidden normativity
2. overestimation of arbitrariness
3. common knowledge requirement and source of salience
4. connection between conventions and coordination problems
5. imprecise equilibrium concept

We will survey 1-4 here as 5 is an extension rather than critique which we will address in the next section on refinements of Lewis's theory. Each subsection starts with immediate criticism of Lewis's theory and continues with a larger problem related to Lewis's theory this criticism points to.

### Hidden normativity of conventions
One of the major criticisms of Lewis's theory of conventions is unrealistic conformity requirement expressed of his 4-th clause: "each person prefers universal conformity to $R$, provided that nearly everyone else adheres to it". As some scholars points out, this strict requirement rules out such regularities as sending thank-you notes after dinner [@gilbert1992] as non-conventional, for they do not require complete conformity. Many commentators find this unintuitive as we usually call any mutually expected behavioral regularity a convention regardless of its level of conformity. 

However, a possible defense of Lewis's position is to restrict a social group where convention takes place and to add that "each person *within a certain social group* prefers universal conformity to $R$…". This addition addresses Gilbert's criticism in that it supports an idea of near-complete conformity relative to the scale and size of a social group with operative convention. If sending thank-you notes after a dinner within a certain group is indeed a convention, not writing such a note would at least disappoint a dinner host. Of course, this might not impose any external sanctions on a guest not writing a thank-you note. However, conformity relative to group size highlights inherent normativity in the form close to normative expectation, which @bicchieri2005 considers an essential ingredient of social norms rather than conventions.

As can be seen, a convention's level of conformity poses a deeper problem, that of normativity of conventions. The level of conformity helps distinguish between conventions as regularities *de facto* and *de jure*  [@rescorla2024], where the former describe actual behavior and the latter prescribe how individuals should behave in certain situations. Lewis himself anticipated such objections and claimed that conventions eventually become social norms. This claim later generated a major controversy over the relationship between those [@bicchieri2023]. Level of conformity points to a problem of the source of such conformity, which concerns Lewis's critics.

@gilbert1992 contends that Lewis’s account ignores the normative force of conventions. For Gilbert, the source of conformity of conventions is *joint commitments* that bind participants to collective ends, creating obligations to conform and justifying criticism of defectors. Lewis’s model, which reduces conventions to equilibrium strategies in coordination games, cannot explain why individuals feel *obliged* to comply with conventions (e.g., stopping at red lights) or apologize for breaching them. Gilbert also disputes Lewis’s focus on coordination problems, arguing that many conventions like etiquette rules lack clear coordination benefits and instead reflect shared commitments. In Lewis, there is appeal to instrumental rationality which maximizes expected value and avoids sanctions, but some scholars see this as insufficient to substantiate conventions. 

For instance, @guala2010 study the extent to which Lewis conventions are normative. He addresses both theoretical and empirical aspects and conclude that Lewis has put forward a scientific theory of conventions and not an analysis of the folk notion, and that conventions do indeed have intrinsic normativity beyond that of instrumental rationality. However, there is another strand of scholars that disagree and put forward that the only normativity of conventions is that of instrumental rationality [@gold2007; @bacharach1997].

In experimental settings, given an iterated Ultimatum or Prisoner dilemma game, only 29% of potential deviants in the lab choose to breach emergent convention [@guala2010]. As Guala and Mittone argue, players in these experiments may unintentionally create extra pressure to conform with their shared history of action, beyond the requirements of rational decision-making and social norms. However, the exact mechanism of additional normative expectation formation is to be discovered. 

From this, Guala concludes that Lewis' model provides an incomplete account of conventions' ontology. Data suggest that Lewis conventions acquire normative force through repeated play, and any future model must account for this. This has non-trivial implications for theory and practice, as it implies that habits and customs may be hard to disrupt. 

In a similar vein, @hindriks2019 claims that instrumental rationality cannot motivate adherence to conventions and norms and their perception as legitimate. Instrumental rationality with its costs and expected utilities fails to capture the motivation by the normative part of convention itself and not by the costs of its violation. Hindriks claims that it is *normative expectations* and *normative beliefs* that complement sanctions as a source for norm existence and perception as legitimate. 

In a broader context, the problem of normativity of Lewis conventions ignited a lively debate in philosophy regarding the relationship between conventions and social norms. They share a foundation in regularities and mutual expectations, but diverge in normative force, enforcement mechanisms, and social functions. Lewis’s model offers a minimalist, rationalist account of coordination, whereas social norms represent a richer, more complex landscape of social regulation, deeply shaped by values, sanctions, and cultural meanings. Thus, norms are seen as conventions whcich acquire enforcement capacity beyond pure coordination with repeated play.

@ullmann-margalit1977 gave on of the first game-theoretic conceptualizations of social norms. She argued that, as groups interact repeatedly, they develop expectations based on both obligation and the threat of social sanctions. These expectations go beyond simple conventions, relying on individuals’ internalized sense of duty and the potential for consequences like disapproval or ostracism. According to Ullmann-Margalit, this represents a move from coordinating behavior solely through rational self-interest to one where compliance is motivated by a deeply held conviction.

More precisely, Ullmann-Margalit emphasized normative authority as a mechanism of norm emergence, where theya rise as informal solutions to coordination, cooperation, and mixed-motive problems—situations characterized by divergent individual and collective interests. She conceptualizes a *history space* $\mathcal{H}$ as sequences of past interactions, where each history $h = [(a^1, s^1), (a^2, s^2), \dots, (a^t, s^t)]$ pairs joint action profiles $a^k\in A^n$ with observed sanction signals $s^k\in \{-1,0,1\}^n$ (negative, neutral, positive). A *normative choice function*

$$N:\mathcal{H} \to \Delta(A)$$

maps each history to a probability distribution over actions, reflecting both *strategic expectations* and *normative weights*.

Then, for any history $h$, an agent’s expected utility from choosing action $a$ is given by:

$$U(a\mid h) = u(a\mid h) + \beta\, I(a\mid h),$$

where:

- $u(a\mid h)$ is the material payoff based on beliefs about opponents’ strategies inferred from $h$.  
- $I(a\mid h)$ is the *internalized norm intensity*, capturing both social and psychological sanctions.  
- $\beta>0$ scales the importance of normative pressures relative to material gains.

Ullmann‑Margalit further suggests that norm intensity $I(a\mid h)$ evolves according to a *reinforcement learning* update:

$$I_{t+1}(a) = I_t(a) + \gamma\bigl(s_t(a) - I_t(a)\bigr),$$

where $s_t(a)$ is the average sanction observed when action $a$ was taken at time $t$, and $0<\gamma\le1$ is a sensitivity parameter. Over time, this embeds the *frequency and severity* of social approval or disapproval into agents’ preference structures.

A critical feature of Ullmann‑Margalit’s sketch is the *threshold effect*: once $\beta\,I(a\mid h)$ exceeds a context-dependent threshold $\theta$, normative considerations dominate, and agents will comply even against short-term material incentives. Formally, if

$$u(a'\mid h) - u(a^*\mid h) < \beta\bigl[I(a^*\mid h) - I(a'\mid h)\bigr] \quad\forall a'\ne a^*, $$

then $N(h)$ places all weight on $a^*$, the *normatively prescribed* action, regardless of smaller material gains from deviation.

This model suggests path-dependence as early interaction profiles and sanction signals can lock a community into a particular normative equilibrium, making norm shifts resistant to modest perturbations. In addition, in public goods or trust games, where $u(a)$ favors free‑riding, a sufficiently high $I(a)$ can sustain cooperation via internalized guilt and peer sanctions. @crawford1995 later modeled a similar situation of cooperation problems with $\delta$-parameters seen as additionally incurred costs in the form of potential sanctions, which, being sufficiently high, can transform a cooperation game into a coordination game effectively eliminating equilibria. Ullmann‑Margalit also acknowledges multiple channels like formal penalties, gossip and emotional costs that feed into $s_t(a)$, allowing norms to persist even when formal institutions are weak. Through these mechanisms, Ullmann‑Margalit transforms Lewis’s static, expectation-based model into a dynamic framework that accounts for the emergence, stability, and transformations of social norms with genuine normative force.


Jon Elster’s scholarship marries rational choice theory with psychological realism to explain how norms function as commitments within individuals’ strategic calculus. In works such as *The Cement of Society* (1989) and *Explaining Social Behavior* (2007), Elster introduces the notion of *self‑command*, wherein agents willingly bind themselves to future course of action—echoing the metaphor of Ulysses and the Sirens—to overcome short‑term temptations. He further refines the discussion by distinguishing between first‑order expectations (what I think you will do) and second‑order expectations (what I think you think I ought to do). While Lewisian conventions require only the former, sophisticated social norms depend on *second‑order normative expectations* that reinforce an agent’s sense of duty. Moreover, Elster analyzes how norms can resolve *mixed‑motive dilemmas* by aligning long‑term interests with communal standards, thus embedding normative force within a rational choice framework.

Jon Elster’s contributions integrate psychological realism into rational choice by modeling norms as strategic commitments and belief‑dependent preferences. His analysis unfolds in two interrelated strands:

1. Self‑Binding Commitments and Dynamic Choice.Elster models norm adherence as the outcome of a two‑stage game. Agents first choose a commitment set C (subset of full action set A) to maximize the worst‑case long‑run payoff:

V(C) = min_{a in C} U(a) - kappa * |C|

where U(a) represents long‑run utility and kappa>0 is the cost of restricting options. In the action stage, agents choose a* in C to maximize the immediate payoff u(a). This formalism captures how moral vows or binding contracts prune future options to enforce norm compliance.

2. Belief‑Dependent Preferences and Second‑Order Expectations.Elster formalizes utility that depends on both empirical expectations about others’ actions and normative expectations about what others think is appropriate. Let P(S) denote beliefs over opponents’ strategy profiles. Then:

U_emp(a) = E_{S~P}[u(a,S)]
U_norm(a) = E_{S~P}[Indicator(a is approved by others)]
U*(a) = U_emp(a) + lambda * U_norm(a) - c * D(a)

where lambda>0 weights normative approval, and D(a) is 1 if a deviates from the norm (0 otherwise), with c capturing sanction cost or psychological guilt. A normative equilibrium occurs when every agent's action maximizes U*(a), beliefs are correct, and normative expectations are self‑fulfilling.

Illustrative Example:In a trust game with actions C (cooperate) and D (defect), material payoffs satisfy u(D,C) > u(C,C) > u(D,D) > u(C,D). Let p = Prob(other cooperates) and q = Prob(other approves cooperation). Then:

U*(C) = p*u(C,C) + (1-p)*u(C,D) + lambda * q - c
U*(D) = p*u(D,C) + (1-p)*u(D,D)

Even if p is low, a sufficiently large (lambda*q - c) term can make cooperation strictly optimal. This illustrates how normative expectations and sanctions sustain cooperative norms beyond pure coordination.

Through these mechanisms, Elster bridges game‑theoretic precision with psychological realism, demonstrating how internal commitments and belief‑dependent utilities generate stable social norms.

***

Elinor Ostrom’s work on the governance of common‑pool resources (*Governing the Commons*, 1990) demonstrates how communities craft and sustain norms as part of a broader institutional ecology. Observing diverse case studies—from irrigation systems in Nepal to fisheries in Turkey—Ostrom identified design principles that underlie effective self‑organized governance. Among these are clear boundary definitions, collective choice arrangements, monitoring, graduated sanctions, and conflict‑resolution mechanisms. Unlike Lewis’s static model, Ostrom emphasizes the *evolutionary dynamics* of institutional development, where norms operate in concert with formal rules and organizational structures. In her view, norms endure not merely because of mutual expectation but because they are embedded in an adaptive system of shared understanding, enforcement, and local stewardship. This situates norms as *informal institutions* integral to sustaining cooperation in resource management and beyond.

Jon Elster: Rational Choice, Self‑Binding, and Second‑Order Expectations


Joshua Epstein and Agent‑Based Models of Norm Formation

The computational turn in social science, represented by Joshua M. Epstein and Robert Axtell’s *Growing Artificial Societies* (1996), offers a dynamic perspective on how conventions and norms evolve from the bottom up. Through agent‑based models—so‑called Sugarscape simulations—heterogeneous agents endowed with simple behavioral rules interact over time. Epstein’s experiments reveal that both global conventions (uniform behaviors across the population) and localized norms (behaviors contingent on neighbor interactions) can emerge spontaneously, without centralized coordination. These models underscore the roles of *path dependence* and *network topology* in determining which patterns solidify. By operationalizing Lewisian coordination in silico, Epstein bridges abstract theory and empirical complexity, illustrating that the interplay of agent diversity, stochasticity, and adaptive learning can give rise to durable social regularities with normative overtones.

Peyton Young: Evolutionary Stability and Norm Cascades

Peyton Young has contributed significantly to our understanding of convention and norm adoption through *stochastic evolutionary game theory*. In *Individual Strategy and Social Structure* (1998) and subsequent articles, Young introduces the concept of *stochastically stable states*—equilibria that persist under small random perturbations in agents’ behavior. While Lewisian conventions represent equilibria in coordination games, Young shows how these equilibria can shift when the underlying payoff structures are altered by social sanctions, transforming conventions into *institutionalized norms*. His work on *norm cascades* describes how once normative expectations and sanctioning thresholds cross a critical mass, societies can rapidly tip from one equilibrium to another. Thus, evolutionary dynamics and minimal levels of enforcement suffice to stabilize or overturn established conventions.

Cristina Bicchieri: Expectations, Conditional Preferences, and Sanctions

Cristina Bicchieri’s *The Grammar of Society* (2006) provides a rigorous formalism distinguishing conventions from norms based on *conditional preferences*. According to Bicchieri, individuals follow a rule if (a) they expect sufficiently many others to follow it (empirical expectation) and (b) they believe sufficiently many others think they ought to follow it (normative expectation). In Lewis’s conventions, only empirical expectations matter; normative expectations and potential sanctions are absent. By contrast, true norms depend on both layers of expectation and are upheld through social sanctions—whether external (punishments) or internal (guilt). Bicchieri’s framework highlights that modifying agents’ beliefs about others’ attitudes—through information campaigns or framing—can transform a convention into a norm, offering actionable insights for policy and institutional design.

Herbert Gintis: Strong Reciprocity and Cultural Group Selection

Herbert Gintis extends the analysis of norms by appealing to *strong reciprocity* and *cultural evolution*. In *Game Theory Evolving* (2000) and *Individuality and Entanglement* (2011), Gintis argues that humans possess an innate proclivity to punish norm violators at personal cost, even in one-shot anonymous interactions. This disposition, coupled with *cultural group selection*, explains how cooperative norms proliferate: groups adhering to strong reciprocal norms outcompete less cohesive groups. Gintis embeds Lewisian coordination games within a broader evolutionary narrative, where cultural transmission and selection pressures endow conventions with moral and sanctioning dimensions that transcend individual strategic calculation.

Conclusion

The dialogue between Lewisian conventions and social norms reflects a trajectory from **descriptive equilibria** towards **normatively rich institutions**. While Lewisian theory captures the elegance of coordination through common knowledge, the subsequent scholarship—spanning Ullmann‑Margalit’s norm genesis, Ostrom’s institutional ecologies, Elster’s self‑binding rationality, Epstein’s simulation models, Young’s evolutionary stability, Bicchieri’s conditional preferences, and Gintis’s cultural evolution—reveals the layered complexity of societal regulation. Together, these perspectives elucidate how conventions can acquire prescriptive force, how norms are institutionalized and enforced, and how the interplay of rational choice, psychology, and evolutionary dynamics shapes the fabric of social life.

***

The constructs of **social norms** and **conventions** serve to explain how individuals coordinate their behavior and maintain cooperation within societies. David Lewis’s game-theoretic model of **conventions** provides a baseline descriptive framework: conventions are equilibria of coordination games supported by common knowledge. However, subsequent scholarship has introduced additional layers of **normative force**, **sanctioning**, and **institutional structure**. Many theorists have employed formal tools—game theory, evolutionary dynamics, agent-based modeling, and decision-theoretic formalisms—to rigorously characterize these phenomena. This essay revisits the relationship between Lewisian conventions and social norms, integrating formal definitions and equations where used by Edna Ullmann‑Margalit, Elinor Ostrom, Jon Elster, Joshua Epstein, Peyton Young, Cristina Bicchieri, and Herbert Gintis.

David Lewis and the Logic of Convention

In *Convention: A Philosophical Study* (1969), Lewis formalizes conventions as **Nash equilibria** in symmetric coordination games. Let $G = (I, S, u)$ be a game with players $i\in I$, identical strategy sets $S_i = S$, and payoff function $u_i(s_i,s_{-i}) = u(s_i,s_{-i})$. A strategy profile $s^* = (s^*,\dots,s^*)$ is a convention if for every $i$:

$$u(s^*,s^*) \ge u(s',s^*) \quad \forall s' \in S, $$
and (common knowledge) each player expects others to play $s^*$. Lewis emphasizes the role of **common knowledge** of the game structure and mutual rationality, but he refrains from attributing any moral obligation to $s^*$—it is a purely descriptive equilibrium.

Ullmann‑Margalit and the Emergence of Normative Force

Edna Ullmann‑Margalit’s *The Emergence of Norms* (1977) does not present a fully axiomatized model, but she sketches a **normative choice function** $N: \mathcal{H} \to A$ mapping histories $h \in \mathcal{H}$ of repeated interactions to actions $A$, such that:

1. If $h$ exhibits repeated coordination outcomes, $N(h)$ coincides with the Lewisian equilibrium strategy.
2. When $h$ involves mixed-motive dilemmas, $N(h)$ maximizes a **utility function** $U(a\,|\,h) = u(a\,|\,h) + \beta I(a,h)$, where $u$ represents material payoffs and $I$ an *internalized norm* component weighted by $
obreak\beta>0$.

Her emphasis on **felt obligation** and **social sanctions** corresponds to endogenizing $I(a,h)$: deviations from the expected pattern incur negative disutility (guilt) or external penalties.

Elinor Ostrom: Institutional Principles without Equations

While Ostrom’s *Governing the Commons* (1990) is primarily empirical, she identifies **design principles** that can be formalized in repeated-public-good games. For instance, one can define a protocol $P$ with strategies $s_i^{(t)}$ updated via:

$$s_i^{(t+1)} = \begin{cases} s_i^{(t)} & \text{if payoffs and sanctions under } P \text{ keep expected utility above threshold},\\ s_i^{(t)}' & \text{otherwise}, \end{cases}$$

where graduated sanctions are functions $\sigma_i(s_i^{(t)},g)$ depending on individual’s action and group monitoring signals $g$. Though Ostrom does not specify these equations, her principles imply such an iterative adjustment process.

Jon Elster: Self‑Binding and Second‑Order Expectations

Elster introduces a two-stage model where an agent chooses a **commitment device** before playing a game. Formally, let $C \subseteq A$ be a set of permissible actions after commitment. The agent solves:

1. **Commitment stage**: choose $C$ to maximize $V(C) = \min_{a\in C} U(a)$
2. **Action stage**: pick $a\in C$ to maximize $u(a)$

Here, $U(a)$ reflects long-run utility, while $u(a)$ captures immediate payoff. Norms arise when agents choose $C$ to exclude self-harming deviations. He also distinguishes **first-order expectations** $E_1[s_{-i}]$ and **second-order expectations** $E_2[\text{ought}(s_{-i})]$, requiring norms be supported by both.

Joshua Epstein: Agent‑Based Simulation Rules

In *Growing Artificial Societies* (1996), Epstein and Axtell define a discrete-time agent-based model on a lattice. Agents follow rule sets:

1. **Move**: to neighboring cell maximizing resource $R$. 
2. **Metabolize**: consume $m$ units. 
3. **Trade**: exchange surplus according to price $p$. 
4. **Reproduce**: if $E > E_0$. 

Though not conventional game-theoretic equations, these **algorithmic formalisms** produce emergent conventions (uniform trading prices) and localized norms (spatial clustering of behavior) through repeated iteration.

Peyton Young: Stochastic Stability

Young’s stochastic evolutionary model formalizes conventions as **stochastically stable states** of a perturbed Markov process. Let $X^\epsilon_t$ be a finite-state Markov chain over population configurations, where with probability $1-\epsilon$ agents best-respond, and with $\epsilon$ make random mistakes. A state $x$ is stochastically stable if:

$$\lim_{\epsilon\to0} \mu_\epsilon(x) > 0,$$

where $\mu_\epsilon$ is the chain’s stationary distribution. Introducing sanction-based payoffs alters the best-response rule, tipping conventions into normative equilibria when punishment changes payoff matrices.

Cristina Bicchieri: Conditional Preference Logic

Bicchieri’s formalism specifies that an individual follows a rule $r$ in context $C$ if both:

1. **Empirical expectation**: $EE(r,C) = P(\text{others follow }r\,|\,C) \ge p^*$
2. **Normative expectation**: $NE(r,C) = P(\text{others think one should follow }r\,|\,C) \ge n^*$

with thresholds $p^*,n^*\in(0,1)$. This conditional preference model distinguishes conventions ($NE$ irrelevant) from norms ($NE$ binding).

Herbert Gintis: Strong Reciprocity Games

Gintis formulates **strong reciprocity** using modified public-goods games. For players $i,j$, action contributes $c$ to a public pool and can punish defectors at personal cost $k$. Payoffs:

$$\pi_i = b\cdot \frac{\sum_j a_j}{N} - a_i - k \sum_{j\in D_i},$$

where $a_j$ is j’s contribution and $D_i$ those punished by $i$. Strong reciprocity equilibria arise when punishment cost $k$ is offset by group-level benefits $b$, embedding norms in the payoff structure.

Conclusion

Across these frameworks, formal tools elucidate how **descriptive equilibria** (Lewisian conventions) transform into **prescriptive norms** through the introduction of internalized utilities, sanction structures, evolutionary perturbations, and expectation thresholds. By tracing these mathematical and computational formalisms, we gain a deeper understanding of the mechanisms sustaining coordination and cooperation in human societies.

***
 @young1998 showed how investigated the emergence of social norms and conventions via stochastic evolution within populations of boundedly rational agents. His models depicted individuals learning and adapting strategies through limited information and simple learning rules, absent common knowledge of the game or other players’ intentions. Conventions arose as stochastically stable equilibria resulting from adaptive play, where agents adjusted strategies based on past interactions and occasional random experimentation, leading to the selection of specific conventions. This analysis suggested that perceived common knowledge often associated with established institutions stemmed from the long-run stability of these equilibria, rather than a prerequisite for their formation or maintenance in a world characterized by bounded rationality. As conventions solidified through adaptive play, individuals developed expectations and reliance, fostering predictable social interactions despite lacking sophisticated reasoning about others’ knowledge states. Consequently, aggregate individual adaptive behavior, devoid of perfect rationality or complete information, could generate complex social structures and conventions mirroring rational strategic outcomes.

* how norms and conventions relate
* game-theoretic views on norms
    * [[⏳-Bicchieri-et-al.-2018|bicchieri et al. 2018]]
    * [[Conventions-acquire-additional-normativity-through-repeated-play]]
    * [[11.1a_Normative-rules-can-transform-cooperation-problem-into-coordination-problem-by-increasing-delta-parameter]]
    * [[11.2b_Norms-both-make-behaviour-more-stable-and-predictable-and-introduce-new-behaviour-by-changing-game-payoffs]]
    * [[Social-norm-conformity-is-due-not-only-to-costs-of-violation,-but-normative-expectations-and-beliefs]]
* [[10.1-equilibrium-emergence-can-be-at-cognitive-and-evolutionary-scales.md]]

***


### Overestimation of arbitrariness
Overestimation of arbitrariness is another area of criticism. According to Lewis, arbitrariness is one of the key distinguishing aspects of conventions. However, as @gilbert1992 points out, not all possible solutions to a coordination problem are equally profitable for players. In cases where one way of coordinating is more preferred than another, convention will not be that arbitrary. In other words, alternative conventions are logically justified, but pragmatically implausible as there is almost always a slight "preference" of one convention over the other due to different factors like historical accident and history of play. Later scholars talked about this in terms of symmetry-breaking by stochastic events [@skyrms2010; @skyrms2010a] and salience of conventions amplified by the history of iteratively playing a certain coordination game [@korbak2021a]. 

Arbitrariness was recast as a continuum between contingency and necessity, or conventionality and functionality [@oconnor2019]. Signaling between vervet monkeys might well be modeled as a convention in the Lewisian sense of repeated behavioral patterns of solving coordination problems [@harms2004; @skyrms2010]. However, this convention is not historically contingent in the sense of several possible solutions being equally profitable as Lewis supposes and as Gilbert critiques, for there are evolutionary constraints breaking the symmetry between multiple equilibria. Agents might be (and most probably are) hardwired to following certain strategies in certain environmental conditions. This distinction, as O'Connor underlines, highlights some conventions as more functional and others as more arbitrary. 

A similar line of criticism comes from @burge1975, who notes that Lewisian requirement for convention to involve mutual knowledge of *alternative regularities*, or practices that could replace existing ones if widely adopted, is too strict. Conventions might fix without agents' knowledge of alternatives, Burge argues. He contends that conventions can stabilize with habit, custom or tradition, widely following Hume's original argument, and that knowledge of alternative conventions is not needed. Conventions, as Burge argues, are not governed by any biological, psychological or sociological law, they are historically accident. In addition, agents do not necessarily deliberate to "switch" from one convention to another. In terms of game theory, Lewis requires that agents know the structure of the game with its multiple equilibria, whereas Burge's notion does not. This leads to yet another point of criticism, overly intellectualist requirements for agents.

* [[10.1a1c_Conventionality-can-be-measured-by-the-entropy-H(x)-of-a-convention.md]]

### Epistemic overreach of common knowledge requirement
Common knowledge denotes an epistemic state within a group wherein a proposition *p* is known by all members, and each member knows that every other member knows *p*, recursively extending to an infinite level of iterated knowledge. This recursive nature differentiates it from mere mutual knowledge, which necessitates only that each individual knows *p*. Consequently, common knowledge represents an idealized, stringent condition profoundly impacting coordination and strategic interaction, prompting investigation into its feasibility and real-world relevance.

As @cubitt2003 underline, Lewis’s initial conception of common knowledge did not imply unconstrained cognitive capacity of idealized agents. As they put forward, a proposition *p* is common knowledge if a state of affairs *A* exists where everyone has a reason to believe *A* holds, *A* indicates to everyone that everyone has a reason to believe *A* holds, and *A* indicates to everyone that *p*. This definition generates an infinite chain of “reasons to believe” rather than an infinite chain of “knowledge,” suggesting a more pragmatic approach towards achieving coordination. This approach acknowledges the limitations of human epistemic capabilities and focuses on the justification for beliefs about states of affairs and others’ beliefs about them rather than in absolute certainty on every level of iterated knowledge. Nevertheless, the majority of scholars interpret Lewisian conventions as computationally and cognitively demanding. 

@gilbert1992 criticized the infinite regress of Lewis's common knowledge. She challenged the psychologically implausible requirement of infinite levels of iterated knowledge, arguing it is unnecessary for explaining social phenomena like collective belief and convention. Gilbert proposed a framework centered on joint commitment, asserting that social facts emerge from situations where individuals are collectively committed to intend or believe something as a unified body, rather than through an infinite chain of individual beliefs about others’ beliefs. This joint commitment involves a shared intention or belief held by a group as a collective entity, irrespective of individual members’ personal convictions—for instance, a group’s shared commitment despite private doubts. This approach provides a means to understand shared social states and collective actions, generating shared obligations and expectations that drive behavior and shape attitudes, thereby avoiding the demanding epistemic requirements of common knowledge.

@bicchieri1993 argued that real-world agents operate under bounded rationality, which is more psychologically plausible. Individuals possess finite processing capacity and memory, which makes an infinite regress of knowledge untenable. Bicchieri investigated how agents form beliefs and expectations about others’ actions in coordination games, emphasizing mutual expectations and the potential for coordination through learning and repeated interactions, even without full common knowledge. She highlighted the role of *social norms*, proposing that they function through conditional preferences – individuals preferring to conform if they expect others to do so – and normative expectations, which are beliefs about what others believe one ought to do. This allows coordination to emerge and persist through observation, belief updating, and conformity, irrespective of the norm’s common knowledge status.

@heifetz1999 underscored the limitations of the common knowledge assumption in dynamic settings and games with temporal imprecision where communication is not instantaneous or unreliable. The coordinated attack problem when two parties agree to attack at the same time exemplifies how the absence of guaranteed, instantaneous communication can preclude the establishment of common knowledge, leading to suboptimal outcomes. Researchers have investigated alternative, weaker notions like finite levels of mutual knowledge or common belief to account for imperfections in real-world information and bounded rationality, offering potentially more accurate models of coordination and cooperation.

One of the more radical criticisms of the common knowledge requirement comes from evolutionary game theory, a branch of game theory pioneered by @maynardsmith1982 which assumes natural selection and evolutionary dynamics as a source of solutions for strategic games instead of rationality of self-interested actors with complete information. These criticisms doubt the necessity of common knowledge for conventions.

For example, @binmore2008 challenged the infinite levels of common knowledge posited by Lewis, arguing that agents only require first-order expectations regarding others’ behavior to converge on an equilibrium. This perspective emphasizes accurate prediction of actions as a critical element for coordination, with rational players responding accordingly. Binmore’s evolutionary approach highlighted cultural evolution’s role in shaping these common understandings and norms, suggesting societies develop and transmit effective coordination strategies over time based on promoting social stability – a dynamic process which refines coordination strategies rather than a static, pre-existing condition of full common knowledge. He also notes that Lewis's analysis of conventions confines its usage to small-scale societies as it implies observing public events being observed by another party. And this is not realistic in larger populations. Binmore suggests that conventions do not generally require common knowledge overall and can be established in evolutionary environments with only one level of reasoning instead of infinite hierarchy of beliefs. He also notes that everyday conventions mostly operate via automatic behavior and low-level mutual expectations. 

@guala2020 put forward a similar argument about "belief-less" coordination where most everyday conventions do not require iterated beliefs and hence cognitive capacities for meta-representation. Means-ends rationality and cheap heuristics are said to be sufficient.

### Connection between conventions and coordination problems
Some scholars argue that conventions are not necessary for solving coordination problems, undermining Lewis's theory. @sugden2005 and @vanderschraaf1998 argue that conventions need not necessarily be solutions for coordination problems—fashion or property conventions are not like this, for example[^coordination-fading]. Both of them have developed generalized accounts which do not require conventions to solve coordination problems. @davis2003, Marmor [-@marmor1996; -@marmor2009], @miller2001, Sugden [-@sugden1986; -@sugden2004] have argued that conventions need not be coordination equilibria.

[^coordination-fading]: However, seen dynamically, it can be argued the any convention came into being to solve a coordination problem, but after it have been established, it might have lost its initial coordinating function.  

@sugden2005 posits that conventions arise from behavioral patterns generating *mutual advantage*, independent of explicit coordination, thus rejecting Lewis’s focus on purely coordinating problems. Drawing on Hayek and Hume, he emphasizes spontaneous order of conventions which challenges the primacy of "constitutive" pre-establihed rules like law in governing social interactions. He argues that conventions emerge when patterns of behavior yield benefits *for all participants*, even in competitive or asymmetric situations. Unlike traditional game-theoretic models that focus on Nash equilibria, Sugden’s framework accommodates scenarios where *no clear equilibrium exists* which renders Lewis-style coordination problems too restrictive. 

Sugden introduces the concept of *team reasoning*, where individuals act on collective goals rather than individual incentives, akin to Gilbert’s joint commitment and collective intentionality but without endorsing a “plural subject” ontology. Fashion conventions emerge through independent adoption of trends perceived as advantageous for social signaling. This framework elucidates conventions in competitive scenarios lacking coordination equilibria, exemplified by property rights systems governed by historical precedent rather than coordinated agreement. 

As @davis2003 and @marmor2009 note, people follow trends for social distinction rather than coordination, yet these patterns become conventional through repeated adoption. 

@marmor2009 challenges Lewis’s emphasis on coordination problems, arguing instead for an analysis grounded in actual games like chess, distinct from the theoretical “games” favored by game theorists. His main argument is that there are deeper conventions like truth-telling which make Lewis-style coordination possible. He outlines three conditions for a rule to be considered conventional:

1. A population $P$ normally follows rule $R$ in circumstances $C$.
2. There is a reason $A$ for members of $P$ to follow $R$ in circumstances $C$.
3. There exists at least one alternative rule $S$, such that if members of $P$ had followed $S$ instead of $R$, $A$ would still have been a sufficient reason for following $S$, partly because $S$ was generally followed instead of $R$. Rules $R$ and $S$ are mutually exclusive in the given circumstances.

Marmor draws two distinctions: 

- coordination / constitutive conventions
- "deep" / "surface" conventions 

Coordination conventions solve Lewis-style problems like driving sides by aligning actions for mutual benefit, depend on shared expectations and mutual compliance. Constitutive conventions create social practices or classes thereof like chess rules which constitute the game of chess itself/ Marmor argues that constitutive conventions emerge as responses to complex social needs and are foundational to many practices, including legal systems. Unlike coordination conventions, they do not depend on mutual expectations but instead define the ontology of the practice. Deep conventions are foundational norms that underpin social practices and are less amenable to change. For example, truth-telling is a deep convention necessary for effective communication. In its turn, surface conventions are more specific instantiations of deep conventions and vary across contexts. For instance, particular linguistic rules like grammar are surface conventions based on deeper norms like truth-telling.

@millikan2005 presents a radically biological perspective on conventions, diverging significantly from economic and sociological approaches. Her core argument posits that a convention is fundamentally a behavior pattern sustained within a population through the mechanism of replicated precedent. Notably, Millikan rejects the prevailing tradition, exemplified by Hume and Lewis, which attributes social order to the rational decisions of individual agents. She explicitly denies any role for rationality in convention maintenance, asserting that a society upholding a convention solely through unreflective conformity would fulfill her definition. While Burgé similarly emphasizes factors beyond enlightened self-interest—including inertia, superstition, and ignorance—Millikan’s position is more extreme, entirely excluding any rational underpinning for convention stability.

For Millikan, conventions persist through replication adjusted according to the weight of precedent, where current patterns derive from prior instances. They are arbitrary and contingent as their stability is dictated neither by optimal design nor conformity of the majority. Instead, it influenced by its effective functional performance which might have been achieved with other patterns and does not require conscious adherence to rules. Millikan’s approach characterizes conventions as descriptive regularities which are emergent, stabilized patterns replicated through unconscious imitation, allowing for flexible adaptation without rigid definitions or universal agreement. For example, language speakers do not consciously follow a rule when calling a book a “book”,they simply replicate the behavior they have observed and linguistic conventions can be disobeyed without incurring sanctions, unlike rules in a normative sense. This contrasts with Lewis’s high-demanding view of mutual expectations, common knowledge and inherent normativity.

Millikan distinguished three types of coordination: 

- *blind coordination*, where participants act without knowledge of each other’s actions (e.g., traffic systems in Lewisian examples)
- *half-blind coordination*, where one party anticipates the other’s behavior based on precedent (e.g., linguistic communication)
- *open coordination*, where both parties fully anticipate each other’s actions.

Linguistic conventions predominantly fall into half-blind coordination. 

Millikan’s biological perspective frames conventions as analogous to evolutionary processes:

- Just as genes propagate based on their fitness, cultural conventions proliferate because they serve useful functions for individuals or groups.
- The “proper function” of a convention is its capacity to achieve specific outcomes (e.g., facilitating communication) effectively over time.

The notion of function will be important later as it is used in contemporary theories of social institutions as strategic equilibria [@guala2015] which try to smuggle biological functions and generate major controversy over the very notion and its relation to convention.

## Extensions and refinements
Lewis's theory of conventions became a starting point for formal research on conventions and later scholars refined his theory, sometimes to an unrecognizable extent. There are many refinements, but we will consider only most important for the topic of emergence of social institutions from animal conventions. In this section, we survey theories explicitly citing Lewis as a baseline. 

As I mentioned in the previous section, imprecise equilibrium concept was among the popular criticisms of Lewis's theory, and this component has been actively worked and elaborated on. Two notable reformulations of conventions are as *correlated equilibria* (CE) and *evolutionary stable strategies* (ESS). 

### Vanderschraaf's *inductive deliberation* as a source of salience
Vanderschraaf [-@vanderschraaf1995; -@vanderschraaf1998; -@vanderschraaf2001] redefined social conventions as CE through *inductive learning*, positioning conventions as foundational to achieving justice as mutual advantage. He formalized the notion of salience (or focal points) as information partitions and employed the *Dirichlet rule*[^dirichlet] to show how agents sequentially update their beliefs about others' strategies to gradually arrive at an equilibrium.

[^dirichlet]: The Dirichlet rule is a Bayesian updating procedure based on the Dirichlet distribution used for modeling probabilities over a finite set of discrete outcomes ("a distribution over distributions"). In learning models, the Dirichlet rule updates the probability assigned to each probability distribution by counting the number of times each of them has produced a particular outcome such as a reward. These counts serve as parameters of the Dirichlet distribution, which then yields a probability distribution over the options. Formally, if option $j$ has been rewarded $\gamma_j$ times, the updated probability for option $j$ is proportional to $\gamma_j$, and the probability vector $\mathbf{x} = (x_1, ..., x_k)$ over $k$ options is such that $x_j \in (0,1)$ and $\sum_{j=1}^k x_j = 1$. This rule captures how empirical frequencies shape probabilistic beliefs in a principled Bayesian manner. 

Lewis considered a coordination equilibrium a convention if the players have common knowledge of mutual expectations. Vanderschraaf calls this mutual expectation criterion (MEC). Each agent has a decisive reason to conform to her part of the convention, expecting the other agents to do likewise. Lewis stated that an equilibrium must be a coordination equilibrium to reflect the notion that a person conforming to a convention wants their intention to be seen as such. Vanderschraaf calls it the public intentions criterion (PIC). Furthermore, Lewis argues that common knowledge of the MEC is necessary for a convention. However, as Vanderschraaf notes, it is not sufficient, since common knowledge of the MEC can be satisfied at any strict Nash equilibrium.

According to Vanderschraaf, a convention constitutes a strategy profile $\sigma^* = (\sigma_1^*, \ldots, \sigma_n^*)$ where each agent $i$ maximizes expected utility such that $\mathbb{E}[u_i(\sigma_i^*, \sigma_{-i}^*)] \geq \mathbb{E}[u_i(\sigma_i', \sigma_{-i}^*)]$ for all alternative strategies $\sigma_i' \neq \sigma_i^*$, ensuring stability against unilateral deviations.

The formation of conventions operates not through cognitively expensive rational deliberation, but through relatively cheap *inductive learning* mechanisms. Agents employ *Dirichlet dynamics* to update beliefs about opponents' strategies. This updating process describes how agents repeatedly revise their beliefs by incorporating new observations of others’ behavior. A *deliberational equilibrium* is then defined as a fixed point of this learning dynamic, where agents’ beliefs stabilize. The stabilized joint beliefs and strategies that emerge from this iterative updating correspond to what Vanderschraaf calls *endogenous correlated equilibrium* (ECE)[^ece]: a CE arising internally from the agents’ inductive learning and mutual belief revision, rather than from an external correlation device as it is usually presented in broader game theory literature[^choreographer]. @kono2008 has mathematically proven how ECE is possible and that distributions of ECE and exogenous CE are completely different. The Dirichlet dynamics responsible for arriving at ECE is modeled as follows:

[^ece]: The distinction between "exogenous" and "endogenous" information influencing agent's strategy choice is already in @aumann1987. The former type of information is obtained from external cues and the latter from agents' reasoning about about how other agents reason. Aumann did not consider the distinction important, for the knowledge of exogeneity/endogeneity of agents' information or even actions does not contribute to achieving CE. Vanderchraaf's usage of Dirichlet dynamics clarified how endogeneity can contribute but did not eliminate the external signal altogether.

[^choreographer]: Many scholars use metaphors emphasizing the external character of CE: "mediator" and "correlation device" [@fudenberg1991], "choreographer" [@gintis2009a] and others. 

$$p_{t+1}(s_{-i}) = \frac{n_{s_{-i}} + \alpha_{s_{-i}}}{\sum_{s'_{-i}} (n_{s'_{-i}} + \alpha_{s'_{-i}})}$$

where $n_{s_{-i}}$ represents observed strategy profiles and $\alpha_{s_{-i}}$ denotes prior beliefs [@vanderschraaf2018]. Repeated interactions lead to path-dependent emergence of focal points, particularly in bargaining scenarios. Two prominent conventions arise: equal division of goods ($x_i = \frac{1}{n}$) and egalitarian payoff distributions satisfying $u_i(x_i) - u_i(d) = u_j(x_j) - u_j(d)$ for all agents $i,j$, where $d$ represents disagreement payoffs [@vanderschraaf1995].

An important part of Vanderschraaf's theory of conventions is his contribution to moral philosophy and theory of justice. He  grounded principles of justice in conventions that generate Pareto improvements[^pareto] over non-cooperative baselines. A just convention $\sigma^J$ must satisfy $u_i(\sigma^J) \geq u_i(\sigma^B)$ for all agents $i$, where $\sigma^B$ denotes the baseline equilibrium [@vanderschraaf2018]. 

This requirement addresses the vulnerability objection to justice theories which fail to adequately protect the most vulnerable persons. It does so by ensuring that conventions benefit even the least advantaged participants, creating mutual advantages that stabilize social arrangements. The framework reconciles Humean conventionalism with game theory, demonstrating how justice emerges from repeated coordination problems rather than abstract moral principles.

[^pareto]: Pareto efficiency describes a state where no further improvements are possible for well-being of any individual without simultaneously decreasing the well-being of at least one other individual.

<!--Vanderchraaf notes that conventions as CE allow for characterization of a wide range of equilibria. Given a game $\Gamma$ with pure strategy coordination equilibria $\mathbf{A}_1, \ldots, \mathbf{A}_m, m \geqslant 2$, and a lottery $\Omega$ with mutually exclusive outcomes $H_1, \ldots, H_m$ such that $p_k\left(H_j=\lambda_j\right)$ for each player $j$. Then if the players condition on $\mathscr{H}=\left\{H_1, \ldots, H_m\right\}$, and $f: \Omega \rightarrow S$ is defined by $f(\omega)=\mathbf{A}_j$ if $\omega \in H_j$, then inequality is satisfied for all $\omega \in \Omega$, making $f$ a convention. With infinitely many possible values for the $\lambda_j$'s, any noncooperative game with two or more pure strategy coordination equilibria has infinitely many correlated equilibria corresponding to conventions.-->

As can be seen, convention as CE allows for the “fair” coordination, even though no pure strategy equilibrium exists as we saw earlier with the “Battle of Sexes” game example. To reiterate, neither of the pure strategy Nash equilibria in this game is "fair", in the sense that the players receive the same payoff. 

This game has a mixed Nash equilibrium at which Husband plays $A1$ with probability $\frac 2 3$ and Wife plays $A2$ with probability $\frac 2 3$, and at this equilibrium each player's expected payoff is $\frac 2 3$, so this equilibrium is "fair". However, at the mixed Nash equilibrium, both players are indifferent to the strategies they play given what each player believes about her opponent, so this equilibrium fails the PIC and is consequently not a convention. Nevertheless, there is a correlated equilibrium fair to both players, and which each player will prefer over the pure strategy equilibrium that is unfair to her.

<!--\begin{table}[h]-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!--& $A1$ & $A2$ \\-->
<!--\hline-->
<!--$A1$ &$10, 7$ &$0, 0$\\-->
<!--\hline-->
<!--$A2$ &$0, 0$ &$7, 10$ \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{\small "Battle of sexes" game}-->
<!--\end{table}-->

This game has a mixed Nash equilibrium at which both agents play their strategies with probability $\frac 2 3$, yielding an expected payoff of $\frac 2 3$ for each agent. However, this equilibrium does not satisfy the PIC and is thus not a convention. Nevertheless, there is a correlated equilibrium that is fair to both players and preferable to the pure strategy equilibrium. With a toss of a fair coin, there is a probability space $\Omega = \{H, W\}$ with "heads" and "tails". The agents have a common information partition $\mathscr{H} = \{\{H\},\{W\}\}$ and the correlated strategy combination is denoted as a function $f: \Omega \rightarrow \{A 1, A 2\} \times \{A 1, A 2\}$ with $f(H) = (A 1, A 1)$ and $f(W) = (A 2, A 2)$. Husband has a higher expected payoff with this combination than any of the other strategies, so she will not deviate from it. The expected payoff for Husband is $2$ if the outcome is $H$, and $1$ if it is $W$.

$$
\begin{aligned}
& \left.E\left(u_1 \circ f \mid H\right)=2>0=E\left(u_1(A 2, A 1)\right) \mid H\right), \text { and } \\
& E\left(u_1 \circ f \mid W\right)=1>0=E\left(u_1(A 1, A 2) \mid W\right)
\end{aligned}
$$

The same holds for the second player. To this end, neither player would want to deviate, since the overall expected payoff at this equilibrium for each player is

$$
E\left(u_k \circ f\right)=\frac{1}{2} \cdot E\left(u_k \circ f \mid H\right)+\frac{1}{2} \cdot E\left(u_k \circ f \mid T\right)=\frac{3}{2}
$$

It means that each player prefers the expected payoff from $f$ to that of the mixed equilibrium.

For Vanderschraaf, a convention as a mapping of “states of the world” to strategy combinations of a noncooperative game [@vanderschraaf1995, 69]:

DEFINITION 1. A *game* $\Gamma$ is an ordered triple $(N, S, \mathbf{u})$ consisting of the following elements:

1. A finite set $N ={\{1,2, …, n\}}$, called the *set of players*;
2. For each player $k \in N$, there is a finite set $S_{k}= \{{A_{k_{1}}, A_{k_{2}},\dots, A_{kn_{k}}}\}$, called the *alternative pure strategies* for player $k$. The Cartesian product $S = S_{1} \times \dots \times S_n$ is called the *pure strategy set* for the game $\Gamma$;

3. A map $\mathbf{u}: S \rightarrow \mathbb{R}^n$, called the *payoff function* on the pure strategy set. At each strategy combination $\mathbf{A} = (A_{1j_1}, \dots, A_{nj_{n})}\in S$, player $k$’s payoff is given by the $k$th component of the value of $\mathbf{u}$, that is, player $k$’s payoff $u_k$, at $\mathbf{A}$ is determined by $$u_k(\mathbf{A}) = I_{k} \circ \mathbf{u} (A_{1j_1}, \dots, A_{nj_n}),$$

where $I_k(\mathbf{x})$ projects $\mathbf{x} \in \mathbb{R}^n$ onto its $k$th component.

As Vanderschraaf builds on Aumann's model [-@aumann1987], each player has a personal *information partition* $\mathscr{H}_k$ of a probability space $\Omega$. Elementary events on $\Omega$ are called *states of the world*. At each state $\omega$, each player $k$ knows which element $H_{kj}\in \mathscr{H}_k$ has occurred, but not which $\omega$. $H_kj$ represents $k$'s private information about the states of the world. While $k$ knows the opponent partitions, she does not know their content. A function $f: \Omega \rightarrow S$ defines a *exogenously correlated strategy $n$-tuple*, such that at each state of the world $\omega \in \Omega$, each player $k$ selects a strategy combination $f(\omega)=(f_1(\omega),\dots,f_n(\omega))\in S$ correlated with the state of the world $\omega$. Thus, by playing $f_k(\omega)$, $k$ follows *Bayesian rationality* and maximizes expected payoff given private information and expectations regarding opponents.

DEFINITION 2. Given $\Gamma = (N, S, \mathbf{u})$, $\Omega$, and the information partitions $\mathscr{H}$ of $\Omega$ as defined above, $f:\Omega \rightarrow S$ is a *correlated equilibrium* if and only if, for each $k \in N$,

1. $f_k$ is an $\mathscr{H}_k$-measurable function, that is, for each $H_{kj}\in \mathscr{H}_k$, $f_k(\omega)$ is constant for each $\omega' \in H_kj$, and

2. For each $\omega \in \Omega$, $$E(u_{k} \circ f|\mathscr{H}_k)(\omega) \geq E(u_{k} \circ (f_{-k}, g_k)|\mathscr{H}_k)(\omega)$$

where $E$ denotes expectation, '$-k$' refer to the result of excluding the $k$th component from an $n$-tuple. This holds for any $\mathscr{H}_k$-measurable function $g_{k}: \Omega \rightarrow S_k$. The correlated equilibrium $f$ is *strict* if and only if the inequalities are all strict.

The measurability restriction on $f_k$ means that $k$ knows her strategy in each $\omega$. This definition implies that players have common knowledge of the payoff structure, partitions of $\Omega$, and $f: \Omega \rightarrow S$, which is needed to compute expected payoffs and reach correlated equilibrium. In addition, if the players possess common knowledge of Bayesian rationality, they will follow their ends of $f$, expecting others to do the same, since they jointly maximize expected utility in this way.

The agents refer to a common information partition of the states of the world. While each agent $k$ has a private information partition $\mathscr{H}_{k}$ of $\Omega$, there is a partition of $\Omega$, namely the intersection $\mathscr{H}=\cap_{k \in N}\mathscr{H}k$, of the states of the world such that for each $\omega \in \Omega$, all the agents will know which cell $H(\omega) \in \mathscr{H}$ occurs. The agents' expected utilities in the following Definition 3 are conditional on their common partition $\mathscr{H}$, reflecting the intuition that conventions rely upon information that is public to all.

The agents' expected utilities are conditioned on their common information common partition $\mathscr{H}$ of the states of the world, which is the intersection of all their private partitions $\mathscr{H} = \cap_{k \in N}\mathscr{H}_k$. This reflects that conventions depend on information available to all agents.

DEFINITION 3. Given $\Gamma=(N, S, \mathbf{u}), \Omega$, and the partition $\mathscr{H}$ of $\Omega$ of events that are common knowledge among the players, a function $f: \Omega \rightarrow S$ is a convention if and only if for each $\omega \in \Omega$, and for each $k \in N, f_k$ is $\mathscr{H}$-measurable and

$$
E\left(u_k \circ f \mid \mathscr{H}\right)(\omega)>E\left(u_k \circ\left(f_{-j}, g_j\right) \mid \mathscr{H}\right)(\omega)
$$

for each $j \in N$ and for any $\mathscr{H}$-measurable function $g_j: \Omega \rightarrow S_j$.

It means that if any player $j$ deviates from a convention $f$, every player $k \in N$, including $j$, will be worse off. This definition of convention as a strict correlated equilibrium satisfies the PIC, as all agents are aware of the common partition and the strategies each player is expected to play. Thus, if any opponent mistakenly thinks that a player $k$ will play a strategy $g_k(\omega) \neq f_k(\omega)$ other than the one prescribed by $f$, they may be tempted to deviate, resulting in a worse-off outcome for $k$. Conversely, if all opponents are aware that $k$ will play her strategy $f_k(\omega)$ at each state of the world $\omega \in \Omega$, then they have a strong incentive to conform with convention $f(\omega)$, which gives $k$ an improved outcome.

Overall, Vanderschraaf's contribution is formalization of salience, hence he uses the *common* information partition $\mathscr{H}$ as a necessary restriction to make the definition of convention conform with Lewis' spirit. The other question is how salience itself emerges. Lewis suggests that pre-game communication, precedent, and environmental cues may lead agents to link their expectations and actions with various "states of the world", thus achieving correlated equilibrium. However, these sources of salience face the problem of infinite regress, for it is unclear how precedent or pre-game communication occurred in the first place without an established and shared conventional rules. Vanderschraaf, along with Skyrms [@vanderschraaf1993], proposes *inductive deliberation* as a mechanism by which salience is being established. It requires agents to be Bayesian rational and works by recursive belief modification. Players can reach a correlated equilibrium without communication by dynamically updating their beliefs using a common inductive rule, even if their beliefs don't initially allow for an equilibrium.

Another significant extension of Lewis's theory is related to redefining conventions as ESS and is due mostly to Skyrms.

### Skyrms's evolutionary approach to conventions
Skyrms integrated Lewis’s theory of conventions into an evolutionary framework. He showed how signaling conventions can emerge naturally with adaptive processes like evolution and learning in agents with limited cognitive sophistication which overcomes Lewis's reliance on common knowledge [@skyrms2010]. 

Although Skyrms has almost established an entire fruitful research program with many followers [@huttegger2007a; @huttegger2007; @oconnor2020; @lacroix2020; @franke2014] and we will take a closer look at his generalization of Lewis's signaling models later in this section, I suggest he would not have done it without his earlier and less-known contribution to game theory which has to do with generalization of the ESS solution concept.

The ESS, or evolutionary stable strategy, being a foundational solution concept in evolutionary game theory formulated by @smith1973 is a strategy that, if adopted by majority of population, cannot be invaded by any mutant strategy. Crucially, this concept implies random matching[^pairing], where individuals are paired for strategic interactions independently of their types, such that the probability of encountering any strategy is only proportional to its overall population frequency. While this assumption simplifies analysis and yields elegant theoretical results, it limits the applicability of ESS to well-mixed populations and fails to capture the complexity of structured or socially embedded interactions.

[^pairing]: Random matching is a standard assumption in evolutionary game theory where individuals in a large, well-mixed population are paired to interact purely by chance, meaning each individual is equally likely to meet any other, regardless of their strategy. This context is important because, under random matching, the ESS depends solely on the average payoffs determined by the overall population frequencies, and strategies like cooperation typically cannot persist unless they are directly favored by the payoff structure. Deviations from random matching (assortative or structured matching) can introduce correlations between strategies, fundamentally altering which behaviors can be evolutionarily stable [@jensen2018; @izquierdo2024]. 

Skyrms recognized that ESS does not generate stable strategies with non-random matching arising from mechanisms like kin selection, signaling systems, spatial or social structure. These correlations induce interactional dependencies increasing the probability of similar-strategy encounters. Such dependencies drastically alter the evolutionary dynamics and can stabilize strategies such as cooperation or signaling conventions that would be unstable or unsustainable under classical ESS assumptions [@skyrms1994].

This led Skyrms to establishing "adaptive ratifiable strategy" as a generalization ESS that incorporates the endogenous structure of interactions, making it a more realistic predictor of evolutionary outcomes. A strategy is adaptive-ratifiable if it maximizes expected fitness when it is nearly fixed in the population, taking into account the conditional probabilities of interacting with other strategies. This concept ensures dynamic stability under replicator dynamics[^replcator] where correlation affects interaction frequencies [@skyrms1994].

[^replcator]:

The notion of adaptive ratifiable strategy made another Skyrms's concept possible. That of "correlated convention" [@skyrms2014], which is conventions as stable yet not necessary Pareto optimal behavioral patterns made possible due to interactional dependencies of any kind between agents. Skyrms explored many possibilities for such correlation like spatial interaction [@alexander1999], social structure [@skyrms2003], social networks [@skyrms2004] and finally signaling systems [@skyrms2010a]. However, as we will see in the second chapter of the thesis, Skyrms's "correlation" is different from Vanferschraaf's.

Skyrms’s approach to conventions differs from Lewis’s in not relying on common knowledge and substituting it with evolutionary pressures which make conventions arise and persist. He showed that even simplest organisms like bacteria can arrive at signaling systems akin to Lewisian conventions with the aid of simple adaptive mechanisms like mutation-selection or reinforcement learning [@skyrms2014].

Skyrms explored various learning dynamics that enable signaling systems to emerge in populations. For example:

- *Simple Reinforcement Learning* where agents adjust their strategies based on trial-and-error feedback from successful interactions. In a basic Lewis-Skyrms signaling game setup with 2 world states, 2 signals and 2 actions, senders and receivers begin with random dispositions and gradually reinforce successful pairings between states, signals, and actions.

- *Win-Stay/Lose-Shift Dynamics* where agents establish conventions more rapidly than simple reinforcement learning. This dynamic involves sticking with successful strategies while shifting away from unsuccessful ones, enhancing convergence speed and stability.

Skyrms's framework models conventions as stable equilibria of sender-receiver games that evolve via reinforcement learning and evolutionary dynamics rather than rational deliberation. Formally, a signaling game involves:

- a set of states of the world $S = \{s_1, s_2, \ldots, s_n\}$
- a set of signals $M = \{m_1, m_2, \ldots, m_k\}$
- a set of acts $A = \{a_1, a_2, \ldots, a_l\}$. 

The sender observes a state $s \in S$and chooses a signal $m\in M$to send. The receiver, upon receiving $m$, chooses an action $a \in A$. The payoffs $u_S(s, m, a) $and $u_R(s, m, a)$ for sender and receiver respectively depend on how well the receiver’s action matches the state. Unlike Lewis’ model, which assumes common knowledge of salience to coordinate on a unique equilibrium, Skyrms shows that conventions can emerge through adaptive processes even when initial behaviors are random and no focal points exist.

A central concept in Skyrms’ analysis is the informational content of signals, which he quantifies using information-theoretic measures. Given a prior probability distribution over states $P(S_i)$ and a posterior distribution conditioned on a signal $ m $, denoted $ P(S_i \mid m) $, the information conveyed by $ m $ can be expressed as the vector of log-likelihood ratios:

$$
\left( \log_2 \frac{P(S_1 \mid m)}{P(S_1)}, \log_2 \frac{P(S_2 \mid m)}{P(S_2)}, \ldots, \log_2 \frac{P(S_n \mid m)}{P(S_n)} \right).
$$

where $P(S_i)$ represents prior probabilities of states and $P(S_i \mid m)$ denotes posterior probabilities conditioned on a signal $m$. This formalization bridges Lewis’s conceptual framework with mathematical models of communication.

This measure captures how a signal updates the receiver’s conditional strategy choice given the state of the world, thereby guiding action selection [@skyrms2010].

Skyrms further explores signaling equilibria under conditions of partial alignment or conflict of interests between sender and receiver. In such cases, the equilibrium strategies may involve deceptive or partially informative signals. Formally, if the sender’s payoff function $u_S$ differs from the receiver’s $u_R$, the equilibrium concept extends to signaling equilibria where strategies $\sigma_S: S \to \Delta(M)$ and $\sigma_R: M \to \Delta(A)$ satisfy mutual best responses:

$$
\sigma_S(s) \in \arg\max_{m \in M} \mathbb{E}_{a \sim \sigma_R(m)}[u_S(s, m, a)], \quad \sigma_R(m) \in \arg\max_{a \in A} \mathbb{E}_{s \sim P(\cdot \mid m)}[u_R(s, m, a)],
$$

where $\Delta(X)$ denotes the set of probability distributions over $X$ [@skyrms1996].

The evolutionary dynamics driving the emergence of conventions are often modeled through reinforcement learning algorithms such as the Roth-Erev model [@erev1998]. Agents maintain propensities $q_{i}(x)$ for choosing actions $x$ (signals or responses), which are updated iteratively according to received payoffs:

$$
q_{i}^{t+1}(x) = q_{i}^t(x) + \alpha \cdot \left( r_i^t(x) - q_i^t(x) \right),
$$

where $\alpha$ is a learning rate and $r_i^t(x)$ is the reward at time $t$ for action $x$ [@skyrms2010]. Over repeated interactions, these learning dynamics lead to convergence on stable signaling conventions without requiring explicit coordination or rational foresight.

Transmission of information in signals and emphasis on *informational content* of a signal ignited a lively response from philosophers of biology critiquing Skyrms for the lack of causation [@shea2018a; @godfrey-smith2020; @harms2004] which we will survey in Chapter 3. 

An interesting part of Skyrms's extension of Lewis signaling game is it's implicit reliance on epistemic language of "observing" states of of the world and "interpreting" signals for "updating beliefs". Although Skyrms utterly rejects any Bayesian interpretation of his signaling games [@lacroix2020a], he is sometimes interpreted as a incurring epistemology to his agents, especially when his theory is discussed side-by-side with natural theories of mental content [@millikan1987; @millikan2004; @baraghith2019; @harms2004]: that senders "represent" world states and transmit this public representation to a receiver who then "interprets" it with its own mental states. Consider vervet monkeys' alarm calls. They can easily be described as involving mental states of "representing" an eagle and sending a certain signal to fellows monkeys who "decode" that public representation and map it onto suitable action. While plausible and the case for most natural theories of mental content like @millikan2004, it is not the case for Skyrms. 

Although the structure of Lewis-Skyrms game mirrors the flow of information in epistemic contexts (state-signal-action pairings) and it is tempting to treat senders and receivers as Bayesian-rational, the Skyrmsian agents update their behavioral dispositions rather than beliefs as they do not possess any inference and can only adjust their mappings according to failure rates [@skyrms2012]. 

Skyrms's sender-receiver system is an *information channel* focusing on how effective codes (signal-meaning pairings) arise and stabilize, not on agents’ beliefs or intention. His signaling games are mechanistic as Maynard Smith's, for they take into account only objective, or "ontic", features of agents like strategy frequency across population or, in case of signaling game, *mappings* from state to signal and from signal to action in accordance to the rate of coordination failures. Compare Lewis-Skyrms game 

$$
\begin{array}{ccccc}
World & \xrightarrow{state} & Sender & \xrightarrow{Message} & Receiver & \xrightarrow{act} & {} \\
\end{array} \\
$$

with Shannon's information channel:

$$
\begin{array}{ccccc}
Source & \xrightarrow{original \quad message} & Encoder &\xrightarrow{signal} & Channel & \xrightarrow{signal} & Decoder & \xrightarrow{decoded \quad message} & {} \\
\end{array}
$$

As @martinez2019 proposes a "channel-first" view on signaling games and argues, the central behavioral unit of Lewis-Skyrms games is not strategies, but the *encoding-decoding pair* which is similar to *mappings* from above. 

In this framework, world states, signals and actions can be represented as *random variables* $S$, $M$ and $A$, each of which is a set of discrete units like states, messages and actions like $[S_1, \dots, S_s]$ together with a probability distribution $[Pr(S_1), \dots Pr(S_s)]$ over them. The same applies to messages and actions.

A sender observes the current state and transmits a signal – one of $m$ possible signals. The receiver detects this signal and chooses an action, $A_i$, from a set of available actions. Both the signal sent and the action chosen are random variables.

The probabilities for the random variables are linked through the sender’s and receiver's strategies which are a probability matrices of signals given world states of acts given signals respectively.

$$
\left[\begin{array}{ccc}
\operatorname{Pr}\left(M_1 \mid S_1\right) & \ldots & \operatorname{Pr}\left(M_m \mid S_1\right) \\
\vdots & \ddots & \vdots \\
\operatorname{Pr}\left(M_1 \mid S_s\right) & \ldots & \operatorname{Pr}\left(M_m \mid S_s\right)
\end{array}\right]\left[\begin{array}{ccc}
\operatorname{Pr}\left(A_1 \mid M_1\right) & \ldots & \operatorname{Pr}\left(A_a \mid M_1\right) \\
\vdots & \ddots & \vdots \\
\operatorname{Pr}\left(A_1 \mid M_m\right) & \ldots & \operatorname{Pr}\left(A_a \mid M_m\right)
\end{array}\right]
$$

As per criticisms of Skyrms's approach to Lewisian signaling games, @martinez2019 argues that Skyrms did not go far enough into information theory and allowed informational analysis only *after* sender and reciever adopted the strategies they will be using which does not explain how they arrived at them. Martinez suggests using Shannon's rate-distortion function [@shannon1948] to show minimum mutual information between states and acts with minimum rate of distortion. I allows him to recast payoffs as distortion indicators in the channel. Seen with this lens, a coordination game of signaling as an information channel looks more cooperative.

Overall, Skyrms's extension of Lewis's theory of conventions has dropped rationality requirements and introduced a more naturalistic account of signaling systems in a broader context.

# ОСТАНОВИЛСЯ ЗДЕСЬ

### Gintis

Gintis addressed key epistemic and conceptual gaps in Lewis’s original framework. He contended that achieving coordination as in Lewisian game requires agents to have mutually consistent beliefs based on shared inductive standards. It means there must be some guarantee that agents have the same rationality. Lewis implied this and did not question, but this is a strong assumption which needs substantiation, according to Gintis. He critiqued Lewis's theory for not fully explaining how shared beliefs responsible for converging on an equilibrium arise. According to him [@gintis2009a] Lewis’s ‘indication’ relies on shared knowledge but lacks a formal explanation of the cognitive and social processes involved.

<!--***-->
<!--Herbert Gintis’s refinement of David Lewis’s theory of conventions addresses key epistemic and conceptual gaps in Lewis’s original framework, enhancing its explanatory power and applicability within game theory and the behavioral sciences.-->
<!---->
<!--## Background: Lewis’s Theory of Conventions-->
<!---->
<!--David Lewis (1969) defined a *convention* as a regularity $$ R $$ in the behavior of members of a population $$ P $$ in a recurring situation $$ S $$ that satisfies three conditions:-->
<!---->
<!--1. Everyone conforms to $$ R $$.-->
<!--2. Everyone expects everyone else to conform to $$ R $$.-->
<!--3. Everyone prefers to conform to $$ R $$ on the condition that others do so, making $$ R $$ a coordination equilibrium in $$ S $$.-->
<!---->
<!--Lewis emphasized that conventions solve coordination problems by selecting among multiple equilibria in coordination games. Crucially, Lewis introduced the concept of *common knowledge* as an epistemic foundation for conventions: a proposition $$ p $$ is common knowledge among a group $$ G $$ if everyone knows $$ p $$, everyone knows that everyone knows $$ p $$, and so on ad infinitum. This infinite hierarchy of mutual knowledge ensures stable expectations and coordination[2][5].-->
<!---->
<!--## Limitations in Lewis’s Account-->
<!---->
<!--While Lewis’s theory is seminal, it assumes without fully explaining how common knowledge and shared expectations arise. The key epistemic challenge is explaining the *mechanism* by which agents come to share beliefs and coordinate on a particular equilibrium. Lewis’s notion of “indication” (how an event $$ A $$ indicates a proposition $$ p $$ to agents) relies on inductive reasoning and shared background but lacks formalization of the cognitive or social processes involved[2][5].-->
<!---->
<!--## Gintis’s Refinement: Epistemic and Normative Foundations-->
<!---->
<!--Herbert Gintis refines Lewis’s theory by explicitly integrating epistemic game theory and social norm theory to explain the emergence and stability of conventions beyond mere payoff considerations. His refinement can be understood through the following points:-->
<!---->
<!--### 1. Explicit Modeling of Epistemic Conditions-->
<!---->
<!--Gintis stresses that conventions require *not only* that agents have preferences aligned with coordination equilibria but also that they share *common knowledge* or at least *common reason to believe* the relevant facts. He highlights that:-->
<!---->
<!--- Common knowledge is a strong condition and often unrealistic; instead, *common reason to believe* or *mutual awareness* may suffice.-->
<!--- Agents must have *awareness structures* that allow them to recognize the relevance of others’ beliefs and expectations.-->
<!--- Coordination depends on *higher-order beliefs*—beliefs about others’ beliefs—and on the capacity for *symmetric reasoning* (agents reason similarly about the situation).-->
<!---->
<!--Formally, if $$ K_i(p) $$ denotes “agent $$ i $$ knows $$ p $$,” then common knowledge of $$ p $$ means:-->
<!---->
<!--$$-->
<!--p \wedge \bigwedge_{n=1}^\infty \bigwedge_{i_1, \ldots, i_n \in G} K_{i_1} K_{i_2} \cdots K_{i_n} (p)-->
<!--$$-->
<!---->
<!--Gintis underlines how this infinite chain is necessary for stable coordination but also explores weaker epistemic states that can sustain conventions in practice[2][5].-->
<!---->
<!--### 2. Role of Salience and Symmetric Reasoning-->
<!---->
<!--Gintis builds on Lewis’s insight that *salience*—the obviousness or naturalness of a solution—helps agents coordinate by making certain equilibria focal. He formalizes how salience depends on:-->
<!---->
<!--- The *symmetry* of agents’ reasoning processes.-->
<!--- The *shared background* and *inductive standards* that make certain signals or behaviors stand out as coordination devices.-->
<!--- The *precedent* or history of repeated interactions that create expectations about what others will do.-->
<!---->
<!--Thus, conventions are not just equilibria but *socially constructed focal points* sustained by shared cognitive frameworks[5].-->
<!---->
<!--### 3. Integration of Social Norms and Institutional Structures-->
<!---->
<!--Gintis argues that conventions are embedded in a larger normative and institutional context. He emphasizes:-->
<!---->
<!--- Conventions as *correlated equilibria* supported by social norms, signaling, and enforcement mechanisms.-->
<!--- The insufficiency of purely individualistic rationality: conventions emerge from *collective mental constructs* and *social epistemology*.-->
<!--- The role of *constitutive rules* that define social practices and make certain behaviors meaningful and expected.-->
<!---->
<!--This moves beyond Lewis’s model by incorporating the social and institutional scaffolding that sustains conventions over time[4][5].-->
<!---->
<!--### 4. Formal and Evolutionary Extensions-->
<!---->
<!--Gintis supplements Lewis’s static equilibrium concept with:-->
<!---->
<!--- **Epistemic game theory**, modeling agents’ knowledge and belief dynamics explicitly.-->
<!--- **Evolutionary game theory**, explaining how conventions evolve through learning, imitation, and adaptation in populations.-->
<!---->
<!--This dual approach captures both the rational deliberation and the adaptive processes behind conventions[1][2].-->
<!---->
<!--## Summary of Gintis’s Refinement in Formal Terms-->
<!---->
<!--- Lewis’s coordination equilibrium $$ R $$ solves the game $$ G $$ with multiple equilibria.-->
<!--- Gintis adds epistemic conditions: For each agent $$ i $$, there exists a state $$ \omega $$ such that-->
<!---->
<!--$$-->
<!--\omega \in K_i \bigcap_{j \in P} K_j (R) \quad \text{and} \quad \omega \in K_i K_j (R) \quad \text{for all } j,-->
<!--$$-->
<!---->
<!--ensuring mutual knowledge or reason to believe $$ R $$.-->
<!---->
<!--- Salience $$ S $$ acts as a coordination device making $$ R $$ focal:-->
<!---->
<!--$$-->
<!--S: \Omega \to \{0,1\}, \quad S(\omega) = 1 \iff \text{R is salient at } \omega,-->
<!--$$-->
<!---->
<!--where $$ \Omega $$ is the state space.-->
<!---->
<!--- Social norms $$ N $$ and institutional rules $$ I $$ provide correlated signals that sustain $$ R $$:-->
<!---->
<!--$$-->
<!--N, I: \Omega \to \text{Signals}, \quad \text{such that } \Pr(R | N, I) \text{ is high}.-->
<!--$$-->
<!---->
<!--## Conclusion-->
<!---->
<!--Herbert Gintis’s refinement of Lewis’s theory of conventions advances the original framework by rigorously incorporating epistemic conditions—common knowledge and mutual awareness—and emphasizing the social, normative, and institutional underpinnings of conventions. He situates Lewis-style coordination games within a richer model where shared beliefs, salience, and social norms jointly sustain stable conventions, bridging the gap between abstract equilibrium concepts and real-world social phenomena. This refinement forms a cornerstone of Gintis’s broader project to unify behavioral sciences through game-theoretic and epistemic analysis.-->
<!---->
<!--***-->
<!---->
<!--Gintis argues this framework fails to explain how such shared mental constructs arise in practice[^3][^4]. Specifically:-->
<!---->
<!--1. **Unrealistic Epistemic Demands**: The infinite recursion of mutual knowledge is computationally intractable for real-world agents. Lewis assumes but does not model the cognitive or social processes enabling agents to approximate common knowledge[^3][^5].-->
<!--2. **Lack of Emergent Social Properties**: Lewis treats conventions as equilibria sustained by individual rationality alone, ignoring the role of **social norms**, **institutional signals**, and **cultural evolution** in shaping shared expectations[^1][^3]. For example, driving on the right or left is not merely a coordination equilibrium but a norm enforced by law and social sanction[^1].-->
<!--3. **No Account of Symmetric Reasoning**: Lewis’s agents lack a mechanism for **symmetric reasoning**—the ability to infer others’ beliefs from one’s own. Gintis stresses that shared mental constructs require agents to reason analogously, guided by common cultural frameworks or norms[^3][^5].-->
<!---->
<!--In short, Lewis’s theory lacks a *generative mechanism* for the shared mental states it presupposes. Gintis concludes that conventions cannot be reduced to individual rationality but depend on **emergent social properties** that coordinate beliefs[^3][^4].-->
<!---->
<!------->
<!---->
<!--## Gintis’s Epistemic Game Theory Intervention-->
<!---->
<!--### Source and Logic-->
<!---->
<!--Gintis’s intervention arises from synthesizing **Bayesian rationality** with **sociological theories of norms** and **evolutionary game theory**[^2][^3]. He argues that classical game theory’s failure to explain coordination stems from its neglect of:-->
<!---->
<!--- **Correlated equilibria**: Strategies guided by external signals (e.g., social norms).-->
<!--- **Epistemic conditions**: How agents acquire and update beliefs about others’ knowledge.-->
<!---->
<!---->
<!--### Key Components-->
<!---->
<!--1. **Correlated Equilibria as Social Norms**:-->
<!--   Social norms act as **correlation devices**, directing agents to strategies that form equilibria. For example, a norm \$ N \$ partitions the strategy space \$ S \$ into subsets, with agents choosing \$ s_i \in S_i \$ conditional on \$ N \$. This creates a correlated equilibrium:-->
<!---->
<!--$$-->
<!--\Pr(s_i, s_{-i} | N) = \Pr(s_i | N) \Pr(s_{-i} | N),-->
<!--$$-->
<!---->
<!--where \$ s_{-i} \$ denotes others’ strategies[^3][^5].-->
<!---->
<!--2. **Symmetric Reasoning and Common Priors**:-->
<!--   Agents achieve coordination via **symmetric reasoning**—a cognitive capacity to infer others’ beliefs from shared norms or cultural frameworks. Formally, if agents are symmetric reasoners, mutual knowledge of a norm \$ N \$ implies:-->
<!---->
<!--$$-->
<!--K_i(N) \Rightarrow K_i K_j(N) \quad \forall i,j,-->
<!--$$-->
<!---->
<!--reducing the epistemic burden of common knowledge[^3][^5].-->
<!---->
<!--3. **Evolutionary Foundations**:-->
<!--   Gintis integrates evolutionary game theory to explain how norms and symmetric reasoning emerge. Populations evolve **prosocial traits** (e.g., honesty) and **punishment mechanisms** that stabilize cooperative equilibria[^1][^3].-->
<!---->
<!--### Implications-->
<!---->
<!--- **Rejection of Methodological Individualism**: Social norms and common priors are emergent properties irreducible to individual rationality[^2][^4].-->
<!--- **Unification of Behavioral Sciences**: Game theory becomes a bridge between economics (rationality), sociology (norms), and biology (evolution)[^2][^3].-->
<!---->
<!--By formalizing the epistemic and social foundations of coordination, Gintis’s framework explains how shared mental constructs arise—a mechanism absent in Lewis’s original theory[^3][^5].-->
<!--***-->
<!--Herbert Gintis critiques David Lewis’s theory of conventions primarily on the grounds that it assumes rather than explains the emergence of shared mental constructs necessary for coordination. Lewis’s framework relies on the concept of *common reason to believe* (CRtB), which requires that members of a population have mutual and higher-order beliefs about certain propositions relevant to coordination. Formally, Lewis defines CRtB as follows: there exists a state of affairs \$ A \$ such that-->
<!---->
<!--1. Everyone in the population \$ P \$ has reason to believe that \$ A \$ holds;-->
<!--2. \$ A \$ indicates to everyone in \$ P \$ that everyone in \$ P \$ has reason to believe that \$ A \$ holds;-->
<!--3. \$ A \$ indicates to everyone in \$ P \$ that a proposition \$ x \$ (such as a convention) holds.-->
<!---->
<!--This structure is designed to generate an infinite hierarchy of mutual beliefs, enabling coordination[^1].-->
<!---->
<!--However, Gintis points out that Lewis’s theory does not provide a *mechanism* by which agents come to share these mental constructs or inductive standards. In particular:-->
<!---->
<!--- The assumption that agents share *symmetric reasoning*—meaning that if a proposition \$ A \$ indicates \$ x \$ to one agent, it does so to all others—is strong and often unrealistic. Agents may have different perceptions or interpret the same information differently, undermining the symmetry condition[^1].-->
<!--- Lewis’s framework does not explain how agents develop *common background information* or *shared inductive standards* that allow them to interpret signals and coordinate expectations. The theory presupposes these shared cognitive frameworks rather than modeling their emergence or maintenance.-->
<!--- The infinite regress of mutual knowledge or reason to believe is epistemically demanding and lacks a plausible cognitive or social process to realize it in practice.-->
<!---->
<!--Consequently, Gintis argues that Lewis’s theory is incomplete because it treats conventions as equilibria sustained by shared mental states without explaining how those states arise or are sustained. This gap highlights the need for a richer account of the social and epistemic processes that generate and stabilize shared mental constructs necessary for coordination[^1].-->
<!---->
<!------->
<!---->
<!--## Gintis’s Epistemic Game Theory Intervention: Source, Logic, and Explanation-->
<!---->
<!--To address the shortcomings in Lewis’s account, Gintis introduces an epistemic game theory framework that explicitly models the knowledge and belief structures underlying coordination and conventions. This intervention draws on the intersection of game theory, epistemic logic, and social norm theory.-->
<!---->
<!--### Source and Motivation-->
<!---->
<!--Gintis’s epistemic game theory builds on the recognition that classical game theory’s solution concepts, such as Nash equilibria, assume agents have common knowledge of the game structure and rationality but do not explain how such knowledge arises. The motivation is to provide a formal apparatus that captures *higher-order beliefs*—beliefs about others’ beliefs—and the cognitive processes agents use to coordinate in the absence of perfect common knowledge[^1].-->
<!---->
<!--### Logical Structure-->
<!---->
<!--The epistemic approach formalizes agents’ reasoning through modal operators representing knowledge and reason to believe. For agent \$ i \$, \$ K_i(x) \$ denotes “agent \$ i \$ knows proposition \$ x \$,” and \$ R_i(x) \$ denotes “agent \$ i \$ has reason to believe \$ x \$.” The framework includes axioms such as:-->
<!---->
<!--- **Closure under indication**: If \$ x \$ indicates \$ y \$ to agent \$ i \$, then \$ R_i(x) \$ implies \$ R_i(y) \$:-->
<!---->
<!--$$-->
<!--[R_i(x) \cap (x \text{ indi } y)] \subseteq R_i(y)-->
<!--$$-->
<!---->
<!--- **Transitivity of indication**: If \$ x \$ indicates \$ y \$ and \$ y \$ indicates \$ z \$, then \$ x \$ indicates \$ z \$:-->
<!---->
<!--$$-->
<!--[(x \text{ indi } y) \cap (y \text{ indi } z)] \subseteq (x \text{ indi } z)-->
<!--$$-->
<!---->
<!--- **Higher-order indication**: If \$ x \$ indicates to \$ i \$ that \$ j \$ has reason to believe \$ y \$, and \$ i \$ has reason to believe that \$ y \$ indicates \$ z \$ to \$ j \$, then \$ x \$ indicates to \$ i \$ that \$ j \$ has reason to believe \$ z \$:-->
<!---->
<!--$$-->
<!--[(x \text{ indi } R_j(y)) \cap R_i(y \text{ ind}_j z)] \subseteq [x \text{ indi } R_j(z)]-->
<!--$$-->
<!---->
<!--These axioms formalize how agents propagate and update their beliefs and reason about others’ reasoning, enabling the emergence of mutual expectations necessary for coordination[^1].-->
<!---->
<!--### Explanation and Implications-->
<!---->
<!--Gintis’s epistemic game theory explains coordination as a process where agents use *indication relations* and *reason to believe* to build up mutual expectations without requiring full common knowledge. It recognizes that:-->
<!---->
<!--- Agents may rely on *correlated signals* or social norms as coordination devices that reduce epistemic demands.-->
<!--- Symmetric reasoning is a strong but sometimes approximated condition; agents may hold *distributed reason to believe* where beliefs are consistent but not identical.-->
<!--- The framework bridges individual reasoning and social structure by showing how shared mental constructs can emerge from the interaction of agents’ beliefs and signaling mechanisms.-->
<!---->
<!--This intervention thus provides the missing mechanism in Lewis’s theory by modeling how shared mental constructs—common reason to believe and expectations—can be generated and sustained through epistemic processes formalized within game theory[^1].-->

- [[Private-property-equilibrium-generalizes-Bourgeois-equilibrium-by-endogenizing-costs|Private property equilibrium generalizes Bourgeois equilibrium by endogenizing costs]]

<!---->
<!--Refinements and Game Theory Applications**  Robert Aumann\'s 1976 paper \"Agreeing to Disagree\" stands as a landmark contribution that brought the concept of common knowledge into the formal realm of game theory and economics.^1^ Aumann provided a rigorous, set-theoretic definition of common knowledge based on partitions of the state space, offering a powerful mathematical tool for analyzing strategic interactions. His formalization defined an event as common knowledge at a particular state if that event includes all states that any player considers possible, all states that any player considers possible for any other player, and so on, ad infinitum.^43^ This rigorous definition enabled the formal analysis of how information is shared and understood among rational agents.  One of the most significant results stemming from Aumann\'s formalization is the \"agreeing to disagree\" theorem.^40^ This theorem demonstrates that if two or more rational agents share a common prior probability distribution over the states of the world, and if their posterior probabilities about a particular event become common knowledge among them, then these posterior probabilities must be equal. This result has profound implications for understanding belief revision, information aggregation, and the potential for consensus among rational agents. The very fact that a disagreement in probabilities becomes common knowledge implies that the agents should revise their beliefs until they converge, assuming they started with the same underlying beliefs and are reasoning rationally based on their information.  -->
<!---->
<!--Robert Aumann’s 1976 paper “Agreeing to Disagree” established a landmark formalization of common knowledge within game theory and economics.^1^ Aumann’s rigorous, set-theoretic definition defined an event as common knowledge at a particular state if it encompasses all states considered possible by every player, recursively extending to all players’ considerations of other players’ possibilities ad infinitum.^43^ This enabled the formal analysis of information sharing and understanding among rational agents. The resulting “agreeing to disagree” theorem.^40^ posits that if two or more rational agents share a common prior probability distribution and their posterior probabilities about an event become common knowledge, those posterior probabilities must converge. This fundamentally demonstrates belief revision, information aggregation, and the potential for consensus among rational agents, implying that agents should iteratively adjust their beliefs towards convergence given a shared prior and rational, information-based reasoning.-->

<!--***-->
<!---->
<!--***-->
<!---->
<!--The concept of common knowledge finds a significant parallel and connection in cognitive science with the development of Theory of Mind (ToM), which refers to the ability to attribute mental states -- such as beliefs, intentions, desires, and knowledge -- to oneself and to others.^1^ The foundational work of David Premack and Guy Woodruff in 1978 explored whether non-human primates possess a ToM, raising critical questions about the cognitive prerequisites for understanding others\' mental states.^56^ Their research suggested that attributing mental states to others is a fundamental aspect of social cognition, and arguably a necessary stepping stone towards grasping the more complex, recursive nature of common knowledge. To understand \"I know that you know,\" one must first have the capacity to represent that \"you know\" something.  Michael Tomasello\'s extensive work on the evolution of human cognition, particularly his 2014 contributions, emphasizes the uniquely human ability to engage in \"shared intentionality\".^58^ This involves the capacity to participate with others in collaborative activities that have shared goals and intentions, requiring a sophisticated understanding of one\'s own and others\' mental states, as well as the ability to engage in joint attention. Shared intentionality, with its focus on mutual understanding and shared goals in cooperative contexts, bears a close relationship to the concept of common knowledge. Engaging in a collaborative task effectively often requires a level of shared understanding about the objective, the roles of the participants, and each other\'s intentions and expectations, which can be seen as a functional form of common knowledge within that specific context. Tomasello\'s research suggests that the development of shared intentionality is a key factor differentiating human cognition from that of other primates and underpins our complex social interactions and cultural practices.  -->
<!---->
<!--Experimental studies have provided valuable insights into how humans reason about and utilize common knowledge in various strategic and social situations. Michael Suk-Young Chwe\'s 2001 work, \"Rational Ritual,\" offered an analysis of how public rituals and ceremonies serve as mechanisms for creating common knowledge within a group.^1^ Chwe argued that by making information simultaneously available to a large number of people, rituals ensure that participants not only receive the information but also become aware that others have received the same information, and that those others are aware of this as well, creating a shared epistemic state that is crucial for solving coordination problems and fostering shared cultural understandings.^60^ From Super Bowl commercials to political inaugurations, these public events function to establish common knowledge by providing a shared experience and a simultaneous broadcast of information.  Cristina Bicchieri and Erte Xiao\'s 2009 experimental research focused on the role of expectations in individuals\' compliance with social norms.^18^ Their studies explored how individuals\' normative expectations (what they believe others think they should do) and empirical expectations (what they believe others will actually do) influence their decisions in social interactions. These expectations are closely related to the concept of common knowledge, as they involve beliefs about others\' beliefs and behaviors. Bicchieri and Xiao\'s work highlighted the complex interplay between these different types of expectations in guiding behavior, providing empirical evidence for the importance of shared understandings -- a key component of common knowledge -- in the context of social norms. By manipulating information about others\' expectations, their experiments shed light on the cognitive processes involved in reasoning about shared knowledge and its impact on individual choices within social contexts.  -->
<!---->
<!--Recognizing the stringent requirements and potential limitations of common knowledge, particularly the infinite regress, alternative frameworks have been proposed to better capture the epistemic states underlying coordination and social interaction. One such framework is the concept of common belief, introduced by Dov Monderer and Dov Samet in 1989.^1^ Common belief relaxes the absolute certainty of common knowledge by focusing on a state where the probability of a proposition being believed by all agents, and this belief being iterated at higher levels, approaches one.^40^ This notion acknowledges that in many real-world situations, individuals might act based on a very high degree of confidence that others share certain beliefs, even if they cannot be absolutely certain of this at every level of iteration. Common belief provides a more flexible and potentially more realistic lens through which to analyze scenarios where strong mutual expectations drive behavior without necessarily meeting the strict criteria of common knowledge.  -->
<!---->
<!--**Pragmatic Approaches to Shared Understanding:**  Pragmatic perspectives on shared understanding offer yet another way to think about the epistemic foundations of communication and interaction, moving beyond the purely logical or probabilistic frameworks of common knowledge and common belief. Herbert Clark\'s 1996 work on language use emphasized the collaborative nature of communication, where participants actively work to establish and maintain \"common ground\" -- the shared knowledge, beliefs, and assumptions that are necessary for successful understanding and coordination.^1^ Clark highlighted that communication is a dynamic process where individuals constantly monitor each other\'s understanding and adjust their contributions to ensure they are on the same page. This perspective suggests that shared understanding is often achieved through active collaboration and the ongoing management of common ground in real-time interactions.  Dan Sperber and Deirdre Wilson\'s 1986 relevance theory proposed that human communication is fundamentally driven by the principle of relevance.^1^ According to this theory, communicators aim to provide information that is most relevant to their audience in a given context, and audiences interpret utterances by selecting the most relevant interpretation. This process often relies heavily on shared background knowledge and inferential processes to achieve understanding efficiently. Relevance theory suggests that individuals do not need to explicitly state everything they know; instead, they rely on their audience to infer the intended meaning by selecting the interpretation that is most relevant given the context and their shared assumptions. This pragmatic approach underscores how shared understanding in communication is often achieved efficiently through inference and the exploitation of shared contextual assumptions, rather than requiring explicit common knowledge of every detail.  -->
<!---->
<!--**Conclusion: Synthesis and Future Directions in Common Knowledge Research**  The concept of common knowledge, first systematically explored by David Lewis, has proven to be a remarkably influential and multifaceted idea across a range of disciplines. From its philosophical roots in understanding conventions and coordination, it has been formally integrated into game theory and economics, providing powerful tools for analyzing strategic interactions and information asymmetry. Evolutionary game theory has offered a perspective on how shared understandings, akin to common knowledge, can emerge and stabilize through dynamic processes without requiring fully rational agents or infinite levels of iterated knowledge. Cognitive science has linked common knowledge to fundamental aspects of social cognition, such as theory of mind and shared intentionality, and experimental studies have provided empirical insights into how humans reason about and utilize shared knowledge in various contexts.  Despite its theoretical significance, the standard definition of common knowledge, with its requirement of infinite recursion, has faced critiques regarding its psychological plausibility and practical attainability, particularly in dynamic real-world scenarios. This has led to the development of alternative frameworks, such as common belief, which relaxes the certainty requirement, and pragmatic approaches that focus on the active construction of shared understanding in communication. These alternative perspectives highlight the complexity of shared knowledge and the need for models that better reflect the cognitive limitations of agents and the imperfections of information in real-world interactions.  Future research on common knowledge and shared understanding could fruitfully explore several directions. Further investigation into the cognitive mechanisms underlying how humans actually reason about others\' knowledge and beliefs, and how these processes relate to the theoretical concept of common knowledge, is warranted. The development of more realistic models of strategic interaction that incorporate bounded rationality, imperfect information, and the dynamics of belief formation and revision remains a crucial area. Additionally, the application of common knowledge concepts and related frameworks to understand emerging technologies and social phenomena, such as the dynamics of information sharing on social media platforms and the challenges of coordination in artificial intelligence systems, presents exciting new avenues for exploration. Understanding the nuances of how shared knowledge and expectations are formed, maintained, and utilized in these evolving contexts will be increasingly important in the years to come.  **Bibliography**-->
<!---->
<!--***-->
<!---->
<!--Schiffer conceptualized common knowledge as an *infinite hierarchy of mutual knowledge*, defined recursively as follows:  -->
<!--- **Mutual knowledge₁**: Everyone knows proposition $p$.  -->
<!--- **Mutual knowledge₂**: Everyone knows that everyone knows $p$.  -->
<!--- **Mutual knowledgeₙ**: This recursion continues for $n$ levels, where $n \to \infty$.  -->
<!---->
<!--Formally, common knowledge $C(p)$ is the infinite conjunction:  -->
<!--$C(p) = \bigwedge_{n=1}^{\infty} K^n(p),$  -->
<!--where $K^n(p)$ denotes the $n$-th level of mutual knowledge. This approach emphasizes communication as the mechanism to elevate mutual knowledge into common knowledge. For example, in the *Muddy Children Puzzle*, if two children both see mud on each other’s faces, they initially have mutual knowledge₁ (both know there’s at least one muddy face). Only after public announcements do they iteratively reach mutual knowledge₂, mutual knowledge₃, etc., converging toward common knowledge.-->
<!---->
<!--Aumann formalized common knowledge using *information partitions* over possible states of the world. Let $ \Omega $ be the set of possible states, and let $ \mathcal{P}_i $ represent the information partition of agent $ i $. Aumann’s framework defines common knowledge as follows:  -->
<!---->
<!--An event $ E \subseteq \Omega $ is *common knowledge* at state $ \omega $ if the cell of the *meet* of the agents’ partitions containing $ \omega $ is a subset of $E$.  -->
<!---->
<!--A key result is Aumann’s Agreement Theorem: If two rational agents with common priors have common knowledge of their posterior probabilities about an event $E$, their probabilities must coincide. Formally, if $ C(p_i(E) = q_i) $ for agents $ i = 1, 2 $, then $ q_1 = q_2 $. This framework avoids explicit infinite regress by defining common knowledge as a fixed point in the agents’ information partitions.-->
<!---->
<!------->
<!---->
<!--| Aspect                | Schiffer’s Model                          | Aumann’s Model                          |  -->
<!--|-----------------------|-------------------------------------------|-----------------------------------------|  -->
<!--| **Structure**         | Infinite epistemic hierarchy              | Set-theoretic partitions                |  -->
<!--| **Focus**             | Communication-driven knowledge escalation | Bayesian updating and rational agreement |  -->
<!--| **Practicality**      | Requires explicit recursive reasoning     | Avoids regress via topological closure  |  -->
<!--| **Applications**      | Explains coordination puzzles             | Underpins game-theoretic equilibrium    |  -->
<!---->
<!--Schiffer’s model aligns with intuitive examples like the Muddy Children Puzzle, where announcements progressively deepen mutual knowledge. Aumann’s approach, by contrast, provides a mathematical foundation for strategic interactions, showing how common knowledge enforces consensus among Bayesian agents. While Schiffer’s hierarchy is often seen as philosophically intuitive, Aumann’s formalism has been more widely adopted in economics and computer science due to its technical precision. Both, however, agree that common knowledge transcends mere mutual understanding, requiring agents to account for *each other’s epistemic states* in a systematic way.-->
<!---->
<!--The relationship between Lewis’s notion and these subsequent formalizations remains debated. Cubitt and Sugden [@cubitt2003] suggested a fundamental distinction between Lewis’s perspective and later theories, while Vanderschraaf [-@vanderschraaf1998] and Sillari [-@sillari2005] argued for continuity between them.-->
<!---->
<!--*** -->
<!---->
<!--Cubitt and Sugden (2003) argue for a fundamental **discontinuity** between David Lewis’s concept of common knowledge (as outlined in *Convention*, 1969) and the formalizations of Schiffer/Aumann, rooted in differing philosophical foundations and operational assumptions. Here’s a breakdown of their critique:-->
<!---->
<!--### 1. **Lewis’s Notion: Coordination-Focused and Precedent-Based**  -->
<!--Lewis defines common knowledge as arising from **salient precedents** or **coordination equilibria**, where agents:  -->
<!--- Share mutual expectations grounded in a *publicly recognized signal* (e.g., a traffic light).  -->
<!--- Do not require infinite recursion in practice; instead, common knowledge emerges from pragmatic, context-dependent reasoning.  -->
<!---->
<!--For Lewis, common knowledge is a *social construct* tied to conventions—agents coordinate because they recognize a shared basis for action, not because they explicitly compute infinite epistemic hierarchies.-->
<!---->
<!--### 2. **Schiffer/Aumann: Infinite Hierarchies vs. Partitions**  -->
<!--- **Schiffer** formalizes common knowledge as an **infinite tower** of mutual knowledge ($$ C(p) = \bigwedge_{n=1}^\infty K^n(p) $$).  -->
<!--- **Aumann** models it via **information partitions** (common knowledge as the meet of agents’ partitions in $$ \Omega $$).  -->
<!---->
<!--Both frameworks presuppose agents with unbounded logical capacity to process infinite iterations or partition intersections—a stark contrast to Lewis’s emphasis on pragmatic, bounded coordination.-->
<!---->
<!--### 3. **Key Discontinuities Highlighted by Cubitt & Sugden**  -->
<!--**(a) Epistemic vs. Practical Foundations**  -->
<!--- Lewis’s common knowledge is *action-oriented* and rooted in **conventions** (e.g., stopping at red lights).  -->
<!--- Schiffer/Aumann treat it as a *logical property* of agents’ knowledge structures, decoupled from real-world coordination.  -->
<!---->
<!--**(b) Role of Salience**  -->
<!--- Lewis requires **salient cues** (e.g., focal points) to bootstrap common knowledge.  -->
<!--- Schiffer/Aumann exclude salience, relying instead on axiomatic mutual reasoning.  -->
<!---->
<!--**(c) Bounded vs. Unbounded Rationality**  -->
<!--- Lewis’s agents operate under **bounded rationality**—common knowledge emerges from practical precedents, not recursive deductions.  -->
<!--- Schiffer/Aumann assume agents can process infinite hierarchies or partition operations, implying **unbounded cognitive capacity**.  -->
<!---->
<!--**(d) Necessity of Publicity**  -->
<!--- Lewis emphasizes **public events** (e.g., a fire alarm) as triggers for common knowledge.  -->
<!--- Schiffer/Aumann reduce publicity to abstract logical or set-theoretic constructs (e.g., public announcements as partition refinements).  -->
<!---->
<!--### 4. Implications of the Discontinuity  -->
<!--Cubitt and Sugden contend that Schiffer/Aumann’s formalisms fail to capture the **pragmatic, evolutionary nature** of common knowledge in Lewis’s work. By treating it as a fixed logical property, they neglect:  -->
<!--- The role of **culture** and **history** in establishing conventions.  -->
<!--- How agents with limited reasoning capacity *actually* achieve coordination (e.g., via salience rather than infinite deliberation).  -->
<!---->
<!--This disconnect renders Schiffer/Aumann’s models ill-suited for explaining real-world scenarios Lewis sought to address, such as language conventions or social norms.-->
<!---->
<!--### Example: The Traffic Light Puzzle  -->
<!--- **Lewis**: Drivers stop at red lights because they recognize a *salient convention* reinforced by precedent. Common knowledge arises from shared social practice, not mutual knowledge hierarchies.  -->
<!--- **Schiffer/Aumann**: Common knowledge would require drivers to know that others know they know the light is red, ad infinitum—an unrealistic demand for real-time coordination.  -->
<!---->
<!--### Conclusion  -->
<!--Cubitt and Sugden’s critique underscores that Lewis’s common knowledge is **procedural** (rooted in coordination practices), while Schiffer/Aumann’s is **declarative** (a static property of knowledge structures). This philosophical and operational gap explains why formal models struggle to replicate the dynamism of Lewis’s convention-based framework.-->
<!---->
<!--***-->
<!---->
<!--Vanderschraaf and Sillari (2009) argue for **continuity** between David Lewis’s convention-based notion of common knowledge and the formalizations of Schiffer/Aumann, positing that these frameworks share foundational goals and can be reconciled through careful interpretation. Their analysis emphasizes complementary perspectives rather than irreconcilable differences. Here’s their reasoning:-->
<!---->
<!------->
<!---->
<!--### 1. **Shared Foundational Goal: Explaining Coordination**  -->
<!--Both Lewis and the Schiffer/Aumann frameworks aim to explain how agents achieve **coordinated behavior** in strategic interactions.  -->
<!--- **Lewis**: Common knowledge arises from *conventions* (e.g., traffic rules) that stabilize expectations.  -->
<!--- **Schiffer/Aumann**: Formalize the epistemic conditions necessary for coordination (e.g., infinite mutual knowledge or partition intersections).  -->
<!---->
<!--Vanderschraaf and Sillari contend that Schiffer/Aumann’s models *operationalize* the abstract conditions Lewis presupposes in his conventions. For example, Aumann’s partitions can encode the "publicity" of events central to Lewis’s conventions, while Schiffer’s hierarchy mirrors the iterative reasoning agents use to infer shared expectations.-->
<!---->
<!------->
<!---->
<!--### 2. **Publicity as a Bridge**  -->
<!--Lewis’s emphasis on **public events** (e.g., a fire alarm) as triggers for common knowledge aligns with Schiffer/Aumann’s focus on *public announcements* or *partition refinements*:  -->
<!--- In Aumann’s model, a public event $$ E $$ corresponds to a partition cell known to all agents, which becomes common knowledge after observation.  -->
<!--- Schiffer’s hierarchy similarly requires public communication to escalate mutual knowledge.  -->
<!---->
<!--This bridges Lewis’s pragmatic notion of salience (e.g., a red traffic light) with formal models’ requirement of shared information structures.-->
<!---->
<!------->
<!---->
<!--### 3. **Bounded Rationality as Truncated Hierarchies**  -->
<!--Vanderschraaf and Sillari argue that Schiffer’s infinite hierarchy and Aumann’s partitions can accommodate **bounded rationality** in practice:  -->
<!--- Agents in real-world scenarios (e.g., Lewis’s conventions) need not compute infinite recursions explicitly. Instead, established conventions act as **focal points** that *approximate* common knowledge after a few iterations.  -->
<!--- For example, drivers stopping at a red light rely on a convention that implicitly assumes mutual knowledge up to a pragmatically sufficient level (e.g., $$ K^2(p) $$ or $$ K^3(p) $$), bypassing infinite regress.  -->
<!---->
<!--This aligns with experimental evidence showing that humans rarely reason beyond 2–3 levels of mutual knowledge in coordination games.-->
<!---->
<!------->
<!---->
<!--### 4. **Conventions as Fixed Points**  -->
<!--Lewis’s conventions can be mapped to **fixed points** in Aumann’s partition framework:  -->
<!--- A convention (e.g., “drive on the right”) corresponds to a *stable equilibrium* where agents’ knowledge partitions align with shared social rules.  -->
<!--- Similarly, Schiffer’s hierarchy converges to a fixed point ($$ C(p) $$) as mutual knowledge deepens through repeated interactions.  -->
<!---->
<!--Thus, conventions are not merely cultural artifacts but *emergent properties* of the epistemic structures formalized by Schiffer/Aumann.-->
<!---->
<!------->
<!---->
<!--### 5. **Reconciling Salience with Formal Models**  -->
<!--Vanderschraaf and Sillari reinterpret Lewis’s “salience” as a mechanism for **partition refinement** or **hierarchy truncation**:  -->
<!--- A salient event (e.g., a fireworks display) publicly signals a shared context, allowing agents to coordinate without infinite reasoning.  -->
<!--- This can be modeled in Aumann’s framework by restricting the state space $$ \Omega $$ to a subset where salience is common knowledge.  -->
<!---->
<!--For instance, in Lewis’s “phone call breakdown” example, agents coordinate on a default meeting time because salience (e.g., noon) acts as a partition-refining public signal.-->
<!---->
<!------->
<!---->
<!--### 6. **Common Knowledge as a Dynamic Process**  -->
<!--Both frameworks implicitly treat common knowledge as a **dynamic process** rather than a static state:  -->
<!--- **Lewis**: Conventions evolve through precedent and reinforcement.  -->
<!--- **Schiffer/Aumann**: Mutual knowledge escalates via announcements (Schiffer) or Bayesian updating (Aumann).  -->
<!---->
<!--This shared emphasis on iterative learning undermines Cubitt and Sugden’s “discontinuity” claim, as both traditions acknowledge that common knowledge is *constructed* through interaction.-->
<!---->
<!------->
<!---->
<!--### Example: The Repeated Traffic Light  -->
<!--- **Lewis**: Drivers stop at red lights because repeated precedent creates a convention.  -->
<!--- **Schiffer/Aumann**: Each successful coordination (stopping at red) refines drivers’ partitions or mutual knowledge, reinforcing the convention as common knowledge.  -->
<!---->
<!------->
<!---->
<!--### Conclusion  -->
<!--Vanderschraaf and Sillari’s continuity thesis hinges on three claims:  -->
<!--1. Schiffer/Aumann’s formalisms **generalize** Lewis’s conventions by specifying their epistemic preconditions.  -->
<!--2. Bounded rationality in practice **truncates** infinite hierarchies to match Lewis’s emphasis on pragmatic coordination.  -->
<!--3. Salience and publicity act as **bridges** between abstract formal models and real-world conventions.  -->
<!---->
<!--By framing Lewis’s work as a *procedural instantiation* of Schiffer/Aumann’s declarative structures, they argue that the frameworks are complementary, not contradictory.-->
<!---->
<!--***-->
<!---->
<!--@vanderschraaf1998 critiques Lewis’ theory for being overly restrictive in its reliance on Nash equilibria and common knowledge. He argues that conventions need not solve pure coordination problems or require universal conformity. Instead, Vanderschraaf broadens the scope of conventions by introducing *correlated equilibria* and focusing on inductive learning processes.-->
<!---->
<!--In correlated equilibria players coordinate actions through external signals rather than mutual payoff alignment. His model accommodates conventions in asymmetric situations like fashion, where participants follow trends through *observational inductive learning* rather than explicit coordination. This explains property conventions as self-reinforcing patterns where people respect ownership claims based on observed precedents, not because it solves a mutual coordination problem.-->
<!---->
<!--***-->
<!---->
<!--Correlated Equilibria-->
<!--While Lewis relies on Nash equilibria—where players independently choose strategies that are mutual best responses—Vanderschraaf adopts Robert Aumann’s concept of correlated equilibria. In correlated equilibria:-->
<!---->
<!--Players coordinate their actions based on external signals or shared expectations, rather than purely independent reasoning.-->
<!---->
<!--Conventions can emerge even in asymmetric or competitive situations where individuals have divergent preferences (e.g., bargaining scenarios).-->
<!---->
<!--For example, Vanderschraaf shows how property conventions stabilize through historical precedents rather than explicit coordination or universal agreement. These conventions function as correlated equilibria, aligning expectations without requiring identical preferences among participants.-->
<!---->
<!--Inductive Learning-->
<!--Vanderschraaf introduces inductive learning as a mechanism for convention formation. Unlike Lewis’ assumption of common knowledge, Vanderschraaf emphasizes how agents learn behavioral regularities through repeated interactions:-->
<!---->
<!--Agents observe others’ actions over time and adjust their strategies accordingly.-->
<!---->
<!--Behavioral patterns become self-reinforcing as individuals develop expectations based on past observations.-->
<!---->
<!--Conventions emerge organically as focal points—solutions perceived as natural or salient due to historical or social prominence.-->
<!---->
<!--This inductive process allows conventions to form even when common knowledge is absent or imperfect, addressing one of the key criticisms of Lewis’ model.-->
<!---->
<!--Key Differences Between Vanderschraaf and Lewis-->
<!--Aspect	Lewis	Vanderschraaf-->
<!--Equilibrium Type	Nash equilibrium	Correlated equilibrium-->
<!--Knowledge Requirement	Common knowledge	Inductive learning-->
<!--Problem Type	Pure coordination problems	Broader, including asymmetric situations-->
<!--Preference Alignment	Aligned preferences	Divergent preferences-->
<!--Implications of Vanderschraaf’s Theory-->
<!--Vanderschraaf’s revisions expand the applicability of convention theory beyond the narrow scope defined by Lewis. His framework explains how conventions can arise in complex social contexts, such as bargaining or property systems, where interests may conflict rather than align perfectly. By incorporating correlated equilibria and inductive learning, Vanderschraaf provides a more flexible account of how conventions stabilize behavior.-->
<!---->
<!--For instance:-->
<!---->
<!--In bargaining scenarios, agents may converge on egalitarian solutions through inductive learning rather than relying on common knowledge.-->
<!---->
<!--Property rights systems emerge as conventions through historical precedent, functioning as correlated equilibria rather than Nash equilibria.-->
<!---->
<!--Conclusion-->
<!--Peter Vanderschraaf’s theory builds upon David Lewis’ foundational work while addressing its limitations. By introducing correlated equilibria and emphasizing inductive learning processes, Vanderschraaf broadens the scope of convention theory to include competitive and asymmetric situations. His framework provides a more dynamic understanding of how conventions emerge and persist in diverse social contexts.-->
<!---->
<!--@oconnor2021 goes further and proposes an information-theoretic measure for conventionality, or arbitrariness of a convention, applicable to both human “animal” conventions like that of vervet monkeys. As she is most interested in the emergence of cultural traits like gendered division of labor, she says that most cultural traits are both functional and arbitrary, or contingent, for they “might have been otherwise”.-->
<!---->
<!--O'Connor notes that Lewis's notion of convention emphasizes arbitrariness, for a coordination game has at least two *proper coordination equilibria* — a state of a strategic situation where no player can deviate from a selected strategy and improve the payoff for any other player. It means that either of them might have been established equiprobably. In line with this, @simons2019 illustrate the distinction of functional and arbitrary conventions by putting it along three dimensions:-->
<!---->
<!--1. Payoff difference — some coordination equilibria have bigger payoffs than others;-->
<!--2. Likelihood of emergence — some conventions are more likely to emerge than others;-->
<!--3. Stability — once these conventions have emerged, they are unlikely to be deviated from.-->
<!---->
<!--O'Connor proposes to layer these dimensions onto evolutionary models, namely those of replicator dynamics[^replicator-dynamics]. It allows for specifying what Simons and Zollman mean by the likelihood of emergence (2) and stability of conventions (3).-->
<!---->
<!--[^replicator-dynamics]: -->
<!---->
<!--- [ ] написать определение replcator dynamics и кратко критику от стерельного и хармса-->
<!---->
<!--\begin{figure}[htb]-->
<!--\centering-->
<!--\begin{tabular}{c|cc}-->
<!-- &A&B\\ \hline-->
<!--A & (1,1) & (0,0) \\ \hline-->
<!--B & (0,0) & (x,x)-->
<!--\end{tabular}-->
<!--\caption{A coordination game where B equilibrium is more favorable given $x > 1$}-->
<!--\end{figure}-->

%$$
%\begin{array}{c|cc}
% & A & B \\ \hline
%A & (1,1) & (0,0) \\ \hline
%B & (0,0) & (x,x)
%\end{array}
%$$
<!--**A coordination game where B equilibrium is more favorable given $x > 1$**-->
<!---->
<!--Modelled as replicator dynamics, the game on the figure above has B equilibrium as more “natural” in the sense (1) — that of a higher payoff. The corollary of this is a larger basin of attraction. Given $x = 50$, the phase diagram for this game will look like this:-->
<!---->
<!--The basin of attraction for A equilibrium takes up 2% of space, while 98% for B. These basins can represent the probability that each outcome evolves, given little information about the initial conditions of the population. Thus, B is more likely to emerge and is more “natural” in the sense (2).-->
<!---->
<!--To propose a measure of conventionality, O'Connor focuses on naturalness of conventions as their probability of emergence (2). As has been shown, different equilibria might evolve with different probability, and the sizes of basins indicate the amount of information we gain from examining an evolutionary process. The amount of information in this process is a *measure of arbitrariness* of a convention. It increases with greater uncertainty about what will evolve and decreases with less.-->
<!---->
<!--The relevant information-theoretic measure is Shannon entropy. It measures the average amount of information transmitted through a channel: $H(x) = \sum_{i} P(x_{i})I(x_{i})$. The amount of information gained from observing something is related to how much we learn or how surprised we are. It is calculated by summing the probabilities of the signals $P(x_i)$ multiplied by their information content $I(x_{i})$, with $I(x_{i})$ equal to $-\log_{2}P(x_{i})$ — the less probable a signal, the more information it carries. Overall, this weights the probability of each signal being sent by the amount of information it carries, giving a measure of average information in the channel.[^1]-->
<!---->
<!--If other conditions hold, a channel has higher entropy when signals are more equiprobable or there are more signals. This is as opposed to a biased channel, with one signal sent 99% of the time, which has an entropy of just $0.08$. Therefore, more equiprobable signals and more signals lead to higher entropy. As probabilities $P(x_{i})$ represent the sizes of the basins of attraction, learning more from an evolutionary process increases the arbitrariness of an evolving phenomenon in question. Given more equilibria or if their basins of attraction are close to equal, the phenomenon is more arbitrary, contingent or “conventional”.-->
<!---->
<!--It is possible to measure the naturalness of a convention similar to @simons2019 using $-\log_{2}P(x)$, which represents the information value of a particular outcome. The closer the value of $-\log_{2}P(x)$ to $0$, the more natural a convention is. This measure can be used whenever we have clear probabilities for different evolutionary outcomes. However, if there is uncertainty about the initial conditions of a population, it is possible to assign probabilities to different population starting places and not their basins of attraction, for they will not track the probability of emergence correctly. Another case is stochastic dynamics, where each starting point might lead to multiple equilibria depending on chance events. Here, $P(x_{i})$ can be defined as percentage of emergence of different equilibria in an iterated game. For example, if 10 individuals play the game in the figure above with $x=10$ 10K times, it yields 6% chance of emergence of A, and 94% for B.-->
<!---->
<!--As O'Connor notes, one problem with a proposed conventionality measure is the source of probabilities. It means that inputs in an entropy equation can be selected quite arbitrarily depending on a case (which is ironic but predictable). As there are no actual chances, it can be hard to determine, whether a convention might have been otherwise. To address this worry, she underlines the representation-dependence of the measure. We can specify what is probability in terms of a particular model or data set, for instance, basins of attraction, emergence over multiple rounds of simulation, equilibrium time and percentage of societies adopting a behavior. This eliminates worries about probability and chance in the world. However, representations should be tailored to the intended explanatory goals. However, as representations have limitations, the proposed measure should not be taken as an absolute truth.-->
<!---->

<!--## Salience, epistemic and "natural"-->
<!---->
<!--Although these criticisms are fair enough, there are hints of not purely rational and logical nature of "common knowledge" already in Lewis. He elaborated on Schelling's notion of "focal points", and focal points serve as a source of public signals which produce common knowledge [@defreitas2019]. As Schelling noted, observable patterns presuppose their observability, hence it is rational to expect an opponent to behave according to such patterns and thus deduce intentions of another opponent [@schelling1980, 104]. -->
<!---->
<!--As @sugden2006 note that focal points are underpinned not by instrumental rationality of standard game theory, but by *pragmatic rationality* which is induced from its empirical success. Schelling stressed the "perceptual and suggestive element in the formation of mutually consistent expectations" [@schelling1980, 83-84] which is essential for focal points, as the authors note. It means that there are no logical restrictions on converging for expectations between players.  -->
<!---->
<!--To illustrate this point, Sugden and Zamarrón three features of Schelling's focal point analysis: the players' presumption of the solvability of coordination problems, which is based on empirical success of real agents; players' reasoning in finding focal points is not guided by principles of truth and validity essential for deductive systems; players reason fully rationally in finding focal points. As Schelling writes, "most situations - perhaps every situation for people who are practiced at this kind of game - provides some clue for coordinating behavior, some focal point for each person's expectation of what the other expects him to expect to be expected to do" [[@schelling1980, 57]]. ^69e3d6-->
<!---->
<!--To underline the pragmatic nature of focality, authors note Schelling's insistence that players use neither an individualistic best-response strategy nor any team reasoning implying shared agency.  ^59c366-->
<!---->
<!--The inherent difficulty with formalizing the idea of focal points consists of the the "unstructured and unbounded set of possible coordination devices" [[@sugden2006, 616]]. It means that any source of focality might present a theory in itself, be it the primary salience from psychological factors or team reasoning aimed at joint optimality.     -->
<!---->
<!--As Sugden and Zamarrón suppose, for Schelling, a decision in finding focal points is rational if it helps and agent to achieve her ends. It might be connected with principles of evolutionary ecological rationalities.  -->
<!---->
<!--Pattern recognition is bound to contextual cues, hence [[Salience in focal points is highly context-dependent and intersubjective]]. -->
<!---->
<!--### Epistemic salience-->
<!--* [[12.1_cognitive-selectivity-helps-coping-with-social-coordination-by-attention-relation-and-behavior.md]]-->
<!--    * [[12.2_Salience-in-focal-points-is-highly-context-dependent-and-intersubjective.md]]-->
<!--        * [[12.2a_Focal-points-work-because-of-pattern-recognition.md]]-->
<!--        * [[12.2b_Focal-points-are-underpinned-by-pragmatic-rationality.md]]-->
<!--* [[@lacroix2020a]]-->
<!--* [[@zachnik2021]]-->
<!--    * variable frame theory-->
<!--    * cognitive hierarchy theory-->
<!--* Vanderschraaf's formalization of salience with Bayesian updating-->
<!--    * [[10.1a1a_Convention-is-CE,-as-salience-is-an-information-partition.md]]-->
<!--    * [[10.1a1b_Conventions-as-CE-allows-for-"fair"-coordination-as-opposed-to-NE.md]]-->
<!---->
<!--### "Natural" (evolutionary) Salience-->
<!--- Skyrms's elimination of salience with evolutionary dynamics-->
<!--    - [[Symmetry-broken-by-chance-events-leads-to-correlated-equilibrium-in-iterated-Hawk-Dove-game]]-->
<!--    - [[@vandrunen2023]]-->
<!--    - [[@alberti2012]]-->
<!---->
<!--## Common knowledge and cognitive requirements for conventions-->

<!--## Arbitrariness and normativity-->
<!--* Convention space: mapping conventions theories across two dimensions ↓-->
<!--* [When and why Conventions cannot Be Social Institutions | Philosophia](https://link.springer.com/article/10.1007/s11406-019-00125-0) — 5 dimensions of conventions-->
<!---->
<!--@oconnor2019 draws two important distinctions: between conventions and social norms, and between more and less arbitrary conventions. First distinction means that not all behavioral regularities have normative force. For example, friends have a convention of meeting each Friday evening at a bar, and showing up is not what each of them strictly ought to do, for if someone does not come, it is fine for the rest of the friends. On the contrary, if two cars are driving on the same side of the road towards each other, the drivers are forced to swerve, for otherwise they might crash. They ought to swerve, for not only might one of them be fined but they might cause an accident. To clarify, as @bicchieri2005 points out, conventions are different from social norms in the relationship between self-interest and common interest. They coincide in the former and do not necessarily coincide in the latter. In the case of friends at a bar, there is no or little tension between selfand common interest, while in the case of driving cars there is. O'Connor stresses that conventions and norms are the poles of a continuum along which the former acquire normative force. ^60075e-->
<!---->
<!--The second distinction concerns the arbitrary and historically contingent nature of conventions that they “might have been otherwise”. -->
<!---->
<!--According to Lewis, this arbitrariness is one of the key distinguishing aspects of conventions. However, as @gilbert1992 points out in her critique of Lewis's work, not all possible solutions to a coordination problem are equally profitable for players. In cases where one way of coordinating is more preferred than another, convention will not be that arbitrary. In other words, arbitrariness is a feature of conventions that is a continuum between contingency and necessity. For example, signaling between vervet monkeys might well be modeled as a convention in the Lewisian sense of repeated behavioral patterns of solving coordination problems [cf. @harms2004; @skyrms2010]. However, this convention is not historically contingent in the sense of several possible solutions being equally profitable, for there are evolutionary constraints breaking the symmetry between multiple equilibria. Agents might be hardwired to certain strategies. This distinction, as O'Connor underlines, illuminates some conventions as more functional and others as more conventional.[^4]-->

<!--### Functionality vs. arbitrariness: "choosing" conventions-->
<!--* [CEEOL - Article Detail](https://www.ceeol.com/search/article-detail?id=694410)-->
<!--* [CEEOL - Article Detail](https://www.ceeol.com/search/article-detail?id=1007657)-->
<!---->
<!--## Evolution of social conventions-->
<!--Skyrms pioneered a path towards dynamic evolutionary models of coordination and convention-->
<!---->
<!--- 🔥 @lutz2023-->
<!---->
<!--- Harms's functional naturalisic account conventions-->
<!--    - [[@harms2004]]-->
<!--    - [[10.2a_Natural-signs-are-structured-world-affairs-that-convey-information-through-their-structure]]-->
<!--- gintis's view of social norms as correlation + ess-->
<!--    - [[private-property-equilibrium-generalizes-Bourgeois-equilibrium-by-endogenizing-costs]]-->
<!--- Guala's social institutions as evolved normatively-driven conventions-->
<!--    - [[11.1-Institutions-are-rules-in-equilibria-represented-symbolically-by-theoretical-terms.md]]-->
<!--        - [[11.1a_Normative-rules-can-transform-cooperation-problem-into-coordination-problem-by-increasing-delta-parameter.md]]-->
<!--            - [[11.1a1_Norm-triggering-signals-(cues)-might-differ-in-distinct-cultures.md]]-->
<!--            - [[11.1a2_Social-norms-might-be-supported-by-a-variety-of-different-mechanisms.md]]-->
<!--- the problem: 🔥 [[10.1b_Human-and-animal-conventions-differ-in-scope-of-actionable-signals.md]]-->
<!--- Naturalization of social conventions: connecting evolution and deliberation-->
<!--- [[@herrmann2021]]-->
<!---->
<!--# Chapter 2. Rules-in-equilibria theory of social institutions, which implicitly raises the problem of evolution of social conventions-->
<!--- Exposition of theory's components-->
<!--    - [[11.1b_Guala's-explanatory-components-for-theory-of-institutions.md]]-->
<!--    - [[10.1b1_Correlated-equilibrium-instead-of-Nash-highlights-the-variety-of-coordination-devices.md]]-->
<!--    - [[11.2-Institutions-have-etiological-and-teleological-functions.md]]-->
<!--    - [[11.2a-Institutions-are-there-for-they-incentivise-which-is-due-to-gene-culture-coevolution-and-not-only-natural-selection.md]]-->
<!--    - [[11.2b_Norms-both-make-behaviour-more-stable-and-predictable-and-introduce-new-behaviour-by-changing-game-payoffs.md]]-->
<!--- Criticism-->
<!--    - @hedoin2021-->
<!--- https://www.annalsfondazioneluigieinaudi.it/images/LII/R28201801_E-4284-Tieffenbach_Review.pdf-->
<!--- https://ndpr.nd.edu/reviews/understanding-institutions-the-philosophy-and-science-of-living-together/-->
<!--- Problem with correlation — [[003_correlation_as_core_problem]]-->
<!--- Problem with representation — [[006_problem-with-representation]]-->
<!--- Discussion and interim results-->
<!--    - [[11.3_Stable-and-efficient-social-contracts-evolved-due-to-within-group-AND-between-group-dynamics.md]]-->
<!--    - [[10.1a_hard-to-say-coordination-problems-or-socialization-evolved-first.md]]-->
<!---->
<!--# Chapter 3. Evolution of conventions as a problem of scope of actionable signals-->
<!--- [[evolutionary-stable-correlation]]-->
<!--    - <https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0136032>-->
<!--    - <https://www.frontiersin.org/journals/ecology-and-evolution/articles/10.3389/fevo.2023.1229093/full#B24>-->
<!--    - <https://mpra.ub.uni-muenchen.de/16926/>-->
<!--    - <https://philpapers.org/rec/TSACE>-->
<!--    - [[@cripps1991]]-->
<!--    - [[@kim2017]]-->
<!--    - [[@metzger2018]]-->
<!--    - [[@lee-penagos2016]]-->
<!--    - [[@foster1997]]-->
<!--- [[📝-(conf)-Formal-analysis-of-the-'scope-of-actionable-signals'-argument-in-rules-in-equilibria-theory-of-social-institutions]]-->
<!--- [[📝-Emergence-of-norm-driven-coordination-from-basic-signaling-games]]-->
<!--- [[10.2_Sender–reciever-systems-represent-both-within--and-between-organism-coordination.md]]-->
<!--    - [[10.2a_Natural-signs-are-structured-world-affairs-that-convey-information-through-their-structure.md]]-->
<!--- [[005_animal_conventions]]-->
<!--- [[10.1b1_Fitness-is-decoupled-from-utility-due-to-growth-of-social-group-size-and,-as-a-consequence,-weakening-of-individual-level-heritability-of-cultural-traits.md]]-->
<!--- :🔥[[@lacroix2020a]]-->

<!--# Conclusion: Implications for social ontology and sociological theory-->
<!--- [disser_test](/blog/disser_test)-->

# References
<!--- There are many equilibrium-based theories in the social science literature, stemming from Lewis's (1969} seminal work on conventions. See, for example, Schotter (1981}, Calvert (1998}, Grief (2006}, Binmore (2010}. The account presented here is close in spirit to Aoki's (2001, 2011} and Grief and Kingston's (2011} "hybrid" theories. The use of the hawk-dove game to represent animal and human conflicts over contested resources goes back to Maynard Smith's (1982} work on evolutionary game theory. See also Sugden (1986} and more recently Gintis (2007}. On correlated equilibria see Aumann (1974, 1987}, as well as Vanderschraaf (1995, 1998, 2001} and Gintis (2007, 2009}. The theory of institutions as rules in equilibrium has been discussed in a symposium recently published in the Journal of Institutional Economics. The commentaries of Aoki (2015}, Binmore (2015}, Sugden (2015}, and Smith (2015}, in particular, address some of the issues discussed in this chapter. Hindriks and Guala (2015b} — location: []() ^ref-37783-->

<!--Bicchieri (2001) discusses in depth the problem of belief formation in coordination games. The idea that society is a gigantic coordination game and that social institutions help people find a solution is already in Hume (1748}, but has been reformulated in gametheoretic fashion by philosophers and social scientists like Lewis (1969}, Ullmann-Margalit (1977}, Schotter (1981}, Sugden (1986}, Skyrms (1996, 2004}, Binmore (1998, 2005}. Knight (1992} discusses the coordinating function of institutions, as well as the competitive aspect of games such as battle of the sexes. The puzzle of cooperation in prisoner's dilemma experiments has generated an enormous literature, but explanations based on social norms are quite common-see for instance UllmannMargalit (1977}, Sober and Wilson (1998}, Binmore (2005}, Bicchieri (2006}, Gintis (2009}. Functional explanations have suffered from a bad press in social science as a consequence of Jon Elster's (1983} influential critique. Pettit's (1996} distinction between explanations of emergence and explanations of resilience is meant to resist this critique. On equilibrium explanations, finally, see Sober (1983 -->

<!--**Core Components & Key Features:**-->
<!---->
<!--1. **Population Dynamics:** EGT models are typically framed as populations of individuals, each playing a specific strategy. The population’s composition changes over time according to a defined selection rule – most commonly, *replicator selection*, where strategies with higher average payoffs in a given environment become more prevalent in the population.-->
<!---->
<!--2. **Payoff Matrices & Fitness:** Strategies are represented by payoff matrices, analogous to those in standard game theory. However, instead of representing a single player’s payoff, the matrix represents the *fitness* of a strategy given the strategies employed by the entire population. Fitness is often interpreted as the average reproductive success or survival rate associated with that strategy.-->
<!---->
<!--3. **Replicator Dynamics:** The core of EGT is the replicator equation, which describes how the frequency of each strategy in the population changes over time. This equation is based on the idea that strategies with higher fitness will, on average, produce more offspring, leading to an increase in their proportion within the population. -->
<!---->
<!--4. **Multiple Equilibria:** A crucial characteristic of EGT is the potential for multiple evolutionary stable strategies (ESS). An ESS is a strategy that, if adopted by a majority of the population, cannot be invaded by any other strategy. This contrasts with the single Nash equilibrium often found in traditional game theory.-->
<!---->
<!--5. **Beyond Rationality:** EGT acknowledges that agents are not necessarily perfectly rational. Instead, it focuses on the *evolutionary* consequences of strategic interactions, recognizing that strategies can emerge and persist through selection pressures, even if they are not individually optimal.-->
<!---->
<!--**Distinction from Traditional Game Theory:**-->
<!---->
<!--| Feature           | Traditional Game Theory | Evolutionary Game Theory |-->
<!--|--------------------|--------------------------|--------------------------|-->
<!--| **Agent Assumption** | Rational, self-interested | Subject to evolutionary selection |-->
<!--| **Focus**          | Static equilibrium        | Dynamic population change |-->
<!--| **Selection**      | Not explicitly modeled    | Central to the model      |-->
<!--| **Equilibria**     | Single Nash equilibrium    | Multiple ESS possible      |-->
<!---->
<!---->
<!---->
<!--**Applications:**-->
<!---->
<!--EGT has been applied to a wide range of phenomena, including:-->
<!---->
<!--*   Animal behavior (e.g., cooperation in social insects, mate choice)-->
<!--*   Economic phenomena (e.g., market competition, innovation)-->
<!--*   Social science (e.g., voting behavior, cultural evolution)-->
<!---->
<!---->
<!---->
<!--**References (for further reading - this is a starting point):**-->
<!---->
<!--*   Nowak, Ronald A., and John E. Smith. "Evolutionary Dynamics: Algorithms, Models, and Applications." *Princeton University Press*, 2007.-->
<!--*   Segal, David. *Evolutionary Game Theory*. *Cambridge University Press*, 2001.-->
<!---->
 <!--@sugden1995 emphasized the critical function of context-specific salience in establishing common knowledge and resolving coordination problems. Salience, stemming from shared community membership and cultural context, operates as a *correlating device*. It correlates expectations of agents regarding each other's next actions and helps to choose an optimal strategy. Salience enables agents to achieve a common understanding and coordinate actions toward a specific equilibrium. In situations with multiple equilibria, salience provides a focal point, influencing individual attention and expectations, thereby disrupting symmetry and facilitating coordination – as exemplified in Schelling’s coordination games where individuals converge on the most intuitively salient option. Crucially, Sugden argued that common understanding, built upon shared modes of reasoning within a community, is constitutive of salience. Shared cultural backgrounds, experiences, and cognitive frameworks among community members influence what is perceived as salient, allowing individuals to anticipate and coordinate with others’ expectations.-->
