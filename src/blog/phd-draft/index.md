---
id: index
aliases: []
tags: []
date: "26.04.2025"
generate_toc: true
subtitle: phd thesis work-in-progress
title: "Ontic reference in formal social ontology: evolution of social institutions from \"animal conventions\" with niche construction"
---

<!--# Introduction-->
<!--What is a convention? As @goodman1989 notes, this term is intricately ambiguous.-->
<!--Social conventions, the unwritten rules that govern our interactions, present a fundamental puzzle in understanding social order. How do shared patterns of behavior emerge and persist within a population when no explicit agreement dictates them? The term "convention" itself carries a dual meaning, referring both to the ordinary and expected, and to the artificial and optional, highlighting the complexity of this phenomenon 1. Philosophers have long been interested in conventions, recognizing their foundational role in various aspects of social life, including language, law, and morality 1.-->
<!--* [[@rescorla2019] ]-->

# **Chapter 1.** Social conventions: Hume, Lewis and game theory
The tradition of understanding social coordination as a source of social order is historically rich. Aristotle grounded social conventions in human nature and the pursuit of *eudaimonia*, or flourishing. He viewed humans as "political animals" who naturally form communities to achieve collective well-being. Justice and virtue, central to his ethics, were seen as the basis for political order. Unlike later followers of the social contract theory, Aristotle saw social organization as intrinsic to human rationality rather than a deliberate agreement [@aristotle1998].

Hobbes reimagined social conventions as constructs invoked by humanity’s violent "state of nature." He argued that self-preservation drives individuals to surrender freedoms to an absolute sovereign via a social contract resulting from explicit *agreement* [@hobbes2016]. Conventions thus arise from fear and rational self-interest, not innate sociability.

According to @epstein2018, a notion of *convention* was first explicitly used as an alternative to agreement by Pufendorf [-@pufendorf1673], to refer to language and law. He synthesized Hobbesian ideas with theological natural law. While agreeing that humans are self-interested, he attributed the "law of sociality" to divine mandate, requiring peaceful coexistence despite innate corruption. For Pufendorf, natural law obligates humans to form civil societies, with God as the ultimate author of social conventions. This introduced a moral dimension absent in Hobbes’s instrumentalist framework, suggesting that conventions are not merely utilitarian but also morally justified. His point was that conventions do not need to be explicitly agreed to and might exist and work without their intentional design. This intuition has remained largely  unchanged.

Hume’s theory of social conventions, articulated most prominently in *A Treatise of Human Nature* [@hume2003] and *An Enquiry Concerning the Principles of Morals* (1751), offers a groundbreaking empiricist account of how social norms and institutions emerge organically from human interaction rather than rational design or divine mandate. Hume’s analysis hinges on three core premises: 

- the role of custom in shaping behavior
- the centrality of mutual benefit in solving coordination problems
- the artificiality of conventions

These are seen as products of collective habit rather than explicit agreement. The components form the scaffolding of his theory, which bridges psychology, ethics, and political philosophy.

Hume’s empiricist framework posits that human understanding arises from sensory impressions and ideas derived from them. This extends to social behavior: conventions emerge not from reason but from repeated experiences that cultivate habits. For instance, Hume’s iconic example of two individuals rowing a boat illustrates how synchronization arises through trial and error, not prior negotiation:

> “Two men who pull at the oars of a boat, do it by an agreement or convention, tho’ they have never given promises to each other”[@hume2003]. 

However, @schliesser2024 stipulates that this kind of coordination is not backed by "Humean conventions" as they, according to Hume himself[^humean-conventions], require "positive social externality", whereas two burglars could effectively row away from a crime scene. We will not focus on this morally-driven notion of conventions.

[^humean-conventions]: As @hume1998 writes, "It has been asserted by some, that justice arises from human conventions, and proceeds from the voluntary choice, consent, or combination of mankind … if by convention be meant a sense of common interest; which sense each man feels in his own breast, which he remarks in his fellows, and which carries him, in concurrence with others, into a general plan or system of actions, which tends to public utility; it must be owned, that, in this sense, justice arises from human conventions. For if it be allowed (what is, indeed, evident) that the particular consequences of a particular act of justice may be hurtful to the public as well as to individuals; it follows, that every man, in embracing that virtue, must have an eye to the whole plan or system, and must expect the concurrence of his fellows in the same conduct and behaviour. Did all his views terminate in the consequences of each act of his own, his benevolence and humanity, as well as his self-love, might often prescribe to him measures of conduct very different from those, which are agreeable to the strict rules of right and justice …". @schliesser2024 notes that positive social externality is a requirement for a purely "Humean" convention.

Over time, repeating patterns solidify into conventions because they resolve practical problems (coordinating labor, establishing property rights) while minimizing friction. Custom, as Hume writes, “renders our experience useful to us” by creating stable expectations about others’ behavior, even in the absence of formal rules [@hume2003] . This emphasis on habit challenges rationalist theories like Hobbes’s by showing how conventions evolve *unconsciously* through iterative adjustments.

Hume highlights four key features of conventions:

- Mutual benefit: all parties gain from adhering to the convention (e.g., synchronized rowing ensures progress; standardized currency facilitates trade)
- Multiple potential solutions: different solutions could theoretically work (e.g., rowing fast or slow), but consistency matters more than the specific choice
- Unplanned agreement: conventions develop spontaneously through “a slow progression” of trial and error, not deliberate contract
- Reciprocity: adherence depends on the expectation that others will reciprocate, creating a self-reinforcing cycle of trust.

For Hume, conventions like property rights arise because humans recognize the “common interest” in stabilizing possessions to avoid conflict, even if their natural inclinations lean toward self-interest [@hume1998]. This pragmatic focus distinguishes his theory from moralistic accounts, framing conventions as tools for managing inherent human partiality.

Hume classifies conventions as *artificial virtues*, social constructs developed to counteract humanity’s “limited generosity”. Unlike natural virtues like benevolence, which arise instinctively, conventions like justice or promise-keeping require cultivation. Their artificiality, however, does not make them arbitrary. Instead, they gain normative force through collective sentiment: individuals approve of conventions that promote social utility, and disapproval of violations strengthens adherence over time. This process explains how conventions acquire moral weight, transforming into norms that feel binding even when rational self-interest might suggest defiance. Experimental studies inspired by Hume’s (or rather Lewis's [-@lewis2008]) work confirm that conventions stabilize behavior even when incentives to defect arise, underscoring the interplay of habit and normativity [@guala2010].

Hume’s theory diverges sharply from social contract models. While Hobbes rooted conventions in deliberate agreements to escape chaos or secure rights, Hume dismissed the notion of a primordial “state of nature” requiring such pacts. Instead, he argued that conventions emerge incrementally from lived experience, reflecting his broader skepticism toward rationalist abstractions. His framework also anticipated modern game theory, particularly David Lewis’s analysis of conventions as coordination equilibria [@lewis2008], though Hume placed greater emphasis on psychology.  

Crucially, Hume’s account bridged descriptive and normative domains. By showing how conventions evolve from practical needs to moral norms, he offered a naturalistic explanation for social order that avoids appeals to divine law or metaphysical necessity. This aligns with his rejection of causation as anything beyond observed regularity, reinforcing his view that human institutions are contingent products of custom rather than eternal truths.

After Hume, philosophers in the Scottish Enlightenment held that social order is an emergent product of individuals' interactions, however, no such order has been specifically intended by individuals. As @ferguson1980 wrote, “nations stumble on establishments which are, indeed, the result of human action, but not the execution of any human design”. Afterwards, however, the study of conventions has quieten. 

Lewis has revived and operationalized Hume’s insights into a theory of conventions using game theory and treating conventions as equilibria sustained by common knowledge and precedent. While Hume emphasized historical contingency and gradual emergence, Lewis imposed stricter criteria of rationality and mutual expectations [@lewis2008]. He saw conventions as solutions to coordination problems, a class of problem in game theory (a branch of mathematics dealing with strategic behavior) which require two or more agents to align their actions to produce a jointly optimal outcome. In the next section, we will tour game theory and its main concepts before getting back to Lewis's theory of conventions as game theory will be crucially important in the remainder of the thesis.

## Game theory background
Game theory is a mathematical framework used to analyze situations of strategic interaction between rational decision-makers. Originally developed by John von Neumann and Oskar Morgenstern in their seminal work *Theory of Games and Economic Behavior* [@morgenstern1944], game theory has since evolved to encompass a wide range of applications in economics, biology, political science, and sociology [@gintis2009; @osborne2004]. It provides the tools to study how individuals or groups make choices when their outcomes depend not only on their own decisions but also on the decisions of others. The fundamental building blocks of game theory are games, players, strategies, payoffs, and equilibria [@zamir2013].

A strategic game in game theory is defined as a formal model $G = (N, S, P)$ where:

- $N$ is a set of players
- $S = (S_1, S_2, \dots, S_n)$ is strategy sets of each player, where $S_i$ is the set of strategies available to player $i$
- $P = (P_1, P_2, \dots, P_n)$ specifies the payoff functions, where $P_i: S_1 \times S_2 \times \dots S_n \rightarrow \mathbb{R}$ gives the utility for player $i$ given the chosen strategy profile [@myerson1991].

A strategy $s_i \in S_i$ is a complete plan of action a player will follow in any situation they might face within the game. Payoffs represent the rewards or utilities that players receive based on the combination of strategies chosen by all involved.

One of the central concepts in game theory is equilibrium, where no player has an incentive to unilaterally change their strategy given the strategies of others. The most well-known equilibrium concept is the Nash equilibrium (NE), introduced by John Nash in the early 1950s [@nash1950]. A strategy profile $(s_1^*, s_2^*, \dots, s_n^*)$ forms a Nash equilibrium if for every player $i$, the following condition holds:

$$
P_i(s_i^*, s_{-i}^*) \geq P_i(s_i, s_{-i}^*) \quad \forall s_i \in S_i.
$$

Here,

- $P_i$ is a payoff function for player $i$
- $s_i^*$ is a strategy chosen by player $i$ at equilibrium
- $s_{-i}^*$ is a combination of strategies chosen by all other players except player $i$
- The inequality states that player $i$ cannot increase their payoff by unilaterally changing their strategy from $s_i^*$ to any other available strategy $s_i$.

Shortly after Nash’s work, Robert Aumann introduced the concept of *correlated equilibrium* (CE) in 1974 [@aumann1974]. This generalization of Nash equilibrium allows players to coordinate their strategies through signals from a trusted mediator. Unlike Nash equilibrium, where players act independently, CE enables communication or correlation of strategies, capturing coordination through shared information. In a CE, a random signal suggests a strategy to each player, and players follow the recommendation if it is in their best interest to do so. Formally, a correlated equilibrium satisfies:

$$
\sum_{s'_{-i}} q(s_i, s'_{-i}) \cdot [P_i(s_i, s'_{-i}) - P_i(s'_i, s'_{-i})] \geq 0 \quad \forall s_i, s'_i.
$$

Here,

- $q(s_i, s'_{-i})$ represents the probability that the mediator recommends strategy $s_i$ to player $i$ and $s'_{-i}$ to the other players
- $P_i(s_i, s'_{-i})$ is the payoff to player $i$ when they play $s_i$ and the others play $s'_{-i}$
- The inequality ensures that the expected payoff from following the recommendation is at least as great as from deviating.

As Roger Myerson has reportedly observed, 

> "If there is intelligent life on other planets, in a majority of them, they would have discovered correlated equilibrium before Nash equilibrium" [@solan1999]. 

CE can be a more natural concept than Nash equilibrium, as its mathematical simplicity and reliance on cooperation make it easier to discover. Myerson argued that humanity's prioritization of Nash equilibrium may have been an accident of history rather than a reflection of its fundamental importance. In societies or civilizations where cooperative behavior is emphasized or external mediators are prevalent, CE could emerge as a more intuitive starting point for understanding strategic interactions.

In the realm of evolutionary biology, John Maynard Smith introduced the concept of *evolutionarily stable strategy* (ESS) in 1973 [@maynard1973]. An ESS is a strategy $s^*$ that is robust against invasion by mutant strategies and satisfies the following condition:

$$
P(s^*, s^*) > P(s', s^*) \quad or \quad [P(s^*, s^*) = P(s', s^*) \quad and \quad P(s^*, s') > P(s', s')].
$$

Here,

- $P(s^*, s^*)$ is the payoff when both the incumbent and the invader use strategy $s^*$.
- $P(s', s^*)$ is the payoff when the invader uses strategy $s'$ while the incumbent sticks to $s^*$.

Beyond Nash, CE and ESS, game theory has explored other equilibrium concepts, including subgame perfect equilibrium, trembling hand perfect equilibrium, and proper equilibrium, among others. These refinements address limitations of the NE, particularly in dynamic and extensive-form games. We will only focus on CE and ESS in the current thesis. 

<!--Notable equilibrium refinements include:-->
<!---->
<!--- *Subgame Perfect Equilibrium*: introduced by Selten [-@selten1965], it ensures rational behavior at every stage of a dynamic game by requiring equilibrium strategies in every subgame. It refines NE by eliminating non-credible threats and is particularly relevant in sequential games.-->
<!---->
<!--- *Trembling Hand Perfect Equilibrium*: proposed also by Selten [@selten1975], it accounts for the possibility of small, unintended mistakes (or trembles) by requiring that strategies remain optimal even if there is a slight probability of error. This refinement helps to eliminate equilibria that are not robust to slight deviations.-->
<!---->
<!--- *Proper Equilibrium*: introduced by Myerson [-@myerson1978], this concept strengthens trembling hand equilibrium by further penalizing less likely mistakes. It ensures that less probable errors are assigned proportionally smaller probabilities, reinforcing stability.-->
<!---->
<!--- *Sequential Equilibrium*: developed by Kreps and Wilson [@kreps1982], this refinement addresses the problem of imperfect information by combining strategies with beliefs about what has happened earlier in the game. It is particularly useful in signaling games and dynamic strategic interactions.-->
<!---->
<!--- *Perfect Bayesian Equilibrium*: extending the Bayesian framework, it requires that players update their beliefs consistently using Bayes’ rule and choose optimal strategies given their beliefs. It is widely applied in games with incomplete information [@fudenberg1991].-->
<!---->
<!--These equilibrium refinements aim to ensure stability and plausibility in strategic settings by accounting for dynamic aspects, imperfect information, and potential errors.-->

Coordination and cooperation problems are fundamental challenges in social philosophy since Hobbes [-@hobbes2016], and game theory has been an indispensable tool for tackling these problems due to its clarity and rigor.

- *Coordination problems* arise when individuals or groups need to choose between multiple possible equilibria, creating ambiguity about which solution will be selected. These problems are central to strategic interaction because they reflect situations where all parties would benefit from making compatible choices but may struggle to agree on a single option. 

- *Cooperation problems*, on the other hand, highlight the conflict between individual rationality and collective benefit, where mutual cooperation yields a better outcome for all, but self-interest may lead to suboptimal results. Such challenges often require mechanisms to facilitate coordination or encourage cooperation, including social conventions or equilibrium selection techniques. Consequently, equilibrium concepts are fundamentally linked to coordination and cooperation problems because they model how rational agents arrive at stable solutions given others' strategies.

Examples of coordination and cooperation problems include classic games like the Battle of the Sexes and the Prisoner's Dilemma. In the former, a husband and a wife coordinate on choosing a leisure activity where everyone is satisfied with the choice, and in the latter, two prisoners independently either defect or cooperate with each other by uncovering their partner in crime to an officer. The payoff matrices of these games are shown below[^payoff-matrix].

[^payoff-matrix]: A payoff matrix is a mathematical representation that shows the possible outcomes for each combination of strategies chosen by the players. Achieving coordination often requires stabilizing communication to arrive at mutual agreement, especially when different individuals or groups have conflicting preferences. This need for a reliable mechanism to resolve coordination issues is crucial in many social contexts.

<!--Doc representations-->
<!--$$-->
<!--\begin{figure}-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!--& Football & Ballet\\-->
<!--\hline-->
<!--Football & 2,1 & 0,0 \\-->
<!--\hline-->
<!--Ballet & 0,0 & 1,2 \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{Battle of sexes}-->
<!--\end{figure}-->
<!--$$-->

<!--Web-representations-->
$$
\begin{array}{|c|c|c|}
\hline
& Football & Ballet\\
\hline
Football & 2,1 & 0,0 \\
\hline
Ballet & 0,0 & 1,2 \\
\hline
\end{array}
$$
**Battle of the Sexes**

$$
\begin{array}{|c|c|c|}
\hline
& Cooperate & Defect \\
\hline
Cooperate & -1,-1 & -3,0 \\
\hline
Defect & 0,-3 & -2,-2 \\
\hline
\end{array}
$$

**Prisoner's Dilemma**

These matrices model real-world problems such as social dilemmas and negotiations. For instance, the Battle of the Sexes often represents situations where partners must choose between competing preferences, while the Prisoner's Dilemma models the challenge of mutual cooperation versus self-interest in scenarios like arms races or public goods provision.

To illustrate the practical difference of equilibrium concepts in solving coordination problems, let us consider the Battle of the Sexes with pure Nash, mixed Nash and CE.

In pure Nash, two pure strategy equilibria exist: both players attend either Ballet or Football. These equilibria ensure perfect coordination but are inherently unfair, as one player always prefers the chosen event over the other. 

A mixed strategy Nash equilibrium also exists, where players randomize their choices independently, but it risks miscoordination. Let the Husband choose Ballet with probability $p$ and Football with $1-p$, and let the Wife choose Ballet with probability $q$ and Football with $1-q$. Using the *indifference principle* according to which a player randomizes her strategies in a way that the opponent is indifferent between their own available strategies, we calculate probabilities:

1. For the Husband to be indifferent, the Wife's mixed strategy must make his expected payoff from Ballet equal to that from Football:
   $$2q + 0(1-q) = 0q + 1(1-q) \implies 2q = 1 - q \implies q = \frac{1}{3}$$

2. For the Wife to be indifferent, the Husband's mixed strategy must make her expected payoff from Ballet equal to that from Football:
   $$1p + 0(1-p) = 0p + 2(1-p) \implies p = 2(1-p) \implies p = \frac{2}{3}$$

Thus, in the mixed strategy Nash equilibrium:

- The **Husband** chooses Ballet with probability $p = \frac{2}{3}$ and Football with $1-p = \frac{1}{3}$.
- The **Wife** chooses Ballet with probability $q = \frac{1}{3}$ and Football with $1-q = \frac{2}{3}$.

The expected payoffs for both players in this equilibrium are:

- **Husband**: $2q + 0(1-q) = 2\left(\frac{1}{3}\right) + 0 = \frac{2}{3}$,
- **Wife**: $1p + 0(1-p) = 1\left(\frac{2}{3}\right) + 0 = \frac{2}{3}$.

This mixed strategy equilibrium represents a compromise balancing fairness and coordination through randomization, albeit less efficient than pure Nash equilibria due to inherent miscoordination risks[^no-mixed].
 
[^no-mixed]: Epistemic game theorists contend that there is no correlate of mixed-strategy equilibrium when viewed from epistemic (or knowledge) point of view [@perea]. I agree with them and only talk about it here for the purposes of comparison with CE.

In contrast, CE utilizes public signals to coordinate actions effectively. For instance, a public signal such as a coin flip can recommend both players attend Ballet or Football equiprobably. This mechanism eliminates miscoordination and ensures equal expected payoffs for both players (1.5 each). CE helps agents achieve higher payoffs and fairness compared to both pure and mixed Nash equilibria by leveraging shared randomness or communication.

To demonstrate how a signal affects the payoff structure, we add a new strategy *Follow Signal (FS)*, where players choose based on a fair coin flip (Heads = Ballet, Tails = Football). The payoffs depend on actual coordination, not just expectations: we can calculate expected payoffs when one player uses FS and the other does not.

FS (H) vs Ballet (W):  

- Signal = Tails (50%): H chooses Football, W stays at Ballet → $(0, 0)$.  
- Expected payoff: $0.5 \times (2, 1) + 0.5 \times (0, 0)  =  (1, 0.5)$.  

FS (H) vs. Football (W):

- Signal = Heads (50%): H chooses Ballet, W stays at Football → $(0, 0)$.  
- Signal = Tails (50%): Both choose Football → $(1, 2)$.  
- Expected payoff: $0.5 \times (0, 0) + 0.5 \times (1, 2)  =  (0.5, 1)$.  

Thus, the augmented game matrix becomes:  

<!--Doc representation-->
<!--$$-->
<!--\begin{figure}-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|c|}-->
<!--\hline-->
<!-- & Ballet (W) & Football (W) & FS (W) \\-->
<!--\hline-->
<!--Ballet (H) & (2, 1) & (0, 0) & (1, 0.5) \\-->
<!--\hline-->
<!--Football (H) & (0, 0) & (1, 2) & (0.5, 1) \\-->
<!--\hline-->
<!--FS (H) & (1, 0.5) & (0.5, 1) & (1.5, 1.5) \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\end{figure}-->
<!--$$-->
<!---->

<!--Web-representation-->
$$
\begin{array}{|c|c|c|c|}
\hline
 & Ballet (W) & Football (W) & FS (W) \\
\hline
Ballet (H) & (2, 1) & (0, 0) & (1, 0.5) \\
\hline
Football (H) & (0, 0) & (1, 2) & (0.5, 1) \\
\hline
FS (H) & (1, 0.5) & (0.5, 1) & (1.5, 1.5) \\
\hline
\end{array}
$$

The strategy profile of $(FS, FS)$ represents a Nash equilibrium because neither player has an incentive to deviate. If a Husband switches to Ballet, he would only receive $1$, a decrease from his current payoff of $1.5$ when the Wife remains at $FS$. Similarly, if the Wife switches to Football, she would receive only $1$, a decrease from her current payoff of $1.5$ when the Man stays at $FS$. Since no profitable deviation exists for either player, the strategy profile **$(1.5, 1.5)$** is stable. Thus, the CE strategy is as an NE strategy of an augmented game. The difference is that CE are simpler to compute than NE and model real-world scenarios where external signals (e.g., traffic lights) guide decisions. In summary, CE expand the solution space of a game, offering improvements over Nash equilibria when players can leverage a coordination device.

Getting back to coordination problems, @oconnor2019 distinguishes two classes of them:

- correlative problems (same choice to coordinate)
- complementary problems (different choices to coordinate)

In correlative coordination problems, agents need to converge on the same choice to coordinate successfully. For example, consider a driving game, where two players drive towards each other and each can choose the left or right side to drive on. If they both are on the same side and no one swerves, they might crash, and if each of them chooses a different side, they will stay safe. One important feature of this and other coordination problems is arbitrariness, meaning that it does not matter on what side both players would converge. Instead, what matters is that they either coordinate by choosing the same action, for example, swerving to the right. 

<!--Doc representation-->
<!--$$-->
<!--\usepackage{tikz}-->
<!--\begin{tikzpicture}[scale=1]-->
<!--% Draw the two-lane road (one lane each direction)-->
<!--\fill[gray!30] (-2.5,0) rectangle (2.5,6); % road base-->
<!--% Lane markings (center line)-->
<!--\draw[white, dashed, line width=1pt] (0,0) -- (0,6);-->
<!--% Left car (driving upwards, initially left lane, swerving right)-->
<!--\fill[blue] (1.1,1) rectangle (1.6,2); % car body-->
<!--% Right car (driving downwards, initially right lane, swerving right from its perspective)-->
<!--\fill[red] (1.1,5) rectangle (1.6,4); % car body-->
<!--\draw[->, thick, red] (1.55,4.5) .. controls (0.8,3.5) .. (0.2,2.5); % swerving arrow to right lane (middle lane)-->
<!--% Labels-->
<!--\node[blue] at (1.35,0.5) {Swerve right};-->
<!--\node[red] at (1.35,5.5) {Swerve right};-->
<!--\end{tikzpicture}-->
<!--\end{document}-->
<!--$$-->
<!---->

On the game matrix, it is represented as two non-unique equilibria. It means that either of them solves the coordination problem.

<!--Doc representation-->
<!--$$-->
<!--\begin{figure}-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!--& Swerve \quad left & Swerve \quad right \\-->
<!--\hline-->
<!--Swerve \quad left & 1,1 & -1,-1 \\-->
<!--\hline-->
<!--Swerve \quad right & -1,-1 & 1,1 \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{Driving game}-->
<!--\end{figure}-->
<!--$$-->

<!--Web representtion-->
$$
\begin{array}{|c|c|c|}
\hline
& Swerve \quad left & Swerve \quad right \\
\hline
Swerve \quad left & 1,1 & -1,-1 \\
\hline
Swerve \quad right & -1,-1 & 1,1 \\
\hline
\end{array}
$$

Complementary coordination problems, as opposed to correlative ones, require from agents different actions, or strategies, to coordinate successfully. As @oconnor2019 points out, division of labor or resources is an example of this class of games. For instance, two roommates want to organize a party and invite guests. To proceed, they need to tidy up the house and order pizza delivery. If they both do the cleaning, there will be no food when the guests come, and if they both order pizza delivery, they will have plenty of food but be embarrassed by the mess at the house.

<!--Doc representation-->
<!--$$-->
<!--\begin{figure}-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!--& Order & Tidy \\-->
<!--\hline-->
<!--Order & -1,-1 & 1,1 \\-->
<!--\hline-->
<!--Tidy & 1,1 & -1,-1 \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{Party game}-->
<!--\end{figure}-->
<!--$$-->

<!--Web representation-->
$$
\begin{array}{|c|c|c|}
\hline
& Order & Tidy \\
\hline
Order & -1,-1 & 1,1 \\
\hline
Tidy & 1,1 & -1,-1 \\
\hline
\end{array}
$$

The only difference between the two classes of coordination problems is either choosing same or different actions to coordinate successfully.

Coordination problems and conventions are intrinsically linked as former ones emerge when individuals or groups require aligned action for mutual benefit, necessitating communication and shared understanding to stabilize interactions. *Conventions function as a mechanism for predictable coordination by encapsulating mutual expectations*, thereby reducing ambiguity and establishing stable behavioral patterns within a social context. David Lewis’s theory of conventions as coordination equilibria, explored in the subsequent section, provides a central treatment of this relationship.

## Intellectual influences of Lewis's "Convention"
The intellectual atmosphere in which Lewis’s *Convention* was developed was mostly engaged with questions of language, meaning, and social behavior. Several intellectual movements and concerns shaped the development of his theory.

In the mid-20th century, the interest in influence of social practice on linguistic meaning kept growing, as philosophers like Quine [-@quine1960] and Wittgenstein [-@wittgenstein] argued that meaning arises from shared use within a community. Wittgenstein highlighted that language's meaning emerges through public usage, rather than inherent semantic properties. For instance, "game" has no fixed definition but derives its meaning from the activities associated with it. Building on this tradition, Lewis sought to explain how linguistic conventions form, stabilize, and persist in communities by providing a systematic account of their development over time. By conceptualizing meaning as coordinated behavior, Lewis laid a foundation for viewing language as a socially orchestrated activity rather than an innate or purely individualistic construct. Consequently, communication relies not on objective meanings but on mutual expectations about usage, emphasizing convention's crucial role in language [@lewis1969].

The Zeitgeist of analytic philosophy in the 1960s grappled with the legacy of Logical Positivism, which, through formal logic and empirical verification, defined meaning based on analytically true statements or verifiable empirical claims [@godfrey-smith2003]. However, by the 1960s, critiques from Quine, Putnam, and others challenged this framework, particularly the distinction of analytic/synthetic truths, the former being true in virtue of their meaning and the latter in virtue of their relationship to the world. 

Quine rejected traditional notions of necessity and analyticity, asserting ontological commitments are embedded within theories and language [@quine1951; @quine1960; @quine1969], emphasizing empirical evidence and pragmatic considerations in shaping beliefs. His critique of analyticity underscored the revisability of language, highlighting conventions as mutable rather than fixed. Putnam’s “Twin Earth” thought experiment[^twin-earth] further developed these ideas, advocating semantic externalism—the view that word meaning depends on external facts, not solely on mental states—challenging internalist accounts of meaning and emphasizing the role of external factors in linguistic practices. Consequently, conventions are understood as influenced by contextual and environmental factors, moving beyond purely internal or necessary determinations.

[^twin-earth]: On a planet identical to Earth in almost all respects but featuring water composed of XYZ rather than H₂O, inhabitants use the term "water" yet refer to different substance. According to Putnam, this illustrates that psychological states alone do not determine meaning; external factors like chemical composition and environmental acquisition influence linguistic reference. His assertion is encapsulated by his famous statement: "meanings just ain't in the head". This will be crucially important for us later in the discussion of the problem of ontic reference within the study of evolution of social conventions.

Lewis’s theory of convention was a way to address this intellectual shift by emphasizing the contingent nature of meaning. Rather than being dictated by any necessity, conventions arise as arbitrary but stable solutions to coordination problems, reflecting a more pragmatic and flexible understanding of linguistic meaning and social practices. It highlights that even the most strict customs started as contingent behavioral patterns which might have been otherwise but have been amplified with each iteration. This perspective is deeply rooted in Quinean ideas about language as being subject to revision, adaptation, and negotiation within a community or culture.

Another major philosophical concern that Lewis addressed was the ontology of social rules and norms, profoundly influenced by Hume's work. Lewis developed Hume's idea of conventions emerging and persisting even in the absence of centralized enforcement. Lewis argued that conventions are self-reinforcing: once established, individuals have no reason to deviate as long as others continue to conform. The major deviation from Hume's thought was an accent on rationality of agents as the source of such conformity, whereas Hume emphasized psychological custom. 

An example of this can be seen in the development of money as a medium of exchange. Initially, various objects like cattle, shells or metal coins served as currency. Over time, paper money became widely accepted, not because of any intrinsic value, but because people expected others to accept it in transactions. This insight was later influential in discussions of spontaneous order and decentralized systems in political philosophy and economics, particularly in the work of Hayek [@hayek1973]. By explaining conventions as natural outcomes of repeated social interactions, Lewis contributed to a broader understanding of how norms, institutions, and linguistic practices can arise organically without explicit design or coercion.

Furthermore, Hume’s skepticism about moral realism, a position stating that objective moral norms exist, played a role in shaping Lewis’s view of conventions as arbitrary yet stable[^alexander]. Hume argued that moral distinctions are not grounded in objective properties but in human sentiment and social conditioning. Similarly, Lewis contened that conventions are not determined by any intrinsic necessity but arise contingently through social practices. For instance, the choice of driving on the right or left side of the road is arbitrary, yet once established, it becomes self-reinforcing because all individuals benefit from adherence to the convention. This reflects Hume’s broader thesis that social order emerges not from absolute principles but from shared expectations and learned behaviors.

[^alexander]: The emergence of objective yet relative moral norms in accordance with Lewisian approach and rigor was developed by @mackenzie2007, which echoes "arbitrary yet stable" notion of instrumental conventions.

If the problems of meaning, language and conventionality served as the issue Lewis wanted to attack and Hume's notion of convention was resource to build upon, he still needed a tool to construct his argument with. He found it in game theory [@vonneumann1944] and, in particular, in Schelling’s approach to strategic interaction in "mixed motive" games [@schelling1980]. 

Game theory offered a structured mathematical framework for analyzing strategic interactions among individuals conceived as rational actors. Lewis's engagement with game theory and decision theory was facilitated by this prevailing intellectual trend. The emphasis on formal models and rational choice provided a common language and conceptual framework for discussing social behavior across diverse disciplines, making it a natural progression for a philosopher like Lewis to explore these powerful analytical tools in his own work.

Schelling’s work represented a significant departure from prevailing game theory’s emphasis on zero-sum conflict (when there is always a winner and a loser), recognizing that real-world interactions frequently exhibit “mixed motives” or simultaneous conflicting and converging interests. He critiqued the limitations of purely mathematical analysis of strategic interaction and advocated for empirical research to illuminate the conditions shaping behavior, specifically considering opportunities for communication and the presence of attractive alternatives. This expanded scope featuring both conflict and cooperation included the very phenomena of cooperation and coordination that drew Lewis's attention in the context of the problem of social conventions.

Schelling argued that conflict and cooperation are not necessarily opposing forces but are deeply intertwined in strategic interactions. One of his key contributions was the concept of *credible commitment*, where the ability to commit to a particular strategy in advance can influence an opponent’s decisions [@schelling1960, p. 22]. A fundamental aspect of this is *self-binding*, where a player deliberately restricts her own options to strengthen bargaining position.

Another crucial insight was the concept of *focal points* (also known as Schelling points), which are solutions that individuals naturally gravitate toward in coordination games without explicit communication. Schelling demonstrated this through experiments where participants, when asked to choose a meeting place in New York City without coordination, overwhelmingly selected noon at Grand Central Terminal, although it was a location with no inherent payoff advantage but high cultural prominence [@schelling1960, p. 57].

In the study of *pure coordination games*, Schelling examined interactions where players share interests but lack communication, such as selecting matching integers for a reward. Participants often converged on salient choices, such as the number 1, due to its distinctiveness as the smallest positive integer [@schelling1960, p. 102]. His work also refined the Nash equilibrium by demonstrating how focal points can help identify stable and salient outcomes among multiple NE [@lewis1969, p. 78]. Furthermore, for conflict scenarios, he introduced the concept of *"threats that leave something to chance"*, showing that probabilistic threats, such as partial mobilization, can deter adversaries more effectively than deterministic ones by leveraging uncertainty to maintain deterrence [@schelling1960, p. 187].

Lewis formalized Schelling’s insights into a theory of conventions, defining them as solutions to recurrent coordination problems where agents align on focal points due to mutual expectations [@lewis1969, p. 43]. Conventions rely on extrinsic incentives, such as avoiding coordination failure, rather than intrinsic obligations. Lewis also emphasized that communication itself is a coordination game, where signals derive meaning from shared conventions [@lewis1969, p. 95].

One of the central ideas Lewis took from Schelling is the concept of focal point, or salience. He showed that social conventions arise as focal points for coordination. For instance, in many societies, people drive on one designated side of the road not because of an inherent preference for that side, but because universal adherence to a single convention ensures safety and predictability. Building on that idea, Lewis argues that agents select the most salient convention which “stands out” from alternatives, either through precedent, explicit agreement, or intrinsic properties. According to Lewis, salience, a subjective psychological trait independent of the strategic situation, governs convention emergence and conformity. Specifically, Lewis addresses how conventions arise (dynamics – through initial selection and subsequent salience amplification) and why people conform (statics – due to the overwhelming salience of a pre-existing convention, fostering an expectation of adherence). Subsequent refinements of Lewis's theory reimagine and formalize the notion of salience mostly through evolutionary lens [@oconnor2019; @oconnor2020, @skyrms2014; @gintis2007a].

Another crucial concept Lewis adopts from Schelling is the role of expectation and self-enforcement in strategic equilibrium. Schelling showed that in many coordination scenarios, once an equilibrium is established, deviation becomes irrational since the costs of uncoordinated action outweigh potential individual gains. Lewis builds on this by defining conventions as self-perpetuating: once a convention is in place, individuals follow it not because of external enforcement, but because mutual expectations make deviation costly. This is evident in linguistic conventions, where the use of certain words and grammatical structures persists because everyone expects others to conform to them.

Furthermore, Lewis’s notion of *common knowledge*, foundational to his theory of conventions, derives from Schelling’s emphasis on mutual awareness within strategic interaction which is tightly connected with salience. Though Schelling lacked formalization, he highlighted the crucial role of shared understanding for successful coordination. Lewis expanded upon this, asserting that convention stability necessitates not just adherence, but also recognition as the expected behavior within a group, thereby enabling convention maintenance across large populations.

By drawing on Schelling’s work, Lewis was able to provide a game-theoretic foundation for the study of conventions, demonstrating how they emerge, stabilize, and persist over time. Whereas Schelling’s focus was on strategic choices in conflict and negotiation, Lewis extended these principles to the domain of language, social norms, and epistemic coordination, thus broadening the applicability of game-theoretic insights to philosophy and social science. As a result, Schelling’s *The Strategy of Conflict* remains one of the key intellectual influences behind Lewis’s *Convention* and its enduring impact on theories of social coordination.

## Lewis's theory of conventions
Lewis defined social convention as an arbitrary yet self-sustaining behavioral pattern emerging from repeated coordination problems between two or more players. Its distinctive feature is players' conformity to these behavioral patterns, for they expect others to do so, and it is *common knowledge* that every player is expected to conform. Deviation from a conventional choice of action leads to lower payoff, so players do not have incentives to deviate unilaterally which is on their own. For example, if everyone drives on the right side of the road, it is rational for each driver to do the same to avoid collisions. Lewis [@lewis1969, p. 76] formulates convention as follows:

A behavioral regularity $R$ within a population $P$ in a repeated situation $S$ qualifies as a convention if and only if:

1. Every member of $P$ conforms to $R$.
2. Each individual expects others to conform to $R$.
3. All members have similar preferences regarding possible behavioral patterns.
4. Each person prefers universal conformity to $R$, provided that nearly everyone else adheres to it.
5. Members would also prefer an alternative regularity $R'$ under the same conditions, as long as $R'$ and $R$ are mutually exclusive.

Lewis later refined his analysis to accommodate occasional deviations from convention and @skyrms2023 recently introduced *quasi-conventions* as unstable conventions based on yet another concept of *coarse correlated equilibrium*. Despite this, much of the academic discourse focuses on the strict version of Lewis's definition.

Lewisian convention is a special kind of equilibrium called *coordination equilibrium*, which roughly resembles NE, but extends beyond it. In NE, no participant can improve their outcome by unilaterally changing their strategy. If deviation strictly reduces payoff, the equilibrium is considered strict. In this sense, NE represents a "steady state," where each individual acts optimally given the actions of others. However, Lewisian convention extends beyond NE by emphasizing collective preference for conformity, even when minor deviations occur.

Lewis's framework highlights *arbitrariness* in conventions, where $R$ is defined as a convention only if an alternative $R'$ could serve equally well. This acknowledges that conventions are contingent choices among possible solutions rather than inherent necessities which continues the insights of Quine [@quine1969], Putnam [@putnam1975] and others.

Additionally, Lewis introduced the concept of *common knowledge* and made it a condition for a regularity to be a convention, where a fact $p$ is common knowledge if:

- Everyone knows $p$;
- Everyone knows that everyone knows $p$,
- Everyone knows that everyone knows that everyone knows $p$, and so on.

This recursive understanding of knowledge has spurred extensive discussion in both philosophical and game-theoretic literature. Aumann [@aumann1976] and Schiffer [@schiffer1972] have developed formalizations of common knowledge, diverging from Lewis’s original informal approach. 

As we will tour this and other aspects of Lewis's theory in detail later in this chapter, it suffices to mention that further reception of his theory saw the common knowledge requirement too cognitively demanding and unrealistic [@gilbert1992; @binmore2008; @camerer2003; @bicchieri2005; @vanderschraaf1998].

As Lewis's theory uses game theory, rationality plays a fundamental role in his framework. Lewis assumed that agents are instrumentally rational, meaning they choose actions that maximize their expected utility given their beliefs and expectations about the world and the behavior of others. Although the entire metaphor of humans as maximizing agents has been questioned [@paternotte2020a], it still serves as guidance in economic theory [@gintis2007; @gintis2013], biology [@okasha2017; @okasha2012; @engel2008] and human ecology [@mouden2012a; @sterelny2012]. However, there are alternative views on the requirement of agent's rationality for conventions to exist. @millikan2022 suggests that conventions stabilize only by the weight of precedent, thus not requiring any rationality or consciousness.

Lewis's notion of conventions weaves behavior, beliefs, preferences, and expectations into a framework of common knowledge and rationality to explain the stability of conventions. Each part of the definition is vital: 

- common knowledge ensures a shared understanding of the convention, 
- the preference for conformity incentivizes adherence given others' cooperation,
- rationality guides individual choices within the context of shared expectations.

As a primary motivation for Lewis's analysis was to address the philosophical problem of linguistic meaning, he aimed to argue that language is grounded in conventions which do not require up-front agreement on terms. Just as drivers coordinate on a side to drive without a formal contract, speakers of a language develop conventions of using sounds or gestures to refer to specific things through repeated interaction and mutual expectations. Lewis viewed language as a system of signaling, where meaning arises from the conventional association between signals (words, phrases) and states of the world. For example, the word "cat" conventionally signals the presence of a feline. This convention is sustained because speakers generally intend to be truthful and listeners generally trust that they are being told the truth. This mutual expectation and reliance on the regularity of signal-meaning pairings allows for effective communication, which is a form of coordination.

This led Lewis to delineate *behavioral* and *signaling* conventions [@lewis2008, 147-150], where the former coordinate actions and the former coordinate meaning in communication. As a prototypical example of a signaling convention, Lewis gives a story of Paul Revere and the lanterns hung in the steeple of the Old North Church used to warn colonial militia about approaching British Troops in 1775. Two hung lanterns conveyed that troops are advancing by sea, one by land. Additionally, the actions of a message's receiver, given each of these signals, would differ. Senders and receivers of a message coordinate on following a pre-established pattern of "if X, do Y" like in the example with lanterns[^skyrms-learning].

[^skyrms-learning]: As Skyrms has shown [-@skyrms2010; -@skyrms2010a], the pattern can be learned dynamically in iterated games: both X and Y can be established and recognized with trial-and-error via reinforcement learning.

For Lewis, signaling conventions are a special case, or a subclass, of behavioral conventions as they share basic properties like arbitrariness, conformity and being common knowledge. Signaling conventions differ in that they involve communication and interpretation of meaning and solve coordination problems by *information transfer*. They require encoding/decoding which is producing and interpreting signals. 

An important feature of the relationship between these two classes of conventions is that, according to Lewis, signaling conventions fundamentally rely upon and are shaped by pre-existing behavioral conventions. For example, language meanings of words depend on both parties' adherence to established norms of pronunciation and grammar. Signaling systems frequently exhibit nesting, where specific conventions are embedded within larger behavioral regularities. For instance, raising one’s hand to speak during a meeting is a signaling conventions nested within a broader behavioral convention of turn-taking [@vanderschraaf].

There is a formal distinction between behavioral, or "general" as Lewis call it, and signaling conventions. In signaling games, the players can be either senders or receivers, where the former owns private information about the world state and send a signal about it and the latter observes the signal and acts on it. More formally, it looks like the following:

1. **World states**: L (left) and R (right)
2. **Signals**: V₁ and V₂
3. **Actions**: Aᴸ (left action) and Aᴿ (right action)


| Role       | Strategy | Description                           |
|------------|----------|---------------------------------------|
| **Sender** | S₁       | Signal V₁ if L, V₂ if R               |
|            | S₂       | Signal V₂ if L, V₁ if R               |
| **Receiver** | R₁      | Choose Aᴸ if V₁, Aᴿ if V₂            |
|            | R₂       | Choose Aᴿ if V₁, Aᴸ if V₂            |


And in a matrix form it looks as follows:


<!--Doc representation-->
<!--$$-->
<!--\begin{figure}-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!-- & R₁ & R₂ \\-->
<!--\hline-->
<!--S₁ & (1,1) & (0,0) \\-->
<!--\hline-->
<!--S₂ & (0,0) & (1,1) \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{Signaling game}-->
<!--\end{figure}-->
<!--$$-->

<!--Web representation-->
$$
\begin{array}{|c|c|c|}
\hline
 & R₁ & R₂ \\
\hline
S₁ & (1,1) & (0,0) \\
\hline
S₂ & (0,0) & (1,1) \\
\hline
\end{array}
$$

If a sender's signal representing a world state is correctly acted upon by receiver, both parties get the payoff of $(1, 1)$ and if either party fails to map ("encode" or "decode") information, they get $(0, 0)$. There is a plethora of possible options within this informational "layer" of signaling system like pooling, sysnonyms, deception and others extensively studied primarily by philosophers of biology [@skyrms2010a; @skyrms2010; @huttegger2008; @godfrey-smith1991; @shea2018a; @martinez2019].

@godfrey-smith2014 refined Lewis's model by distinguishing *state-act* and *act-act* coordination:

- *State-Act* coordination: signals map states to receiver action;
- *Act-Act* coordination: signals synchronize action between agents without any external events. 

*Act-act* coordination allows to view Hume's boat rowers as an act-act signaling system: the rowers’ rhythmic strokes serve as imperative signals (“Row now!”) that directly coordinate mutual actions rather than conveying information about external conditions [@martinez2016]. The absence of an exogenous state reduces the system to a pure coordination game employing Nash or coordination equilibrium, where the “signal” (stroke rhythm) functions as a self-reinforcing convention stabilized by common interest and reciprocal expectations. Unlike state-dependent signaling of *state-act* coordination, which requires alignment between acts and external facts, *act-act* systems like the rowboat prioritize *interpersonal synchronization* through real-time behavioral feedback, illustrating how communication can organize joint action without representational content.

A paradigmatic real-world example of a *state-act* signaling system is alarm calls specific for each type of predator. For example, vervet monkeys have a call for seeing eagles which conveys hiding in the grass and a call for seeing a snake conveying climbing on a tree [@seyfarth1990]. A perfect connection between a world state, signal and action comprises a signaling system. 

Although formally similar, as both behavioral and signaling conventions can be described as games with players and payoffs, they differ in that the latter have an additional "layer" of information between players. And although Lewis himself proclaimed signaling conventions a subcategory of behavioral ones, the relationship between them is not clear. For Skyrms, signals *inform* action, and signaling networks *coordinate* action, which implicitly conveys signaling conventions as underpinning behavioral ones and nit vice versa. Skyrms further suggests that signaling is responsible for the evolution of teamwork itself [@skyrms2010], which questions Lewis's hierarchical categorization and creates a version of a chicken-and-egg problem, which is out of scope of this thesis.

## Criticisms and generated problems of Lewis's theory
Lewis's theory has been criticized on many grounds, and, as @rescorla2024 notes, virtually every component of his theory has been under attack: from imprecise notion of equilibrium concept to the very necessity of conventions for solving coordination problems. However, many initial criticisms have been met in the refinements and extensions of Lewis's theory by later scholars. 

There are five main areas of criticism of Lewis's account of conventions:

1. conformity requirement and hidden normativity
2. overestimation of arbitrariness
3. common knowledge requirement and source of salience
4. connection between conventions and coordination problems
5. imprecise equilibrium concept

We will survey 1-4 here as 5 is an extension rather than critique which we will address in the next section on refinements of Lewis's theory. Each subsection starts with immediate criticism of Lewis's theory and continues with a larger problem Lewis's theory generated or contributed to.

### Hidden normativity of conventions
One of the major criticisms of Lewis's theory of conventions is unrealistic conformity requirement expressed of his 4-th clause: "each person prefers universal conformity to $R$, provided that nearly everyone else adheres to it". As some scholars points out, this strict requirement rules out such regularities as sending thank-you notes after dinner as non-conventional, for they do not require complete conformity [@gilbert1992]. Many commentators find this unintuitive as we usually call any mutually expected behavioral regularity a convention regardless of its level of conformity. 

However, a possible defense of Lewis's position is to restrict a social group where convention takes place and to add that "each person *within a bounded social group* prefers universal conformity to $R$…". This addition addresses Gilbert's criticism in that it supports an idea of near-complete conformity relative to the scale and size of a social group with operative convention. If sending thank-you notes after a dinner within a certain group is indeed a convention, not writing such a note would at least disappoint a dinner host. Of course, this might not impose any external sanctions on a guest not writing a thank-you note. However, conformity relative to group size highlights inherent normativity in the form close to normative expectation, which @bicchieri2005 considers an essential ingredient of social norms rather than conventions.

As can be seen, a convention's level of conformity poses a deeper problem—normativity of conventions. The level of conformity helps distinguish between conventions as regularities *de facto* and *de jure*  [@rescorla2024], where the former describe actual behavior and the latter prescribe how individuals should behave in certain situations. Lewis himself anticipated such objections and claimed that conventions eventually become social norms. This claim later generated a major controversy over the relationship between those [@bicchieri2023]. Level of conformity points to a problem of the source of such conformity, which concerns Lewis's critics.

@gilbert1992 contends that Lewis’s account ignores the normative force of conventions. For Gilbert, the source of conformity of conventions is *joint commitments* that bind participants to collective ends, creating obligations to conform and justifying criticism of defectors. Lewis’s model, which reduces conventions to equilibrium strategies in coordination games, cannot explain why individuals feel *obliged* to comply with conventions (e.g., stopping at red lights) or apologize for breaching them. Gilbert also disputes Lewis’s focus on coordination problems, arguing that many conventions like etiquette rules lack clear coordination benefits and instead reflect shared commitments. In Lewis, there is appeal to instrumental rationality which maximizes expected value and avoids sanctions, but some scholars see this as insufficient to substantiate conventions. 

For instance, @guala2010 study the extent to which Lewis conventions are normative. They address both theoretical and empirical aspects and conclude that Lewis has put forward a scientific theory of conventions and not an analysis of the folk notion, and that conventions do indeed have intrinsic normativity beyond that of instrumental rationality. However, there is another strand of scholars that disagree and put forward that the only normativity of conventions is that of instrumental rationality [@gold2007; @bacharach1997].

As @guala2010 report, in experimental settings, given an iterated Ultimatum or Prisoner dilemma game, only 29% of potential deviants in the lab choose to breach emergent convention. Players in these experiments may unintentionally create extra pressure to conform with their shared history of action, beyond the requirements of rational decision-making and social norms. However, the exact mechanism of additional normative expectation formation is to be discovered. 

From this, Guala concludes that Lewis' model provides an incomplete account of conventions' ontology. Data suggest that Lewisian conventions acquire normative force through repeated play, and any future model must account for this. This has non-trivial implications for theory and practice, as it implies that habits and customs may be hard to disrupt. 

In a similar vein, @hindriks2019 claims that instrumental rationality cannot motivate adherence to conventions and norms and their perception as legitimate. Instrumental rationality with its costs and expected utilities fails to capture the motivation by the normative part of convention itself and not by the costs of its violation. Hindriks claims that it is *normative expectations* and *normative beliefs* that complement sanctions as a source for norm existence and perception as legitimate. 

In a broader context, the problem of normativity of Lewis conventions ignited a lively debate in philosophy regarding the relationship between conventions and social norms. They share a foundation in regularities and mutual expectations, but diverge in normative force, enforcement mechanisms, and social functions. Lewis’s model offers a minimalist, rationalist account of coordination, whereas social norms represent a richer, more complex landscape of social regulation, deeply shaped by values, sanctions, and cultural meanings. Thus, norms are seen as conventions acquiring enforcement capacity beyond pure coordination with repeated play.

@ullmann-margalit1977 gave one of the first game-theoretic conceptualizations of social norms. She argued that, as groups interact repeatedly, they develop expectations based on both obligation and the threat of social sanctions. These expectations go beyond simple conventions, relying on individuals’ internalized sense of duty and the potential for consequences like disapproval or ostracism. According to Ullmann-Margalit, this represents a move from coordinating behavior solely through rational self-interest to one where compliance is motivated by a deeply held conviction.

More precisely, Ullmann-Margalit emphasized normative authority as a mechanism of norm emergence, where they arise as informal solutions to coordination, cooperation, and mixed-motive problems characterized by divergent individual and collective interests. She conceptualized a *history space* $\mathcal{H}$ as sequences of past interactions, where each history $h = [(a^1, s^1), (a^2, s^2), \dots, (a^t, s^t)]$ pairs joint action profiles $a^k\in A^n$ with observed sanction signals $s^k\in \{-1,0,1\}^n$ (negative, neutral, positive). A *normative choice function*

$$N:\mathcal{H} \to \Delta(A)$$

maps each history to a probability distribution over actions, reflecting both *strategic expectations* and *normative weights*.

Then, for any history $h$, an agent’s expected utility from choosing action $a$ is given by:

$$U(a\mid h) = u(a\mid h) + \beta\, I(a\mid h),$$

where:

- $u(a\mid h)$ is the material payoff based on beliefs about opponents’ strategies inferred from $h$.  
- $I(a\mid h)$ is the *internalized norm intensity*, capturing both social and psychological sanctions.  
- $\beta>0$ scales the importance of normative pressures relative to material gains.

Ullmann‑Margalit further suggests that norm intensity $I(a\mid h)$ evolves according to a *reinforcement learning* update:

$$I_{t+1}(a) = I_t(a) + \gamma\bigl(s_t(a) - I_t(a)\bigr),$$

where $s_t(a)$ is the average sanction observed when action $a$ was taken at time $t$, and $0<\gamma\le1$ is a sensitivity parameter. Over time, this embeds the *frequency and severity* of social approval or disapproval into agents’ preference structures.

A critical feature of Ullmann‑Margalit’s sketch is the *threshold effect*: once $\beta\,I(a\mid h)$ exceeds a context-dependent threshold $\theta$, normative considerations dominate, and agents will comply even against short-term material incentives. Formally, if

$$u(a'\mid h) - u(a^*\mid h) < \beta\bigl[I(a^*\mid h) - I(a'\mid h)\bigr] \quad\forall a'\ne a^*, $$

then $N(h)$ places all weight on $a^*$, the *normatively prescribed* action, regardless of smaller material gains from deviation.

This model suggests path-dependence as early interaction profiles and sanction signals can lock a community into a particular normative equilibrium, making norm shifts resistant to modest perturbations. In addition, in public goods or trust games, where $u(a)$ favors free‑riding, a sufficiently high $I(a)$ can sustain cooperation via internalized guilt and peer sanctions. @crawford1995 later modeled a similar situation of cooperation problems with $\delta$-parameters seen as additionally incurred costs in the form of potential sanctions, which, being sufficiently high, can transform a cooperation game into a coordination game. For instance, given a Prisoner's dilemma with a high delta parameter representing a cost for norm violation, the game becomes that of coordination with two equilibria — “Cooperate, cooperate” and “Defect, defect” (CC, DD) instead of only one — DD. This shows that normative rules can be coordination devices, or “choreographers”, as Gintis puts it [@gintis2009a].

Ullmann‑Margalit also acknowledged multiple channels like formal penalties, gossip and emotional costs that feed into $s_t(a)$, allowing norms to persist even when formal institutions are weak. Through these mechanisms, Ullmann‑Margalit transformed Lewis’s static, expectation-based model into a dynamic framework that accounts for the emergence, stability, and transformations of social norms with genuine normative force.

<!--Elster did not explicitly cite Lewis-->
<!--Elster [@elster1989] synthesized rational choice theory with psychological realism to elucidate the function of norms as commitments within individual strategic calculations. He introduced the concept of "self-command", an agent's voluntary binding to future actions to resist immediate impulses. Elster distinguished between *first-order expectations* (anticipated behavior) and *second-order expectations* (anticipated normative judgments), recognizing that sophisticated social norms necessitate the latter to reinforce an agent’s sense of duty. He analyzed how norms resolve mixed-motive dilemmas by aligning long-term interests with communal standards, thereby integrating normative force within a rational choice framework.-->
<!---->
<!--Elster modeled norm adherence as the outcome of a two‑stage game. Agents first choose a commitment set $$C \subseteq A$$ (a subset of the full action set $$A$$) to maximize the worst‑case long‑run payoff:-->
<!---->
<!--$$-->
<!--V(C) = \min_{a \in C} U(a) - \kappa \cdot |C|-->
<!--$$-->
<!---->
<!--where $$U(a)$$ represents long‑run utility and $$\kappa > 0$$ is the cost of restricting options. In the action stage, agents choose $$a^* \in C$$ to maximize the immediate payoff $$u(a)$$. This formalism captures how moral vows or binding contracts prune future options to enforce norm compliance.-->
<!---->
<!--Elster also formalized utility that depends on both empirical expectations about others’ actions and normative expectations about what others think is appropriate. Let $$P(S)$$ denote beliefs over opponents’ strategy profiles. Then:-->
<!---->
<!--$$-->
<!--\begin{aligned}-->
<!--U_{\text{emp}}(a) &= \mathbb{E}_{S \sim P}[u(a,S)] \\\\-->
<!--U_{\text{norm}}(a) &= \mathbb{E}_{S \sim P}[\mathbb{I}(a \text{ is approved by others})] \\\\-->
<!--U^*(a) &= U_{\text{emp}}(a) + \lambda \cdot U_{\text{norm}}(a) - c \cdot D(a)-->
<!--\end{aligned}-->
<!--$$-->
<!---->
<!--where $$\lambda > 0$$ weights normative approval, and $$D(a) = 1$$ if $$a$$ deviates from the norm (0 otherwise), with $$c$$ capturing sanction cost or psychological guilt. A *normative equilibrium* occurs when every agent's action maximizes $$U^*(a)$$, beliefs are correct, and normative expectations are self‑fulfilling.-->
<!---->
<!--As an example, in a Prisoner's Dilemma with actions $$C$$ (cooperate) and $$D$$ (defect), material payoffs satisfy:-->
<!---->
<!--$$-->
<!--u(D,C) > u(C,C) > u(D,D) > u(C,D)-->
<!--$$-->
<!---->
<!--Let $$p = \Pr(\text{other cooperates})$$ and $$q = \Pr(\text{other approves cooperation})$$. Then:-->
<!---->
<!--$$-->
<!--\begin{aligned}-->
<!--U^*(C) &= p \cdot u(C,C) + (1-p) \cdot u(C,D) + \lambda q - c \\\\-->
<!--U^*(D) &= p \cdot u(D,C) + (1-p) \cdot u(D,D)-->
<!--\end{aligned}-->
<!--$$-->
<!---->
<!--Even if $$p$$ is low, a sufficiently large $$(\lambda q - c)$$ term can make cooperation strictly optimal. This illustrates how normative expectations and sanctions sustain cooperative norms beyond pure coordination.-->

Although not directly related to Lewis's conventions, the pioneering work of @epstein1996 in generative social science employed agent-based modeling to investigate the spontaneous emergence of social conventions and norms, driven by endogenous norm formation without centralized enforcement. It is similar to Lewis's project and is referenced here as a proof-of-concept that norms can be "grown" from behavioral pattern a la Lewis. 

Rooted in agent-based computational economics and evolutionary game theory, Epstein’s models utilize bounded rationality, with agents operating under simple rules and limited information. This rejects traditional assumptions of perfect rationality or equilibrium. System-level behavior is analytically intractable, necessitating simulation as a primary tool. This framework aligns with game theory, specifically repeated and evolutionary games, where payoffs are contingent on frequent population-level strategies, and norms emerge as persistent patterns of behavior sustained by costly deviation or social punishment.

Epstein’s models, utilizing ‘Sugarscape’ simulations, employ heterogeneous agents governed by dynamic, simple behavioral rules, independently generating both global conventions and localized norms without centralized coordination. These models highlight the critical roles of path dependence – the influence of past decisions on future behavior – and network topology in shaping social pattern stability. Translating Lewis’s coordination concept into a computational framework, Epstein demonstrated how agent diversity, stochastic processes, and adaptive learning mechanisms can produce durable social regularities exhibiting normative implications.

In Epstein’s canonical model, agents occupy a grid and interact locally. Each agent follows a simple rule-based strategy and can observe the behavior of its neighbors. Over time, they update their behavior based on local observations and possibly some payoff structure.

The theoretical core of Epstein's model can be expressed using a **game-theoretic payoff matrix**, where agents derive utility from conforming to or deviating from a local behavioral pattern:

Let the strategy set be $(S = \{C, D\})$, representing **conforming** $C$ and **deviating** $D$. The payoff matrix for an agent may be:

<!--Doc representation-->
<!--$$-->
<!--\begin{figure}-->
<!--\begin{tabular}{|c|c|c|}-->
<!--& C & D \\-->
<!--\hline-->
<!--C & R & S \\-->
<!--D & T & P \\-->
<!--\end{tabular}-->
<!--\caption{Epstein's game matrix for simulation of norm emergence}-->
<!--\end{figure}-->
<!--$$-->

<!--Web representation-->
$$
\begin{array}{|c|c|c|}
& C & D \\
\hline
C & R & S \\
D & T & P \\
\end{array}
$$

Where:

- $R$: reward for mutual conformity
- $S$: sucker’s payoff (you conform, others don’t)
- $T$: temptation to deviate
- $P$: punishment for mutual deviation

Agents update their strategy based on *success-based imitation* (copying the strategy of the most successful neighbor), or using rules akin to *replicator dynamics* in evolutionary game theory:

$$
\dot{x}_i = x_i \left[ (A \vec{x})_i - \vec{x}^T A \vec{x} \right]
$$

Where:

- $x_i$: proportion of agents using strategy $i$
- $A$: payoff matrix
- $\vec{x}$: strategy distribution vector

However, in Epstein’s ABM, this is implemented *discretely and locally*: agents switch strategies probabilistically based on their relative payoffs and observed neighborhood norms.

Over time, consistent behavioral patterns like norms may emerge. These norms are not imposed but *self-organized* through repeated interactions and adaptation. A key insight from Epstein’s work is that *norms can be sustained through decentralized enforcement*, such as local peer pressure or reputation systems. For instance, agents might adopt a punishment rule: if a neighbor deviates from a prevailing norm, the agent may impose a cost on them (e.g., by refusing to cooperate in future interactions). This introduces *meta-norms* (norms about enforcing norms), which further stabilize the system.

Several important insights emerged from Epstein’s simulations:

- *Multiple equilibria*: Different regions of the simulation space can stabilize on different norms, illustrating the *path-dependence* of social systems.
- *Robustness*: Norms are robust to noise and perturbations, depending on enforcement mechanisms.
- *Phase transitions*: Under certain conditions, the system exhibits critical behavior where small changes in parameters (e.g., punishment cost) can lead to large-scale shifts in norm adoption.

Joshua Epstein’s work bridges the gap between micro-level behavioral rules and macro-level social patterns. By embedding game-theoretic interactions in a spatially explicit agent-based model, he demonstrated how complex social norms can emerge from simple local interactions. His simulations provide a powerful tool for exploring the dynamics of social norm formation, challenging the view that norms require centralized design or enforcement. Instead, they may be the natural outcome of decentralized, strategic adaptation in social environments.

Another treatment of normativity in regard to conventions is due to @young1998. Young’s theory of social norms represents a major step in formalizing how collective behavioral patterns arise and stabilize in decentralized populations. His key contribution lies in drawing a conceptual and mathematical distinction between *conventions* and *social norms*, and in showing how norms can emerge and persist even when they are not individually payoff-maximizing. While conventions are defined as self-enforcing equilibria of coordination games, social norms in Young’s account involve a deeper layer of *prescriptive expectations* and *enforcement structures*, including social punishment for deviation [@young1998, pp. 83–85]. This distinction allows him to move beyond the Lewisian model of convention [@lewis1969] and more closely approximate real-world practices like tipping, queuing, or property respect, which often persist even in the absence of external enforcement or explicit payoff dominance.

Young modeled social behavior as an evolutionary process grounded in *adaptive learning*. Agents are situated in a population and repeatedly engage in *local interaction games*, where strategies are updated according to boundedly rational rules such as *myopic (or short-sighted) best response* focusing on the present payoff possibilities. Importantly, agents are assumed to make occasional errors, either due to experimentation or misperception which introduces *stochasticity*, or non-deterministic randomness, into the learning process. This leads to a Markov chain[^Markov=chain] over the space of population states, where each state corresponds to a configuration of strategies across individuals.

[^Markov-chain]: A Markov process is a stochastic process that satisfies the *Markov property* (also known as the "memoryless property"): the future state of the process depends only on the present state and not on the sequence of events that preceded it.  In simpler terms, the past doesn't influence the future, given the present. A stochastic process $\{X_t, t \geq 0\}$ is a Markov process if for any $t \geq 0$ and any $s < t$, the conditional probability of $X_t$ given $X_s$ is equal to the unconditional probability of $X_t$ given $X_s$: $P(X_t \in A | X_s \in B, s < t) = P(X_t \in A | X_s \in B)$, where $X_t$ is the state of the process at time $t$, $A$ and $B$ are events in the state space, the state space is denoted by $\mathcal{S}$.

To analyze the long-run behavior of such systems, Young introduces the concept of *stochastic stability*. Let $\mathcal{S}$ be the finite set of population states, and let $P^\varepsilon$ be a transition probability matrix parameterized by a noise level $\varepsilon$. Then the *stationary distribution* $\pi^\varepsilon$ satisfies:

$$
\pi^\varepsilon P^\varepsilon = \pi^\varepsilon,
$$

and the set of *stochastically stable states* $S^* \subseteq \mathcal{S}$ is defined as:

$$
S^* = \left\{ s \in \mathcal{S} \ \middle| \ \lim_{\varepsilon \to 0} \pi^\varepsilon(s) > 0 \right\}.
$$

To compute $S^*$, Young uses the *resistance tree* method. Each transition between states is assigned a *resistance* based on how improbable it is (i.e., how many agents must err simultaneously), and stochastically stable states are those with the *lowest total resistance* across spanning trees rooted at those states [@young1998, pp. 103–107].

This framework has several far-reaching implications. First, it provides a *selection principle* for equilibrium in games with multiple Nash equilibria. Unlike refinements based on rationality assumptions, Young’s selection is *behavioral and dynamic*, requiring only minimal cognition. Second, it allows the modeling of *social enforcement*: norms can be represented as equilibria of games with endogenous punishment strategies, wherein agents prefer to punish norm violations even at a personal cost [@young1998, pp. 90–92]. These punishment mechanisms can themselves be stochastically stable, giving rise to *self-enforcing normative structures* without assuming rational foresight or institutional backing.

Young's framework in also richly connected to other theoretical frameworks. Young’s approach aligns in spirit with Skyrms’s view of *local interaction as a source of correlation* in the emergence of conventions [@skyrms1996], but differs in emphasis. While Skyrms treats conventions as emerging from *evolutionary dynamics with minimal structure*, Young introduces *explicit sanctioning mechanisms and social expectations*, making norms qualitatively distinct from conventions. Moreover, Young’s stochastic stability framework offers a *non-epistemic interpretation* of equilibrium selection that contrasts with the *Bayesian rationality* underlying correlated equilibrium in Aumann’s model [@aumann1974]. In Aumann’s framework, a *correlation device* (e.g., a public signal) coordinates beliefs to yield a correlated equilibrium, relying on agents’ rational Bayesian updating. Young’s framework, by contrast, explains the emergence of coordination *without any epistemic content*, driven instead by population-level statistical stability.

In sum, Young's theory provides a mathematically rigorous account of how *prescriptive social norms*, backed by informal sanctions, emerge and persist in large populations through *local adaptation and noise-driven selection*. His work not only bridges the gap between evolutionary game theory and institutional analysis, but also supplies tools for identifying which norms are likely to prevail under given interaction structures and stochastic conditions.

@bicchieri2005 offered a distinct and now mainstream epistemic and psychological approach to social norms departing from traditional game-theoretic, functionalist, and purely behavioral models. She distinguished conventions from social norms based on *conditional preference*. According to her, individuals follow a rule if they:

(a) expect sufficiently many others to follow it (empirical expectation)
(b) believe sufficiently many others think they ought to follow it (normative expectation). 

In Lewis’s conventions, only empirical expectations matter while normative expectations and potential sanctions are absent. By contrast, actual norms depend on both layers of expectation and are upheld through social sanctions, external (punishments) or internal (guilt) [@bicchieri2006, pp. 11–13]. Bicchieri’s framework highlights that modifying agents’ beliefs about others’ attitudes can transform a convention into a norm, offering actionable insights for policy and institutional design.

Bicchieri posits that a behavioral rule $R$ is a social norm in a population $P$ with respect to a situation $S$ if:

1. The rule $R$ is *recognized* to apply in situation $S$.
2. A sufficiently large subset of $P$ conforms to $R$ in $S$, and each individual $i \in P$ has the *empirical expectation* that others conform to $R$ in $S$.
3. Each $i \in P$ believes that others think she ought to conform to $R$ in $S$ (i.e., has *normative expectations*).
4. Each $i \in P$ has a preference to conform to $R$ *on condition* that:
   - (a) she believes others conform to $R$ in $S$;
   - (b) she believes others believe she ought to conform to $R$ in $S$.

This is often expressed via a *preference conditional on expectations*:

$$
i \text{ prefers to do } R \text{ in } S \iff EE_i(R) \land NE_i(R)
$$

where:

- $EE_i(R)$ = empirical expectation: "Others will do $R$ in $S$"
- $NE_i(R)$ = normative expectation: "Others expect me to do $R$ in $S$"

This conditionality sets Bicchieri apart from rational choice or equilibrium-based models. For her, compliance with norms depends not on fixed utility functions but on *context-sensitive preference shifts* driven by belief structures.

Contra Lewis, Bicchieri insists that *norms are not reducible to equilibrium strategies* or to mutually expected behavior. They involve a prescriptive layer comprised of what others think one *ought* to do. Moreover, unlike Lewis, she does not require common knowledge of the regularity. Instead, norms can exist in mixed populations and be locally activated [@bicchieri2006, pp. 41–45].

Bicchieri argues that norm compliance is largely situational and dependent on expectation structures, not internalized values or long-term moral training like *self-command* in other frameworks adjacent to game theory [@elster1989]. Her experimental evidence suggests that many individuals are *conditional cooperators*, responsive to perceived expectations, and prone to *strategic norm evasion* when the normative context is weak [@bicchieri2006, pp. 153–156]. Norms, for her, do not require full internalization but are highly contextual and can be followed instrumentally in appropriate contexts.

Compared to @ullmann-margalit1977, who conceptualized norms primarily as solutions to recurrent social problems like coordination, cooperation and avoidance of conflict with norms as functional entities, Bicchieri’s view departs in two ways: 

1. Bicchieri decouples norm emergence from functional necessity meaning that not all norms solve problems, and some persist even when suboptimal
2. She builds a *bottom-up epistemic model*: a norm exists not because it solves a coordination problem, but because agents *believe* it exists, and condition their preferences accordingly. The existence of a norm is thus a *psychological fact about belief networks*, not merely a systemic solution.

Bicchieri thus has offered a model of norms as *contextually activated scripts*, grounded in micro-level epistemic structures, and capable of explaining variability, fragility, and rapid change in social behavior. It is also important to note that Bicchieri's agents are entirely Bayesian-rational, meaning they form, have and update explicit beliefs and have *cognitive schemata* sufficient for processing these beliefs [@bicchieri2018].

One more influential conceptualization of social norms is due to Gintis who offered a *multi-level evolutionary account* of social norms that integrates insights from game theory, behavioral economics, evolutionary biology, and complex systems theory. Unlike approaches that treat norms either as equilibrium strategies (Lewis) or as epistemic constructs (Bicchieri), Gintis argued that *norms are a form of socially transmitted rule-based behavior* that co-evolves with the human capacity for cooperation and punishment, and whose persistence is explained through *gene–culture coevolution* [@gintis2003; @gintis2009].

Gintis defined a norm as a rule of behavior that is:

1. *Universally shared* within a reference group,
2. *Individually internalized*, so that deviation provokes negative emotions like guilt or shame,
3. *Enforced through third-party punishment*, and
4. *Costly to individuals*, yet *adaptive* at the group level [@gintis2003, pp. 259–260].

The evolutionary viability of such norms arises from the interplay between individual fitness and group selection: although norm-followers may incur costs, groups with strong norm adherence—especially norms of cooperation, fairness, or punishment—outperform less cohesive groups in intergroup competition. This is formalized in models of *multi-level selection*, where within-group dynamics favor selfishness, but *between-group dynamics favor cooperation* mediated by norms. As Vlerick [-@vlerick2019] suggests, solutions to coordination problems emerge from within-group dynamics, while solutions to competition ones are largely selected through between-group competition. Within-group dynamics explain why salient coordination rules emerge. When it comes to solving competition problems, however, between-group dynamics play a major role. They select *game changing norms* that affect the payoff related to the available strategies through punishment or reward to solve free-rider problems which create better equilibria than the ones originally available. It means that social arrangements with norms alter payoff matrices to ensure that self-interested strategies align with group interests, without requiring self-sacrifice. They are shaped by interactions between individuals and between groups, the latter selecting efficient equilibria and the former leading to salient ones. Sanctions are imposed to solve competition problems.

Gintis models norm enforcement and stability through *replicator dynamics* and public goods games. Suppose $x_i$ is the share of individuals using strategy $i$ (e.g., cooperating, defecting, punishing). Let $f_i$ be the fitness (expected payoff) of strategy $i$. The replicator equation is:

$$
\dot{x}_i = x_i(f_i - \bar{f}),
$$

where $\bar{f} = \sum_j x_j f_j$ is the population average fitness. A norm is stable when the strategy it encodes becomes evolutionarily stable (resists invasion by mutants) due to its *adaptive advantage in group-level performance*.

What makes norms distinctive in Gintis’s account is the incorporation of *strong reciprocity*, a behavioral trait characterized by *cooperation with others and punishment of non-cooperators*, even at personal cost. Strong reciprocity is empirically observed in cross-cultural behavioral experiments like ultimatum, trust, and public goods games and contradicts the predictions of purely self-interested models [@gintis2005]. Gintis treats this trait not as an anomaly but as an *evolutionary stable behavioral phenotype*, sustained through norm-based socialization and group selection.

A central and innovative concept in Gintis’s theory of social norms is the idea that norms transform not just preferences but the *structure of the strategic interaction itself*, by modifying agents’ *subjective representations of payoffs and actions*. This transformation is encoded in what he calls a *belief matrix*, a mapping of how agents perceive and evaluate their strategic options based on the presence of social norms [@gintis2009, ch. 12; @gintis2003, pp. 266–268].

In classical game theory, a game is defined by:

- A set of players $N$,
- A set of strategies $S_i$ for each player $i \in N$,
- A utility function $u_i: S \to \mathbb{R}$ assigning payoffs.

Gintis argues that this framework is incomplete for modeling *norm-governed behavior*, because it assumes that agents evaluate strategies based on static utility functions. However, *norms induce endogenous changes* in the utility functions themselves, via socially learned expectations, emotions like guilt or shame, and reputational incentives. These are captured through a *modified payoff function*:

$$
u'_i(s) = u_i(s) + n_i(s),
$$

where $u'_i$ is the *norm-adjusted utility*, and $n_i(s)$ encodes *normative valuations* of strategy profile $s$. The function $n_i$ depends on agent $i$’s *beliefs* about what is expected, appropriate, or punishable—thus forming part of a *belief matrix*.

The *belief matrix* is not merely a list of beliefs but a *second-order cognitive structure*: it encodes how players *transform the base game* into a normatively laden one. For example, in a Prisoner’s Dilemma, if both players believe that mutual defection is morally wrong and likely to incur reputational loss, their payoff matrix is *endogenously transformed* into a coordination game or even a Stag Hunt, depending on the intensity of normative beliefs. This resembles Crawford's and Ostrom's cooperation games  $\delta$-parametrized with incurred sanctions which I mentioned earlier.

To formalize this, let $M$ be the original payoff matrix, and $B$ be the *belief matrix* that maps social expectations, punishments, and rewards into numerical modifiers. Then:

$$
M' = M + B
$$

where $M'$ is the *norm-governed game* actually perceived and enacted by players.

This idea closely parallels Gintis's general theory of *"strongly endogenous games"* [@gintis2009, pp. 187–189], in which preferences and payoffs are not fixed but shaped by cultural and institutional context. Here, *social norms act as priors or filters* that reshape the game. The belief matrix $B$ may itself evolve over time, via cultural transmission, education, or feedback from repeated play.

Gintis thus provides a mechanism for the *cognitive embedding of norms* in strategic behavior, bridging the rationalist structure of game theory with *evolutionary and cultural psychology*. This resembles Bicchieri' notion of cognitive schemata and hints on its mechanism. Gintis's approach contrasts sharply with static or exogenous models of norms like Lewis’s conventions, and aligns Gintis with *constructivist* and dynamic modeling traditions in behavioral economics.

<!--Like Elster, Gintis attributes a motivational role to internal sanctions like shame or guilt. However, Elster’s account is more sociological and introspective, focusing on the irrational or pre-rational nature of norm-guided action. Gintis gives these same internal mechanisms a formal evolutionary explanation: they persist because they enhance group-level fitness and individual reputational benefits within structured populations. Where Elster tends to be skeptical of rational-choice models, Gintis integrates bounded rationality into a dynamic evolutionary framework.-->

Gintis and Young [@young1998] share an interest in the emergence and stability of social norms. Young explains norm stability via stochastic evolutionary dynamics and local interaction, using resistance trees and Markov chains to model convergence to norms. Gintis, by contrast, provides a biocultural account in which norms co-evolve with cognition, social learning, and enforcement institutions. Moreover, while Young focuses on punishment as a strategy, Gintis integrates it as an evolved emotional mechanism, part of the human behavioral repertoire.

Gintis’s theory positions norms as culturally transmitted and biologically grounded mechanisms for sustaining large-scale cooperation. Unlike equilibrium or expectation-based theories, his model embeds norm-following in the coevolution of genes and culture, and explains persistence through multi-level selection. Norms, in his view, are:

- Emotionally regulated,
- Costly but group-beneficial,
- Transmitted via imitation and enforcement, and
- Fundamental to the evolution of human societies.

Overall, the dialogue between Lewisian conventions and social norms reflects a trajectory from descriptive equilibria towards normatively rich social arrangements. While Lewisian theory captures the elegance of coordination through common knowledge, the subsequent scholarship spanning Ullmann‑Margalit’s norm genesis, Epstein’s simulation models, Young’s evolutionary stability, Bicchieri’s conditional preferences, and Gintis’s cultural evolution reveals the layered complexity of societal regulation. Together, these perspectives elucidate how conventions can acquire prescriptive force, how norms are institutionalized and enforced, and how the interplay of rational choice, psychology, and evolutionary dynamics shapes the fabric of social life.

What has emerged as a pattern through the mentioned works is the continual relationship between conventions and norms. To make it more vivid, @oconnor2019 draws two important distinctions: 

- conventions and social norms, 
- functional and arbitrary conventions. 

First distinction means that, as we have seen, not all behavioral regularities have normative force in the sense of added layer of normativity. Friends having a convention of meeting each Friday evening at a bar, would barely be upset if someone has not showed up, because they do not possess a normative expectation or any other added layer of normativity. On the contrary, if two cars are driving on the same side of the road towards each other, the drivers are forced to swerve, for otherwise they might crash. They ought to swerve, for not only might one of them be fined but they might cause an accident. As @bicchieri2005 points out, conventions are different from social norms in the relationship between self-interest and common interest. They coincide in the former and do not necessarily coincide in the latter. In the case of friends at a bar, there is no or little tension between self-interest and common interest, while in the case of driving cars there is. O'Connor stresses that conventions and norms are the *poles of a continuum* along which the former acquire normative force.

The second distinction O'Connor draws concerns the arbitrary and historically contingent nature of conventions that they “might have been otherwise”, which we will now review.

### Overestimation of arbitrariness
Overestimation of arbitrariness is another area of criticism of Lewis's theory of conventions. Arbitrariness means that there are several equilprobable conventions which might have been otherwise. According to Lewis, arbitrariness is one of the distinguishing aspects of conventions. However, as @gilbert1992 points out, not all possible solutions to a coordination problem are equally profitable for players. In cases where one way of coordinating is more preferred than another, convention will not be that arbitrary. In other words, alternative conventions are logically justified, but pragmatically implausible as there is almost always a slight "preference" of one convention over the other due to different factors like historical accident and history of play. @oconnor2019 studied emergence of unfair norms like gendered division of labor in a similar vein. And later scholars talked about this in terms of symmetry-breaking by stochastic events [@skyrms2010; @skyrms2010a] and salience of conventions amplified by the history of iteratively played coordination game [@korbak2021a]. 

As I mentioned, @oconnor2019 sees arbitrariness as a continuum between contingency and necessity, or conventionality and functionality of conventions. Signaling between vervet monkeys might well be modeled as a convention in the Lewisian sense of repeated behavioral patterns of solving coordination problems [@harms2004; @skyrms2010]. However, this convention is not historically contingent in the sense of several possible solutions being equally profitable as Lewis supposes and as Gilbert critiques, for there are evolutionary constraints breaking the symmetry between multiple equilibria. Agents might be (and most probably are) hardwired to following certain strategies in certain environmental conditions. This distinction, as O'Connor underlines, highlights some conventions as more functional and others as more arbitrary. 

A similar line of criticism came from @burge1975, who noted that Lewisian requirement for convention to involve mutual knowledge of *alternative regularities*, or practices that could replace existing ones if widely adopted, is too strict. Conventions might fix without agents' knowledge of alternatives, Burge argued. He contended that conventions can stabilize with habit, custom or tradition, widely following Hume's original argument, and that knowledge of alternative conventions is not needed. Conventions, as Burge put forward, are not governed by any biological, psychological or sociological law, they are historically accident. In addition, agents do not necessarily deliberate to "switch" from one convention to another. In terms of game theory, Lewis required that agents know the structure of the game with its multiple equilibria, whereas Burge's notion does not. This leads to yet another point of criticism, overly intellectualist requirements for agents.

@oconnor2021 has proposed an information-theoretic measure of arbitrariness applicable to both human and "animal" conventions like alarm calls. It helps to break the distinction of functional and arbitrary conventions that she herself pinpoints [@oconnor2019]. As she is most interested in the emergence of cultural traits like gendered division of labor, she says that most cultural traits are both functional and arbitrary, or contingent, for they “might have been otherwise”.

O'Connor notes that Lewis's notion of convention emphasizes arbitrariness, for a coordination game has at least two *proper coordination equilibria*. It means that either of them might have been established equiprobably. @gilbert1992 critiqued this notion of arbitrariness and suggested that some equilibria are more favorable than others. In line with this, @simons2019 illustrated the distinction of functional and arbitrary conventions by putting it along three dimensions:

1. Payoff difference — some coordination equilibria have bigger payoffs than others;
2. Likelihood of emergence — some conventions are more likely to emerge than others;
3. Stability — once these conventions have emerged, they are unlikely to be deviated from.

O'Connor proposed to layer these dimensions onto evolutionary models, namely those of replicator dynamics. It allows for specifying what Simons and Zollman mean by the likelihood of emergence (2) and stability of conventions (3).

<!--$$-->
<!--\begin{figure}[htb]-->
<!--\centering-->
<!--\begin{tabular}{c|cc}-->
<!-- &A&B\\ \hline-->
<!--A & (1,1) & (0,0) \\ \hline-->
<!--B & (0,0) & (x,x)-->
<!--\end{tabular}-->
<!--\caption{A coordination game where B equilibrium is more favorable given $x > 1$}-->
<!--\end{figure}-->
<!--$$-->


$$
\begin{array}{|c|c|c|}
 &A&B\\ \hline
A & (1,1) & (0,0) \\ \hline
B & (0,0) & (x,x)
\end{array}
$$
**A coordination game where B equilibrium is more favorable given $x > 1$**

Modelled as replicator dynamics, the game has B equilibrium as more “natural” in the sense (1) — that of a higher payoff. The corollary of this is a larger basin of attraction, which represent the probability that each outcome evolves, given little information about the initial conditions of the population. Thus, B is more likely to emerge and is more “natural” in the sense (2).

To propose a measure of conventionality, O'Connor focuses on naturalness of conventions as their probability of emergence (2). As has been shown, different equilibria might evolve with different probability, and the sizes of basins indicate the amount of information we gain from examining an evolutionary process. The amount of information in this process is a measure of arbitrariness of a convention. It increases with greater uncertainty about what will evolve and decreases with less.

The relevant information-theoretic measure is Shannon entropy. It measures the average amount of information transmitted through a channel: 

$$H(x) = \sum_{i} P(x_{i})I(x_{i})$$

The amount of information gained from observing something is related to how much we learn or how surprised we are. It is calculated by summing the probabilities of the signals $P(x_i)$ multiplied by their informational content $I(x_{i})$, with $I(x_{i})$ equal to $-\log_{2}P(x_{i})$ — the less probable a signal, the more information it carries. Overall, this weights the probability of each signal being sent by the amount of information it carries, giving a measure of average information in the channel.

If other conditions hold, a channel has higher entropy when signals are more equiprobable or there are more signals. This is as opposed to a biased channel, with one signal sent 99% of the time, which has an entropy of just $0.08$. Therefore, more equiprobable signals and more signals lead to higher entropy. As probabilities $P(x_{i})$ represent the sizes of the basins of attraction, learning more from an evolutionary process increases the arbitrariness of an evolving phenomenon in question. Given more equilibria or if their basins of attraction are close to equal, the phenomenon is more arbitrary, contingent or “conventional”.

It is possible to measure the naturalness of a convention similar to @simons2019 using $-\log_{2}P(x)$, which represents the informational value of a particular outcome. The closer the value of $-\log_{2}P(x)$ to $0$, the more natural a convention is. This measure can be used whenever we have clear probabilities for different evolutionary outcomes. However, if there is uncertainty about the initial conditions of a population, it is possible to assign probabilities to different population starting places and not their basins of attraction, for they will not track the probability of emergence correctly. Another case is stochastic dynamics, where each starting point might lead to multiple equilibria depending on chance events. Here, $P(x_{i})$ can be defined as percentage of emergence of different equilibria in an iterated game. For example, if 10 individuals play the game in the matrix above with $x=10$ 10K times, it yields 6% chance of emergence of A, and 94% for B.

As O'Connor notes, one problem with a proposed conventionality measure is the source of probabilities. It means that inputs in an entropy equation can be selected quite arbitrarily depending on a case (ironically enough). As there are no actual chances, it can be hard to determine, whether a convention might have been otherwise. To address this worry, she underlines the *representation-dependence* of the measure. It means that we can specify what is probability in terms of a particular model or data set, for instance, basins of attraction, emergence over multiple rounds of simulation, equilibrium time and percentage of societies adopting a behaviour. This eliminates worries about probability and chance in the world. However, representations should be tailored to the intended explanatory goals. However, as representations have limitations, the proposed measure should not be taken as an absolute truth.

Another interesting approach to the notion of functionality of conventions is due to @harms2004 whi specifically studies emergence of meaning in signaling games throughout evolutionary processes. According to him, any semantic convention, or “rule”, might be considered a “function-stabilizing mechanism”, meaning that a certain convention exists, because it has been selected to meet a certain evolutionary pressure. It helps to coordinate the behavior of organisms or different parts of an organism to perform an evolutionary adapted biological function. Rules are sets of maps from conditions to processes. They say what to happen next given a state of the world. Rules for evolutionary adapted traits (AT) might be expressed as:

$$R_{AT}={\{\langle c_{i,}p_{i}\rangle} \mid AT \space sel \space p_{i}\space in \space c_i\}$$

A rule for an adaptive trait is a set of all ordered pairs of a condition and a process such that the trait was selected for performing the process $p_i$ in the conditions $c_i$ . [@harms2004, 203].

It has been observed that animal signals not only inform about the world states, but also direct the behavior of others. For example, alarm calls of vervet monkeys both convey “Look, there is a leopard!” and “Run up the nearest tree” [@seyfarth1990; @baraghith2019]. Harms calls this “primitive content” that has both indicative and imperative functions [@harms2004, 189]. Millikan calls it “pushmi-pullyu” representations and notes that purely descriptive and directive representations require a more advanced cognitive processes [@millikan2005, 166].

Evolutionary development of primitive content leads to the divergence of its descriptive and directive functions due to advanced cognitive capacities. As Harms suggested, it introduces a stabilizing, or regulatory mechanism $SM$ that works “atop” of conventions as rules for adaptive traits and guides behavior in case of failure of $R_{AT}$. It employs a corrective signal $CS = \{cs_{1}, \dots, cs_n\}$ to "enforce" the initial convention when a signal is not sent in the presence of a world state it was selected for:

$$R_{SM}={\{\langle \sigma_{i} \wedge \neg m_{j} \space where \space \langle \sigma_{i,}m_{j}\rangle} \in R_{AT} \rangle\mid SM \space sel \space cs \space when \space (\sigma_{i} \wedge \neg m_{j})\}$$

We can already see parallels with Gintis in terms of "second-order cognitive structure" implied by metacognitive tracking of a corrective mechanism. The rule for a stabilizing mechanism is a set of ordered pairs consisting of the failure of an adaptive trait in the first place and a corresponding corrective signal in the second place. If the adaptive trait fails, the stabilizing mechanism will detect this failure and send a corrective signal/action to restore it.[^regulatory-network] This division is echoed in Millikan's work as first-order and higher-order reproductive families [@millikan1987, 23]. According to it, conventions $R_{AT}$ are first-order and stabilizing mechanisms $R_{SM}$ are second-order reproductive families that serve the same goal of restoring a first-order proper function. Although quote different in nature and in used language, Harms's contribution shows how conventions can be almost purely functional and at the same time adequately incorporate proto-normativity.

[^regulatory-network]: There is an interesting similarity between a semantic regulatory mechanism like Harms' and regulatory networks in biology, that govern the dynamical repertoire of a given system like structural and regulatory genes [@albert2014], which is out of scope of this thesis.

Overall, the problem of arbitrariness in Lewis's conventions has generated fruitful responses, especially in the naturalistic camp. A tightly connected notion is that of cognitive demands and common knowledge.

### Epistemic overreach of common knowledge requirement
Common knowledge denotes an epistemic state within a group wherein a proposition *p* is known by all members, and each member knows that every other member knows *p*, recursively extending to an infinite level of iterated knowledge. This recursive nature differentiates it from mutual knowledge, which necessitates only that each individual knows *p*. Consequently, common knowledge represents an idealized, stringent condition profoundly impacting coordination and strategic interaction, prompting investigation into its feasibility and real-world relevance.

As @cubitt2003 underline, Lewis’s initial conception of common knowledge did not imply unconstrained cognitive capacity of idealized agents. As they put forward, a proposition *p* is common knowledge if a state of affairs *A* exists where everyone has a reason to believe *A* holds, *A* indicates to everyone that everyone has a reason to believe *A* holds, and *A* indicates to everyone that *p*. This definition generates an infinite chain of “reasons to believe” rather than an infinite chain of “knowledge” as justified true belief suggesting a more pragmatic approach towards achieving coordination. This approach acknowledges the limitations of human epistemic capabilities and focuses on the justification for beliefs about states of affairs and others’ beliefs about them rather than in absolute certainty on every level of iterated knowledge. Nevertheless, the majority of scholars interpret Lewisian conventions as computationally and cognitively demanding. 

@gilbert1992 criticized the infinite regress of Lewis's common knowledge. She challenged the psychologically implausible requirement of infinite levels of iterated knowledge, arguing it is unnecessary for explaining social phenomena like collective belief and convention. Gilbert proposed a framework centered on joint commitment, asserting that social facts emerge from situations where individuals are collectively committed to intend or believe something as a unified body, rather than through an infinite chain of individual beliefs about others’ beliefs. This joint commitment involves a shared intention or belief held by a group as a collective entity, irrespective of individual members’ personal convictions—for instance, a group’s shared commitment despite private doubts. This approach provides a means to understand shared social states and collective actions, generating shared obligations and expectations that drive behavior and shape attitudes, thereby avoiding the demanding epistemic requirements of common knowledge.

@bicchieri1993 argued that real-world agents operate under bounded rationality, which is more psychologically plausible. Individuals possess finite processing capacity and memory, which makes an infinite regress of knowledge untenable. Bicchieri investigated how agents form beliefs and expectations about others’ actions in coordination games, emphasizing mutual expectations and the potential for coordination through learning and repeated interactions, even without full common knowledge. She highlighted the role of *social norms*, proposing that they function through conditional preferences – individuals preferring to conform if they expect others to do so – and normative expectations, which are beliefs about what others believe one ought to do. This allows coordination to emerge and persist through observation, belief updating, and conformity, irrespective of the norm’s common knowledge status.

@heifetz1999 underscored the limitations of the common knowledge assumption in dynamic settings and games with temporal imprecision where communication is not instantaneous or unreliable. The coordinated attack problem when two parties agree to attack at the same time exemplifies how the absence of guaranteed, instantaneous communication can preclude the establishment of common knowledge, leading to suboptimal outcomes. Researchers have investigated alternative, weaker notions like finite levels of mutual knowledge or common belief to account for imperfections in real-world information and bounded rationality, offering potentially more accurate models of coordination and cooperation.

One of the more radical criticisms of the common knowledge requirement comes from evolutionary game theory, a branch of game theory pioneered by @maynardsmith1982 which assumes natural selection and evolutionary dynamics as a source of solutions for strategic games instead of rationality of self-interested actors with complete information. These criticisms doubt the necessity of common knowledge for conventions.

For example, @binmore2008 challenged the infinite levels of common knowledge posited by Lewis, arguing that agents only require first-order expectations regarding others’ behavior to converge on an equilibrium. This perspective emphasizes accurate prediction of actions as a critical element for coordination, with rational players responding accordingly. Binmore’s evolutionary approach highlighted cultural evolution’s role in shaping these common understandings and norms, suggesting societies develop and transmit effective coordination strategies over time based on promoting social stability, a dynamic process which refines coordination strategies rather than a static, pre-existing condition of full common knowledge. He also noted that Lewis's analysis of conventions confines its usage to small-scale societies as it implies observing public events being observed by another party. And this is not realistic in larger populations. Binmore suggested that conventions do not generally require common knowledge overall and can be established in evolutionary environments with only one level of reasoning instead of infinite hierarchy of beliefs. He also notes that everyday conventions mostly operate via automatic behavior and low-level mutual expectations. 

@guala2020 put forward a similar argument about "belief-less" coordination where most everyday conventions do not require iterated beliefs and hence cognitive capacities for meta-representation. Means-ends rationality and cheap heuristics are said to be sufficient[^state-of-play].

[^state-of-play]: A quite important clarification here is that to be "on the same page" about the need of common knowledge and the degree of rationality, we need to take into account the stage of a convention in question: is it just forming or is it already stable? It seems intuitive to suggest that earlier rounds of play require more explicit beliefs and cognitive demands than later rounds when strategies become more automatic and probabilities of actions of others are easier to predict. It is less costly to converge on an equilibrium in later rounds of play, so we need to be explicit about the state of play when discussing the need for common knowledge and cognitive demands of conventions.

 @schiffer1972 conceptualized common knowledge as an *infinite hierarchy of mutual knowledge*, defined recursively as follows:

- Everyone knows proposition $p$
- Everyone knows that everyone knows $p$
- This recursion continues for $n$ levels, where $n \to \infty$

Formally, common knowledge $C(p)$ is the infinite conjunction:

$$
C(p) = \bigwedge_{n=1}^{\infty} K^n(p)
$$

where $K^n(p)$ denotes the $n$-th level of mutual knowledge. This approach emphasizes *communication* as the mechanism to elevate mutual knowledge into common knowledge. For example, if two children both see mud on each other’s faces, they initially have mutual knowledge as both know there’s at least one muddy face. Only after public announcements do they iteratively reach mutual knowledge₂, mutual knowledge₃, etc., converging toward common knowledge.

@aumann1976 formalized common knowledge using *information partitions* over possible states of the world in his "agreement theorem". If $\Omega$ is the set of possible states, and $\mathcal{P}_i$ represents the information partition of agent $i$, common knowledge is an event $E \subseteq \Omega$ at state $\omega$ if the cell of the *meet* of the agents’ partitions containing $\omega$ is a subset of $E$.

A key result is Aumann’s "agreement theorem": If two rational agents with common priors have common knowledge of their posterior probabilities about an event $E$, their probabilities must coincide. Formally, if $C(p_i(E) = q_i)$ for agents $i = 1, 2$, then $q_1 = q_2$. This framework avoids explicit infinite regress by defining common knowledge as a fixed point in the agents’ information partitions.

Schiffer’s model aligns with intuitive examples like the muddy children one, where announcements progressively deepen mutual knowledge. Aumann’s approach, by contrast, provides a mathematical foundation for strategic interactions, showing how common knowledge enforces consensus among Bayesian agents. While Schiffer’s hierarchy is often seen as philosophically intuitive, Aumann’s formalism has been more widely adopted in economics and computer science due to its technical precision. Both, however, agree that common knowledge transcends mere mutual understanding, requiring agents to account for *each other’s epistemic states* in a systematic way.

The relationship between Lewis’s notion and these subsequent formalizations remains debated. Cubitt and Sugden [-@cubitt2003] suggested a fundamental distinction between Lewis’s perspective and later theories, while Vanderschraaf [-@vanderschraaf1998] and Sillari [-@sillari2005] argued for continuity between them.

For Lewis, common knowledge is a *social construct* tied to conventions. Agents coordinate because they recognize a shared basis for action, not because they explicitly compute infinite epistemic hierarchies. Schiffer formalizes common knowledge as an infinite tower of mutual knowledge $C(p) = \bigwedge_{n=1}^\infty K^n(p)$. Aumann models it via information partitions, common knowledge as the meet of agents’ partitions in $\Omega$. Both frameworks presuppose agents with unbounded logical capacity to process infinite iterations or partition intersections which contrasts with Lewis’s emphasis on pragmatic nature of coordination.

To substantiate the sharp distinction between Lewis's and Shiffman/Aumann notions of common knowledge, @cubitt2003 highlight five key areas of divergence: 

- *Epistemic and practical foundations*:
    - Lewis’s common knowledge is action-oriented and rooted in conventions (e.g., stopping at red lights)
    - Schiffer/Aumann treat it as a logical property of agents’ knowledge structures, decoupled from real-world coordination

- *Role of salience*:
    - Lewis requires salient cues (e.g., focal points) to bootstrap common knowledge
    - Schiffer/Aumann exclude salience, relying instead on axiomatic mutual reasoning

- *Bounded and unbounded rationality*:
    - Lewis’s agents operate under bounded rationality—common knowledge emerges from practical precedents, not recursive deductions
    - Schiffer/Aumann assume agents can process infinite hierarchies or partition operations, implying unbounded cognitive capacity

- *Necessity of publicity*:
    - Lewis emphasizes public events (e.g., a fire alarm) as triggers for common knowledge
    - Schiffer/Aumann reduce publicity to abstract logical or set-theoretic constructs (e.g., public announcements as partition refinements)

Cubitt and Sugden contend that Schiffer/Aumann’s formalisms fail to capture the pragmatic nature of common knowledge which involves culture and history in Lewis’s work. This disconnect, according to Cubitt and Sugden, renders Schiffer/Aumann models ill-suited for explaining real-world scenarios Lewis sought to address, such as language conventions or social norms. Their critique underscores that Lewis’s common knowledge is *procedural* and rooted in coordination practices, while Schiffer/Aumann’s is *declarative*, being a static property of knowledge structures. This philosophical and operational gap explains why formal models struggle to replicate the dynamism of Lewis’s convention-based framework.

@vanderschraaf2023 argue for *continuity* between Lewis’s convention-based notion of common knowledge and the formalizations of Schiffer/Aumann, positing that these frameworks share foundational goals and can be reconciled through careful interpretation. Their analysis emphasizes complementary perspectives rather than irreconcilable differences.

To start, both accounts (Lewis's and Shiffer/Aumann's) share a goal of explaining coordination.  Vanderschraaf and Sillari contend that Schiffer/Aumann’s models *operationalize* the abstract conditions Lewis presupposed in his conventions. For example, Aumann’s partitions can encode the "publicity" of events central to Lewis’s conventions, while Schiffer’s hierarchy mirrors the iterative reasoning agents use to infer shared expectations.

Lewis’s emphasis on *public events* like fire alarm as triggers for common knowledge aligns with Schiffer/Aumann’s focus on *public announcements* or *partition refinements*:

- In Aumann’s model, a public event $E$ corresponds to a partition cell known to all agents, which becomes common knowledge after observation
- Schiffer’s hierarchy similarly requires public communication to escalate mutual knowledge.

This bridges Lewis’s pragmatic notion of salience like a red traffic light with formal models’ requirement of shared information structures.

Next, Vanderschraaf and Sillari argue that Schiffer’s infinite hierarchy and Aumann’s partitions can accommodate *bounded rationality* in practice: 

- Agents in real-world scenarios need not compute infinite recursions explicitly. Instead, established conventions act as *focal points* that *approximate* common knowledge after a few iterations[^potenrial-recursions]
- For example, drivers stopping at a red light rely on a convention that implicitly assumes mutual knowledge up to a pragmatically sufficient level like $K^2(p)$ or $K^3(p)$, bypassing infinite regress. This is called *fixed point definition*, because it "fixes" a common knowledge as a point in probability space [@paternotte2011]. This interpretation aligns closely with cognitive realism of *relevance theory* [@wilson1999; @sperber2002], where individuals arrive at mutual understanding having found the minimally interpretable meaning of a signal which aligns with context. It is also sometimes called *fast and frugal* heuristics, which optimizes cognitive resources by using simple rules like "stop searching if found minimally adequate meaning" [@gigerenzer1999; @gigerenzer2002]. This aligns with experimental evidence using "cognitive hierarchy theory" showing that humans rarely reason beyond 2–3 levels of mutual knowledge in coordination games [@bardsley2010].

[^potenrial-recursions]: Logicians @lismont1995 contend that epistemic interactions (or belief recursions) are not actual, but potential: agents do not compute them explicitly, but *could* deduce them from the situation give adequate cognitive resources.

As Vanderschraaf and Sillari continue, Lewis’s conventions can be mapped to *fixed points* in Aumann’s partition framework:

- A convention corresponds to a *stable equilibrium* where agents’ knowledge partitions align with shared social rules
- Similarly, Schiffer’s hierarchy converges to a fixed point $C(p)$ as mutual knowledge deepens through repeated interactions.

Thus, conventions are not merely cultural artifacts but *emergent properties* of epistemic structures formalized by Schiffer/Aumann.

Vanderschraaf and Sillari reinterpret Lewis’s “salience” as a mechanism for *partition refinement* or *hierarchy truncation*:

- A salient event publicly signals a shared context, allowing agents to coordinate without infinite reasoning
- This can be modeled in Aumann’s framework by restricting the state space $\Omega$ to a subset where salience is common knowledge.

Both Lewis's and Schiffer/Aumann frameworks implicitly treat common knowledge as a *dynamic process* rather than a static state.

- *Lewis*: Conventions evolve through precedent and reinforcement
- *Schiffer/Aumann*: Mutual knowledge escalates via announcements (Schiffer) or Bayesian updating (Aumann).

This shared emphasis on iterative learning undermines Cubitt and Sugden’s “discontinuity” claim, as both traditions acknowledge that common knowledge is *constructed* through interaction.

Overall, Vanderschraaf and Sillari’s continuity thesis hinges on three claims:

1. Schiffer/Aumann’s formalisms generalize Lewis’s conventions by specifying their epistemic preconditions
2. Bounded rationality in practice truncates infinite hierarchies to match Lewis’s emphasis on pragmatic coordination
3. Salience and publicity act as bridges between abstract formal models and real-world conventions.

By framing Lewis’s work as a *procedural instantiation* of Schiffer/Aumann’s declarative structures, they argue that the frameworks are complementary, not contradictory.

Overall, Lewis's notion of common knowledge ignited ongoing debates in philosophy, cognitive science and logic regarding its nature. Throughout the thesis, I will stick with Aumann's notion of common knowledge as information partition, because our main framework for studying conventions will be Vanderschraaf's. Of course, there are other accounts of common knowledge with subtle aspects of it, which are not directly relevant to the present thesis [@paternotte2011; @monderer1989; @morris1999; @bonnay2009].

### Connection between conventions and coordination problems
Some scholars argue that conventions are not necessary for solving coordination problems, undermining Lewis's theory. @sugden2005 and @vanderschraaf1998 argue that conventions need not necessarily be solutions for coordination problems. For instance, fashion or property conventions are not like this[^coordination-fading]. Both of them have developed generalized accounts which do not require conventions to solve coordination problems. @davis2003, Marmor [-@marmor1996; -@marmor2009], @miller2001, Sugden [-@sugden1986; -@sugden2004] have argued that conventions need not be coordination equilibria.

[^coordination-fading]: However, seen dynamically, it can be argued the any convention came into being to solve a coordination problem, but after it have been established, it might have lost its initial coordinating function.  

@sugden2005 posits that conventions arise from behavioral patterns generating *mutual advantage*, independent of explicit coordination, thus rejecting Lewis’s focus on purely coordinating problems. Drawing on Hayek and Hume, he emphasizes spontaneous order of conventions which challenges the primacy of "constitutive" pre-established rules like law in governing social interactions. He argues that conventions emerge when patterns of behavior yield benefits *for all participants*, even in competitive or asymmetric situations. Unlike traditional game-theoretic models that focus on Nash equilibria, Sugden’s framework accommodates scenarios where *no clear equilibrium exists* which renders Lewis-style coordination problems too restrictive. 

Sugden introduces the concept of *team reasoning*, where individuals act on collective goals rather than individual incentives, akin to Gilbert’s joint commitment and collective intentionality but without endorsing a “plural subject” ontology. Fashion conventions emerge through independent adoption of trends perceived as advantageous for social signaling. This framework elucidates conventions in competitive scenarios lacking coordination equilibria, exemplified by property rights systems governed by historical precedent rather than coordinated agreement. 

As @davis2003 and @marmor2009 note, people follow trends for social distinction rather than coordination, yet these patterns become conventional through repeated adoption. 

@marmor2009 challenges Lewis’s emphasis on coordination problems, arguing instead for an analysis grounded in actual games like chess, distinct from the theoretical “games” favored by game theorists. His main argument is that there are deeper conventions like truth-telling which make Lewis-style coordination possible. He outlines three conditions for a rule to be considered conventional:

1. A population $P$ normally follows rule $R$ in circumstances $C$
2. There is a reason $A$ for members of $P$ to follow $R$ in circumstances $C$
3. There exists at least one alternative rule $S$, such that if members of $P$ had followed $S$ instead of $R$, $A$ would still have been a sufficient reason for following $S$, partly because $S$ was generally followed instead of $R$. Rules $R$ and $S$ are mutually exclusive in the given circumstances.

Marmor draws two distinctions: 

- coordination / constitutive conventions
- "deep" / "surface" conventions 

Coordination conventions solve Lewis-style problems like driving sides by aligning actions for mutual benefit and depend on shared expectations and mutual compliance. Constitutive conventions create social practices or classes thereof like chess rules which constitute the game of chess itself. Marmor argues that constitutive conventions emerge as responses to complex social needs and are foundational to many practices, including legal systems. Unlike coordination conventions, they do not depend on mutual expectations but instead define the ontology of the practice. Deep conventions are foundational norms that underpin social practices and are less amenable to change. For example, truth-telling is a deep convention necessary for effective communication. In its turn, surface conventions are more specific instantiations of deep conventions and vary across contexts. For instance, particular linguistic rules like grammar are surface conventions based on deeper norms like truth-telling.

@millikan2005 presents a radically biological perspective on conventions, diverging significantly from economic and sociological approaches. Her core argument posits that a convention is fundamentally a behavior pattern sustained within a population through the mechanism of replicated precedent. Notably, Millikan rejects the prevailing tradition, exemplified by Hume and Lewis, which attributes social order to the rational decisions of individual agents. She explicitly denies any role for rationality in convention maintenance, asserting that a society upholding a convention solely through unreflective conformity would fulfill her definition. While Burgé similarly emphasizes factors beyond enlightened self-interest including inertia, superstition, and ignorance, Millikan’s position is more extreme, entirely excluding any rational underpinning for convention stability.

For Millikan, conventions persist through replication adjusted according to the weight of precedent, where current patterns derive from prior instances. They are arbitrary and contingent as their stability is dictated neither by optimal design nor conformity of the majority. Instead, it is influenced by its effective functional performance which might have been achieved with other patterns and does not require conscious adherence to rules. Millikan’s approach characterizes conventions as descriptive regularities which are emergent, stabilized patterns replicated through unconscious imitation, allowing for flexible adaptation without rigid definitions or universal agreement. For example, language speakers do not consciously follow a rule when calling a book a “book”. Instead, they simply replicate the behavior they have observed and linguistic conventions can be disobeyed without incurring sanctions, unlike rules in a normative sense. This contrasts with Lewis’s high-demanding view of mutual expectations, common knowledge and inherent normativity. However, it resembles Guala's notion of "belief-less" coordination.

Millikan distinguished three types of coordination: 

- *blind coordination*, where participants act without knowledge of each other’s actions (e.g., traffic systems in Lewisian examples)
- *half-blind coordination*, where one party anticipates the other’s behavior based on precedent (e.g., linguistic communication)
- *open coordination*, where both parties fully anticipate each other’s actions.

Linguistic conventions predominantly fall into half-blind coordination. 

Millikan’s biological perspective frames conventions as analogous to evolutionary processes:

- Just as genes propagate based on their fitness, cultural conventions proliferate because they serve useful functions for individuals or groups
- The “proper function” of a convention is its capacity to achieve specific outcomes (e.g., facilitating communication) effectively over time.

The notion of function will be important later as it is used in contemporary theories of social institutions as strategic equilibria [@guala2015] which try to smuggle biological functions and generate controversy over the very notion and its relation to convention.

This concludes the overview of criticisms of Lewis's theoy of conventions and broader problems it generated. In the next section, we will look into the important refinements of Lewis's theory which will be of central importance in the next chapters, when we will discuss game-theoretic approaches to social ontology and the problem of ontic reference it generates.

## Extensions and refinements
Lewis's theory of conventions became a starting point for formal research on conventions and later scholars refined his theory, sometimes to an unrecognizable extent. There are many refinements, but we will consider only most important for the topic of emergence of social institutions from animal conventions. We will cover equilibria concept refinements by Vanderschraaf and Skyrms and the notion of salience in its relation to arbitrariness/functionality of conventions. As we will see, all these aspects will come together in shaping the notion of naturalistic account of social institution in the next chapter.

As I have mentioned in the previous section, imprecise equilibrium concept was among the popular criticisms of Lewis's theory, and this component has been actively worked and elaborated on. Two notable reformulations of conventions are as *correlated equilibria* (CE) and *evolutionary stable strategies* (ESS). We start by studying them.

### Vanderschraaf's *inductive deliberation* as a source of salience
Vanderschraaf [-@vanderschraaf1995; -@vanderschraaf1998; -@vanderschraaf2001] redefined social conventions as CE through *inductive learning*, positioning conventions as foundational to achieving justice as mutual advantage. He formalized the notion of salience (or focal points) as information partitions and employed the *Dirichlet rule*[^dirichlet] to show how agents sequentially update their beliefs about others' strategies to gradually arrive at an equilibrium *endogenously*, without explicit external signal.

[^dirichlet]: The Dirichlet rule is a Bayesian updating procedure based on the Dirichlet distribution used for modeling probabilities over a finite set of discrete outcomes ("a distribution over distributions"). In learning models, the Dirichlet rule updates the probability assigned to each probability distribution by counting the number of times each of them has produced a particular outcome such as a reward. These counts serve as parameters of the Dirichlet distribution, which then yields a probability distribution over the options. Formally, if option $j$ has been rewarded $\gamma_j$ times, the updated probability for option $j$ is proportional to $\gamma_j$, and the probability vector $\mathbf{x} = (x_1, ..., x_k)$ over $k$ options is such that $x_j \in (0,1)$ and $\sum_{j=1}^k x_j = 1$. This rule captures how empirical frequencies shape probabilistic beliefs in a principled Bayesian manner. 

Lewis considered a coordination equilibrium a convention if the players have common knowledge of mutual expectations. Vanderschraaf calls this mutual expectation criterion (MEC). Each agent has a decisive reason to conform to their part of the convention, expecting the other agents to do likewise. Lewis stated that an equilibrium must be a coordination equilibrium to reflect the notion that a person conforming to a convention wants their intention to be seen as such. Vanderschraaf calls it the public intentions criterion (PIC). Furthermore, Lewis argues that common knowledge of the MEC is necessary for a convention. However, as Vanderschraaf notes, it is not sufficient, since common knowledge of the MEC can be satisfied at any strict Nash equilibrium.

According to Vanderschraaf, a convention constitutes a strategy profile $\sigma^* = (\sigma_1^*, \ldots, \sigma_n^*)$ where each agent $i$ maximizes expected utility such that $\mathbb{E}[u_i(\sigma_i^*, \sigma_{-i}^*)] \geq \mathbb{E}[u_i(\sigma_i', \sigma_{-i}^*)]$ for all alternative strategies $\sigma_i' \neq \sigma_i^*$, ensuring stability against unilateral deviations.

The formation of conventions operates not through cognitively expensive rational deliberation, but through relatively cheap *inductive learning* mechanisms. Agents employ *Dirichlet dynamics* to update beliefs about opponents' strategies. This updating process describes how agents repeatedly revise their beliefs by incorporating new observations of others’ behavior. A *deliberational equilibrium* is then defined as a fixed point of this learning dynamic, where agents’ beliefs stabilize. The stabilized joint beliefs and strategies that emerge from this iterative updating correspond to what Vanderschraaf calls *endogenous correlated equilibrium* (ECE)[^ece]: a CE arising internally from the agents’ inductive learning and mutual belief revision, rather than from an external correlation device as it is usually presented in broader game theory literature[^choreographer]. @kono2008 has mathematically proven how ECE is possible and that distributions of ECE and exogenous CE are completely different. The Dirichlet dynamics responsible for arriving at ECE is modeled as follows:

[^ece]: The distinction between "exogenous" and "endogenous" information influencing agent's strategy choice is already in @aumann1987. The former type of information is obtained from external cues and the latter from agents' reasoning about about how other agents reason. Aumann did not consider the distinction important, for the knowledge of exogeneity/endogeneity of agents' information or even actions does not contribute to achieving CE. Vanderchraaf's usage of Dirichlet dynamics clarified how endogeneity can contribute but did not eliminate the external signal altogether.

[^choreographer]: Many scholars use metaphors emphasizing the external character of CE: "mediator" and "correlation device" [@fudenberg1991], "choreographer" [@gintis2009a] and others. 

$$p_{t+1}(s_{-i}) = \frac{n_{s_{-i}} + \alpha_{s_{-i}}}{\sum_{s'_{-i}} (n_{s'_{-i}} + \alpha_{s'_{-i}})}$$

where $n_{s_{-i}}$ represents observed strategy profiles and $\alpha_{s_{-i}}$ denotes prior beliefs [@vanderschraaf2018]. Repeated interactions lead to path-dependent emergence of focal points, particularly in bargaining scenarios. Two prominent conventions arise: equal division of goods ($x_i = \frac{1}{n}$) and egalitarian payoff distributions satisfying $u_i(x_i) - u_i(d) = u_j(x_j) - u_j(d)$ for all agents $i,j$, where $d$ represents disagreement payoffs [@vanderschraaf1995].

An important part of Vanderschraaf's theory of conventions is his contribution to moral philosophy and theory of justice. He grounded principles of justice in conventions that generate Pareto improvements[^pareto] over non-cooperative baselines. A just convention $\sigma^J$ must satisfy $u_i(\sigma^J) \geq u_i(\sigma^B)$ for all agents $i$, where $\sigma^B$ denotes the baseline equilibrium [@vanderschraaf2018]. 

This requirement addresses the vulnerability objection to justice theories which fail to adequately protect the most vulnerable persons. It does so by ensuring that conventions benefit even the least advantaged participants, creating mutual advantages that stabilize social arrangements. The framework reconciles Humean conventionalism with game theory, demonstrating how justice emerges from repeated coordination problems rather than abstract moral principles[^oconnor].

[^pareto]: Pareto efficiency describes a state where no further improvements are possible for well-being of any individual without simultaneously decreasing the well-being of at least one other individual.

[^oconnor]: Ironically enough, @oconnor2019 uses similar ideas to study the emergence of injustice and maintains that unjust arrangements amplify over time.

<!--Vanderchraaf notes that conventions as CE allow for characterization of a wide range of equilibria. Given a game $\Gamma$ with pure strategy coordination equilibria $\mathbf{A}_1, \ldots, \mathbf{A}_m, m \geqslant 2$, and a lottery $\Omega$ with mutually exclusive outcomes $H_1, \ldots, H_m$ such that $p_k\left(H_j=\lambda_j\right)$ for each player $j$. Then if the players condition on $\mathscr{H}=\left\{H_1, \ldots, H_m\right\}$, and $f: \Omega \rightarrow S$ is defined by $f(\omega)=\mathbf{A}_j$ if $\omega \in H_j$, then inequality is satisfied for all $\omega \in \Omega$, making $f$ a convention. With infinitely many possible values for the $\lambda_j$'s, any noncooperative game with two or more pure strategy coordination equilibria has infinitely many correlated equilibria corresponding to conventions.-->

As can be seen, convention as CE allows for more “fair” coordination, even though no pure strategy equilibrium exists as we saw earlier with the “Battle of Sexes” game example. To reiterate, neither of the pure strategy Nash equilibria in this game is "fair", in the sense that the players receive the same payoff.

<!--This game has a mixed Nash equilibrium at which Husband plays $A1$ with probability $\frac 2 3$ and Wife plays $A2$ with probability $\frac 2 3$, and at this equilibrium each player's expected payoff is $\frac 2 3$, so this equilibrium is "fair". However, at the mixed Nash equilibrium, both players are indifferent to the strategies they play given what each player believes about her opponent, so this equilibrium fails the PIC and is consequently not a convention. Nevertheless, there is a correlated equilibrium fair to both players, and which each player will prefer over the pure strategy equilibrium that is unfair to them.-->

<!--\begin{table}[h]-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|}-->
<!--\hline-->
<!--& $A1$ & $A2$ \\-->
<!--\hline-->
<!--$A1$ &$10, 7$ &$0, 0$\\-->
<!--\hline-->
<!--$A2$ &$0, 0$ &$7, 10$ \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{\small "Battle of sexes" game}-->
<!--\end{table}-->

This game has a mixed Nash equilibrium at which both agents play their strategies with probability $\frac 2 3$, yielding an expected payoff of $\frac 2 3$ for each agent. However, this equilibrium does not satisfy the PIC and is thus not a convention. Nevertheless, there is a correlated equilibrium that is fair to both players and preferable to the pure strategy equilibrium. With a toss of a fair coin, there is a probability space $\Omega = \{H, W\}$ with "heads" and "tails". The agents have a common information partition $\mathscr{H} = \{\{H\},\{W\}\}$ and the correlated strategy combination is denoted as a function $f: \Omega \rightarrow \{A 1, A 2\} \times \{A 1, A 2\}$ with $f(H) = (A 1, A 1)$ and $f(W) = (A 2, A 2)$. Husband has a higher expected payoff with this combination than any of the other strategies, so he will not deviate from it. The expected payoff for Husband is $2$ if the outcome is $H$, and $1$ if it is $W$.

$$
\begin{aligned}
& \left.E\left(u_1 \circ f \mid H\right)=2>0=E\left(u_1(A 2, A 1)\right) \mid H\right), \text { and } \\
& E\left(u_1 \circ f \mid W\right)=1>0=E\left(u_1(A 1, A 2) \mid W\right)
\end{aligned}
$$

The same holds for the second player. To this end, neither player would want to deviate, since the overall expected payoff at this equilibrium for each player is

$$
E\left(u_k \circ f\right)=\frac{1}{2} \cdot E\left(u_k \circ f \mid H\right)+\frac{1}{2} \cdot E\left(u_k \circ f \mid T\right)=\frac{3}{2}
$$

It means that each player prefers the expected payoff from $f$ to that of the mixed equilibrium.

For Vanderschraaf, a convention is a mapping of “states of the world” to strategy combinations of a noncooperative game [@vanderschraaf1995, 69]:

A *game* $\Gamma$ is an ordered triple $(N, S, \mathbf{u})$ consisting of the following elements:

1. A finite set $N ={\{1,2, …, n\}}$, called the *set of players*;
2. For each player $k \in N$, there is a finite set $S_{k}= \{{A_{k_{1}}, A_{k_{2}},\dots, A_{kn_{k}}}\}$, called the *alternative pure strategies* for player $k$. The Cartesian product $S = S_{1} \times \dots \times S_n$ is called the *pure strategy set* for the game $\Gamma$;
3. A map $\mathbf{u}: S \rightarrow \mathbb{R}^n$, called the *payoff function* on the pure strategy set. At each strategy combination $\mathbf{A} = (A_{1j_1}, \dots, A_{nj_{n})}\in S$, player $k$’s payoff is given by the $k$-th component of the value of $\mathbf{u}$, that is, player $k$’s payoff $u_k$, at $\mathbf{A}$ is determined by $$u_k(\mathbf{A}) = I_{k} \circ \mathbf{u} (A_{1j_1}, \dots, A_{nj_n}),$$

where $I_k(\mathbf{x})$ projects $\mathbf{x} \in \mathbb{R}^n$ onto its $k$-th component.

As Vanderschraaf builds on Aumann's model [-@aumann1987], each player has a personal *information partition* $\mathscr{H}_k$ of a probability space $\Omega$. Elementary events on $\Omega$ are called *states of the world*. At each state $\omega$, each player $k$ knows which element $H_{kj}\in \mathscr{H}_k$ has occurred, but not which $\omega$. $H_kj$ represents $k$'s private information about the states of the world. While $k$ knows the opponent partitions, she does not know their content. A function $f: \Omega \rightarrow S$ defines a *exogenously correlated strategy $n$-tuple*, such that at each state of the world $\omega \in \Omega$, each player $k$ selects a strategy combination $f(\omega)=(f_1(\omega),\dots,f_n(\omega))\in S$ correlated with the state of the world $\omega$. Thus, by playing $f_k(\omega)$, $k$ follows *Bayesian rationality* and maximizes expected payoff given private information and expectations regarding opponents.

In addition, given $\Gamma = (N, S, \mathbf{u})$, $\Omega$, and the information partitions $\mathscr{H}$ of $\Omega$ as defined above, $f:\Omega \rightarrow S$ is a *correlated equilibrium* if and only if, for each $k \in N$,

1. $f_k$ is an $\mathscr{H}_k$-measurable function, that is, for each $H_{kj}\in \mathscr{H}_k$, $f_k(\omega)$ is constant for each $\omega' \in H_kj$, and
2. For each $\omega \in \Omega$, $$E(u_{k} \circ f|\mathscr{H}_k)(\omega) \geq E(u_{k} \circ (f_{-k}, g_k)|\mathscr{H}_k)(\omega)$$

where $E$ denotes expectation, '$-k$' refer to the result of excluding the $k$-th component from an $n$-tuple. This holds for any $\mathscr{H}_k$-measurable function $g_{k}: \Omega \rightarrow S_k$. The correlated equilibrium $f$ is *strict* if and only if the inequalities are all strict.

The measurability restriction on $f_k$ means that $k$ knows her strategy in each $\omega$. This definition implies that players have common knowledge of the payoff structure, partitions of $\Omega$, and $f: \Omega \rightarrow S$, which is needed to compute expected payoffs and reach correlated equilibrium. In addition, if the players possess common knowledge of Bayesian rationality, they will follow their ends of $f$, expecting others to do the same, since they jointly maximize expected utility in this way.

The agents refer to a common information partition of the states of the world. While each agent $k$ has a private information partition $\mathscr{H}_{k}$ of $\Omega$, there is a partition of $\Omega$, namely the intersection $\mathscr{H}=\cap_{k \in N}\mathscr{H}k$, of the states of the world such that for each $\omega \in \Omega$, all the agents will know which cell $H(\omega) \in \mathscr{H}$ occurs. The agents' expected utilities in the following Definition 3 are conditional on their common partition $\mathscr{H}$, reflecting the intuition that conventions rely upon information that is public to all.

The agents' expected utilities are conditioned on their common information common partition $\mathscr{H}$ of the states of the world, which is the intersection of all their private partitions $\mathscr{H} = \cap_{k \in N}\mathscr{H}_k$. This reflects that conventions depend on information available to all agents.

Given $\Gamma=(N, S, \mathbf{u}), \Omega$, and the partition $\mathscr{H}$ of $\Omega$ of events that are common knowledge among the players, a function $f: \Omega \rightarrow S$ is a convention if and only if for each $\omega \in \Omega$, and for each $k \in N, f_k$ is $\mathscr{H}$-measurable and

$$
E\left(u_k \circ f \mid \mathscr{H}\right)(\omega)>E\left(u_k \circ\left(f_{-j}, g_j\right) \mid \mathscr{H}\right)(\omega)
$$

for each $j \in N$ and for any $\mathscr{H}$-measurable function $g_j: \Omega \rightarrow S_j$.

It means that if any player $j$ deviates from a convention $f$, every player $k \in N$, including $j$, will be worse off. This definition of convention as a strict correlated equilibrium satisfies the PIC, as *all agents are aware of the common partition and the strategies each player is expected to play*. Thus, if any opponent mistakenly thinks that a player $k$ will play a strategy $g_k(\omega) \neq f_k(\omega)$ other than the one prescribed by $f$, they may be tempted to deviate, resulting in a worse-off outcome for $k$. Conversely, if all opponents are aware that $k$ will play her strategy $f_k(\omega)$ at each state of the world $\omega \in \Omega$, then they have a strong incentive to conform with convention $f(\omega)$, which gives $k$ an improved outcome.

Overall, Vanderschraaf's contribution is formalization of salience, hence he uses the *common* information partition $\mathscr{H}$ as a necessary restriction to make the definition of convention conform with Lewis's spirit. The other question is how salience itself emerges. Lewis suggested that pre-game communication, precedent, and environmental cues may lead agents to link their expectations and actions with various "states of the world", thus achieving equilibrium. However, these sources of salience face the problem of infinite regress, for it is unclear how precedent or pre-game communication occurred in the first place without an established and shared conventional rules. Vanderschraaf, along with Skyrms [@vanderschraaf1993], proposed *inductive deliberation* as a mechanism by which salience is being established. It *requires agents to be Bayesian-rational* and works by *recursive belief modification*. Players can reach a correlated equilibrium without communication by dynamically updating their beliefs using a common inductive rule, even if their beliefs don't initially allow for an equilibrium.

We see here Bayesian rationality, dynamical updating and capacity for recursive beliefs as features of a certain *cognitive architecture* of an agent, a characterization of their cognitive capacities which influence their behavior. As we will see later, this implicit notion of agent's cognitive architecture will be important in the discussion of social ontology in the next chapter.

Another significant extension of Lewis's theory is related to redefining conventions as ESS and is due mostly to Skyrms.

### Skyrms's evolutionary approach to conventions
Skyrms integrated Lewis’s theory of conventions into an evolutionary framework. He showed how signaling conventions can emerge naturally with adaptive processes like evolution and learning in agents with limited cognitive sophistication which overcomes Lewis's reliance on common knowledge [@skyrms2010]. 

Although Skyrms has almost established an entire research program with many followers [@huttegger2007a; @huttegger2007; @oconnor2020; @lacroix2020; @franke2014] and we will take a closer look at his generalization of Lewis's signaling models later in this section, I suggest he would not have done it without his earlier and less-known contribution to game theory which has to do with generalization of the ESS solution concept.

The ESS, or evolutionary stable strategy, being a foundational solution concept in evolutionary game theory formulated by @smith1973 is a strategy that, if adopted by majority of population, cannot be invaded by any mutant strategy. Crucially, this concept implies random matching[^pairing], where individuals are paired for strategic interactions independently of their types, such that the probability of encountering any strategy is only proportional to its overall population frequency. While this assumption simplifies analysis and yields elegant theoretical results, it limits the applicability of ESS to well-mixed populations and fails to capture the complexity of structured or socially embedded interactions.

[^pairing]: Random matching is a standard assumption in evolutionary game theory where individuals in a large, well-mixed population are paired to interact purely by chance, meaning each individual is equally likely to meet any other, regardless of their strategy. This context is important because, under random matching, the ESS depends solely on the average payoffs determined by the overall population frequencies, and strategies like cooperation typically cannot persist unless they are directly favored by the payoff structure. Deviations from random matching (assortative or structured matching) can introduce correlations between strategies, fundamentally altering which behaviors can be evolutionarily stable [@jensen2018; @izquierdo2024]. 

Skyrms recognized that ESS does not generate *stable* strategies with non-random matching arising from mechanisms like kin selection, signaling systems, spatial or social structures. These correlations induce interactional dependencies increasing the probability of similar-strategy encounters. Such dependencies drastically alter the evolutionary dynamics and can stabilize strategies such as cooperation or signaling conventions that would be unstable or unsustainable under classical ESS assumptions [@skyrms1994].

This led Skyrms to establishing "adaptive ratifiable strategy" as a generalization ESS that incorporates the endogenous structure of interactions, making it a more realistic predictor of evolutionary outcomes. A strategy is adaptive-ratifiable if it maximizes expected fitness when it is nearly fixed in the population, taking into account the conditional probabilities of interacting with other strategies. This concept ensures dynamic stability under replicator dynamics where correlation affects interaction frequencies [@skyrms1994].

The notion of adaptive ratifiable strategy made another Skyrms's concept possible. That of "correlated convention" [@skyrms2014], which is conventions as stable yet not necessary Pareto optimal behavioral patterns made possible due to interactional dependencies of any kind between agents. Skyrms explored many possibilities for such correlation like spatial interaction [@alexander1999], social structure [@skyrms2003], social networks [@skyrms2004] and finally signaling systems [@skyrms2010a]. However, as we will see in the second chapter of the thesis, Skyrms's "correlation" is different from Vanferschraaf's.

Skyrms’s approach to conventions differs from Lewis’s in not relying on common knowledge and substituting it with evolutionary pressures which make conventions arise and persist. He showed that even simplest organisms like bacteria can arrive at signaling systems akin to Lewisian conventions with the aid of simple adaptive mechanisms like mutation-selection or reinforcement learning (RL) [@skyrms2014].

Skyrms explored various learning dynamics that enable signaling systems to emerge in populations. For example:

- *Simple RL* where agents adjust their strategies based on trial-and-error feedback from successful interactions. In a basic Lewis-Skyrms signaling game setup with 2 world states, 2 signals and 2 actions, senders and receivers begin with random dispositions and gradually reinforce successful pairings between states, signals, and actions.

- *Win-Stay/Lose-Shift dynamics* where agents establish conventions more rapidly than simple reinforcement learning. This dynamic involves sticking with successful strategies while shifting away from unsuccessful ones, enhancing convergence speed and stability.

Skyrms's framework models conventions as stable equilibria of sender-receiver games that evolve via RL and evolutionary dynamics rather than rational deliberation. Formally, a signaling game involves:

- a set of states of the world $S = \{s_1, s_2, \ldots, s_n\}$
- a set of signals $M = \{m_1, m_2, \ldots, m_k\}$
- a set of acts $A = \{a_1, a_2, \ldots, a_l\}$. 

The sender observes a state $s \in S$ and chooses a signal $m \in M$ to send. The receiver, upon receiving $m$, chooses an action $a \in A$. The payoffs $u_S(s, m, a)$ and $u_R(s, m, a)$ for sender and receiver respectively depend on how well the receiver’s action matches the state. Unlike Lewis’s model, which assumes common knowledge of salience to coordinate on a unique equilibrium, Skyrms shows that conventions can emerge through adaptive processes even when initial behaviors are random and no focal points exist.

A central concept in Skyrms’ analysis is the informational content of signals, which he quantifies using information-theoretic measures. Given a prior probability distribution over states $P(S_i)$ and a posterior distribution conditioned on a signal $m$, denoted $P(S_i \mid m)$, the information conveyed by $m$ can be expressed as the vector of log-likelihood ratios:

$$
\left( \log_2 \frac{P(S_1 \mid m)}{P(S_1)}, \log_2 \frac{P(S_2 \mid m)}{P(S_2)}, \ldots, \log_2 \frac{P(S_n \mid m)}{P(S_n)} \right).
$$

where $P(S_i)$ represents prior probabilities of states and $P(S_i \mid m)$ denotes posterior probabilities conditioned on a signal $m$. This formalization bridges Lewis’s conceptual framework with mathematical models of communication.

This measure captures how a signal updates the receiver’s conditional strategy choice given the state of the world, thereby guiding action selection [@skyrms2010].

Skyrms further explores signaling equilibria under conditions of partial alignment or conflict of interests between sender and receiver. In such cases, the equilibrium strategies may involve deceptive or partially informative signals. Formally, if a sender’s payoff function $u_S$ differs from the receiver’s $u_R$, the equilibrium concept extends to signaling equilibria where strategies $\sigma_S: S \to \Delta(M)$ and $\sigma_R: M \to \Delta(A)$ satisfy mutual best responses:

$$
\sigma_S(s) \in \arg\max_{m \in M} \mathbb{E}_{a \sim \sigma_R(m)}[u_S(s, m, a)], \quad \sigma_R(m) \in \arg\max_{a \in A} \mathbb{E}_{s \sim P(\cdot \mid m)}[u_R(s, m, a)],
$$

where $\Delta(X)$ denotes the set of probability distributions over $X$ [@skyrms1996].

The evolutionary dynamics driving the emergence of conventions are often modeled through RL algorithms such as the Roth-Erev model [@erev1998]. Agents maintain propensities $q_{i}(x)$ for choosing actions $x$ (signals or responses), which are updated iteratively according to received payoffs:

$$
q_{i}^{t+1}(x) = q_{i}^t(x) + \alpha \cdot \left( r_i^t(x) - q_i^t(x) \right),
$$

where $\alpha$ is a learning rate and $r_i^t(x)$ is the reward at time $t$ for action $x$ [@skyrms2010]. Over repeated interactions, these learning dynamics lead to convergence on stable signaling conventions without requiring explicit coordination or rational foresight.

Transmission of information in signals and emphasis on *informational content* of a signal generated a heated debates in philosophy of biology critiquing Skyrms for the lack of causation [@shea2018a; @godfrey-smith2020; @harms2004] and over-reliance on statistical connection instead of functional one.

An interesting part of Skyrms's extension of Lewis's signaling game is its implicit reliance on epistemic language of "observing" states of the world and "interpreting" signals for "updating beliefs". Although Skyrms utterly rejects any Bayesian interpretation of his signaling games [@lacroix2020a], he is sometimes interpreted as a incurring epistemology to his agents, especially when his theory is discussed side-by-side with natural theories of mental content [@millikan1987; @millikan2004; @baraghith2019; @harms2004]: that senders "represent" world states and transmit this public representation to a receiver who then "interprets" it with its own mental states. Consider vervet monkeys' alarm calls. They can easily be described as involving mental states of "representing" an eagle and sending a certain signal to fellows monkeys who "decode" that public representation and map it onto suitable action. While plausible and the case for most natural theories of mental content like @millikan2004, it is not the case for Skyrms. 

Although the structure of Lewis-Skyrms game mirrors the flow of information in epistemic contexts (state-signal-action pairings) and it is tempting to treat senders and receivers as Bayesian-rational, the Skyrmsian agents update their *behavioral dispositions* rather than beliefs as they do not possess any inference and can only adjust their mappings according to failure rates [@skyrms2012]. 

Skyrms's sender-receiver system is an *information channel* focusing on how effective codes (signal-meaning pairings) arise and stabilize, not on agents’ beliefs or intention. His signaling games are mechanistic as Maynard Smith's, for they take into account only objective, or "ontic", features of agents like strategy frequency across population or, in case of signaling game, *mappings* from state to signal and from signal to action in accordance to the rate of coordination failures. Compare Lewis-Skyrms game 

$$
\begin{array}{ccccc}
World & \xrightarrow{state} & Sender & \xrightarrow{Message} & Receiver & \xrightarrow{act} & {} \\
\end{array} \\
$$

with Shannon's information channel:

$$
\begin{array}{ccccc}
Source & \xrightarrow{original \quad message} & Encoder &\xrightarrow{signal} & Channel & \xrightarrow{signal} & Decoder & \xrightarrow{decoded \quad message} & {} \\
\end{array}
$$

@martinez2019 proposes a "channel-first" view on signaling games and argues that the central behavioral unit of Lewis-Skyrms games is not strategies, but the *encoding-decoding pair* which is similar to *mappings* from above. 

In this framework, world states, signals and actions can be represented as *random variables* $S$, $M$ and $A$, each of which is a set of discrete units like states, messages and actions like $[S_1, \dots, S_s]$ together with a probability distribution $[Pr(S_1), \dots Pr(S_s)]$ over them. The same applies to messages and actions.

A sender observes the current state and transmits a signal – one of $m$ possible signals. The receiver detects this signal and chooses an action, $A_i$, from a set of available actions. Both the signal sent and the action chosen are random variables.

The probabilities for the random variables are linked through the sender’s and receiver's strategies which are a probability matrices of signals given world states of acts given signals respectively.

$$
\left[\begin{array}{ccc}
\operatorname{Pr}\left(M_1 \mid S_1\right) & \ldots & \operatorname{Pr}\left(M_m \mid S_1\right) \\
\vdots & \ddots & \vdots \\
\operatorname{Pr}\left(M_1 \mid S_s\right) & \ldots & \operatorname{Pr}\left(M_m \mid S_s\right)
\end{array}\right]\left[\begin{array}{ccc}
\operatorname{Pr}\left(A_1 \mid M_1\right) & \ldots & \operatorname{Pr}\left(A_a \mid M_1\right) \\
\vdots & \ddots & \vdots \\
\operatorname{Pr}\left(A_1 \mid M_m\right) & \ldots & \operatorname{Pr}\left(A_a \mid M_m\right)
\end{array}\right]
$$

As per criticisms of Skyrms's approach to Lewisian signaling games, @martinez2019 argues that Skyrms did not go far enough into information theory and allowed informational analysis only *after* sender and receiver adopted the strategies which does not explain *how they arrived* at them. Martinez suggests using Shannon's rate-distortion function [@shannon1948] to show minimum mutual information between states and acts with minimum rate of distortion. It allows him to recast payoffs as distortion indicators in the channel. Seen with this lens, a coordination game of signaling, even that involving deception, as an information channel looks more cooperative.

Overall, Skyrms's extension of Lewis's theory of conventions has dropped rationality requirements and introduced a more naturalistic account of signaling systems in a broader context. Crucially, it implies a minimal cognitive architecture (or a lack of it) drastically different from Bayesian-rational agents of Vanderschraaf.

### Salience in coordination games: epistemic and natural 
Although both Vanderschraaf's and Skyrms's refinements of Lewis's theory might seem concerned  only with its formal details, they essentially tackle a wider problem of *salience* or *focality* of strategies which is tightly connected with "common knowledge" problem: how and why some strategies (and profiles thereof) "stand out" in the face of other arbitrary arrangements for potential conventions.  Vanderschraaf formalizes salience as information partition of agents' joint probability distribution and Skyrms formalizes it as emergent property of interactional asymmetry of agents' or environment's properties in evolutionary rather than Bayesian "update". Here we briefly review approaches to the problem of salience of strategies as they will be relevant in the next chapters.

We can distinguish between two types of salience: epistemic [@zachnik2021; @mehta2021] and natural [@vandrunen2023]. Broadly speaking, epistemic salience has to do with beliefs of agents, whereas natural salience arises from environmental features or cues to which agents attend.

For Lewis, as he wanted to build upon Schelling's concept of "focal point", salience was unquestionable, but its very notion generated problems as to why and how certain features of environment, history and culture become relevant as cues external to coordination games in the first place. Schelling pointed out that to look for and *recognize patterns* might be an essential feature of human nature [@schelling1980, 104]. Observable patterns, he argued, presuppose their observability, hence it is rational to expect an opponent to behave according to such patterns and thus deduce intentions of another opponent [@schelling1980, 104]. A similar notion is found in "Relevance theory" [@wilson1999; @sperber1996] in cognitive science, where an signal presupposes its optimal relevance, meaning that a signal is "articulated enough" across any sensory modality it is automatically worth noticing, implying that it is a universal feature of human and possible animal cognition. Consider a game-theoretic example from @guala2015.

Dinka and Nuer tribes graze their cattle on two sides of the river Sobat. After the river dried up, its physical barrier disappeared, creating a Hawk-Dove conflict[^hawk-dove] over grazing lands where both tribes risked costly clashes if they chose the same territory. The dry riverbed, however, remained a salient and mutually recognized landmark, providing a natural coordination device that allowed the tribes to condition their grazing strategies on its location, thereby avoiding conflict without direct communication. This focal point effectively transformed the game by correlating strategies and expectations, stabilizing a peaceful equilibrium. The game matrix below has strategies "Graze", "Not graze", "Graze if North" and "Graze if South".

[^hawk-dove]: In this game, two players can choose to be either a hawk (fight for resources), dove (submit and share resources), or bourgeois (submit only when opponent is also bourgeois). The payoffs are determined by the value of the resource and the cost of fighting

<!--\begin{table}[h]-->
<!--\centering-->
<!--\begin{tabular}{|c|c|c|c|}-->
<!--\hline-->
<!--& $G$ & $NG$ & $GIS$ \\-->
<!--\hline-->
<!--$G$ &$-1$ &$2$ &$0.5$\\-->
<!--\hline-->
<!--$NG$ &$0$ &$1$ &$0.5$ \\-->
<!--\hline-->
<!--$GIN$ &$-0.5$ &$1.5$ &$1.0$ \\-->
<!--\hline-->
<!--\end{tabular}-->
<!--\caption{\small Grazing game: the player strategies are Graze, Not Graze and Graze if North / Graze if South}-->
<!--\end{table}-->

$$
\begin{array}{|c|c|c|c|}
\hline
& G & NG & GiS, NGiN \\
\hline
G & 0,0 & 2,1 & 1,0.5\\
\hline
NG & 1,2 & 1,1 & 1,1.5 \\
\hline
GiN, NGiS & 0.5,1 & 1.5,1 & 1.5,1.5 \\
\hline
\end{array}
$$

This notion of observability crucial here was interpreted by @sugden2006 as focal points being underpinned not by instrumental but *pragmatic rationality* which is induced from its empirical success. Schelling stressed the "perceptual and suggestive element in the formation of mutually consistent expectations" [@schelling1980, 83-84] which is essential for focal points, as the authors note. It means that there are no logical restrictions on converging for expectations between players. @herrmann2022 give a vivid example: 

> "In a signalling game, when a sender sends a signal to her partner, the partner responds to that signal in a specific way. But in the real world, her partner might not know what part of the act the sender performs is meant to be the signal. Suppose she signals by waving a red flag. What is the signal here? Is it the colour? The fact that it is a flag? The pattern in which she waves it? Where she stands when she is waving it?" [@herrmann2022, 2].

To make this problem easier, Sugden and Zamarrón suggest three features of Schelling's focal point analysis: 

- the players' presumption of the solvability of coordination problems, which is based on empirical success of real agents
- players' reasoning in finding focal points is not guided by principles of truth and validity essential for deductive systems
- players reason fully rationally in finding focal points. 

As Schelling wrote: 

> "most situations - perhaps every situation for people who are practiced at this kind of game - provides some clue for coordinating behavior, some focal point for each person's expectation of what the other expects him to expect to be expected to do" [@schelling1980, 57].

The inherent difficulty with formalizing the idea of focal points consists of the "unstructured and unbounded set of possible coordination devices" [@sugden2006, 616], which @herrmann2022 illustrate with their red flag example. It means that any source of focality might present a theory in itself.

The notion of "cognitive selectivity" can bw helpful here. @mussweiler2012 note that cognitive selectivity is an evolved characteristic of human cognitive system that plays a major role in individuals' successful coping with inherently complex tasks like coordination. It is a fundamental mechanism of sense-making and navigating social worlds. 

Selectivity is a feature of social information processing happening on three distinct stages: 

- attention determines what information comes into the cognitive system, 
- then this information is related to the already "stored" one
- and then a behavioral response is produced.

Stimuli requiring instantaneous behavioral response and contextually distinct stimuli tend to become more relevant and attended. And this is fair for both animals and humans.

While epistemic salience has to do with *beliefs*, natural salience has to do with attending to properties of environment and correlating strategies on them. Natural salience does not require any rationality at all, for agents update their behavioral strategies according to a simple rule like reinforcement learning. This presupposes few more deeper problems like how agents stabilize on a certain feature of environment as salient [@herrmann2022] and how they "decide" on who takes a sender or a receiver role [@vandrunen2023]? 

Although these types of salience and game-theoretic machinery behind them might seem unrelated and suited for studying different things, I will argue that they are deeply connected in the context of *evolution* of social conventions: how do we get epistemic salience from natural one. However, to arrive at a notion of *evolution* of social conventions and to be able to ask such questions, we need to frame the previous discussions of conventions within the context of social ontology and its naturalistic strand, in particular, which we will do in the next chapter.

## Interim results 
In this chapter, we discussed the notion of *social convention* in the tradition from Hume to Lewis and modern game theory. We reviewed its intellectual precursors and influences, Lewis's theory, its criticisms, extensions and larger-scope problem which his profound theory has generated: 

- the relationship between norms and conventions and account of emergence of normative behavior [@ullmann-margalit1977, @elster1989, @young1998, @bicchieri2005]
- the continuum between arbitrariness and functionality of conventions and the relationship between human and animal 'conventions' [@oconnor2019; @oconnor2021; @harms2004]
- the notion of common knowledge as a (not always) necessary condition for Lewisian conventions and the problem of agents' cognitive architectures [@cubitt2003, @vanderschraaf2023; @schiffer1972]
- the problem of emergence of readily focal equilibria with epistemic and natural salience [@herrmann2022; @zachnik2021]
- the distinct equilibrium concepts of conventions: ESS and correlated [@skyrms2014;@vanderschraaf1995].

Crucially, these notions contain a subtle distinction between human and non-human conventions, illuminated from different angles. All in all, we can trace two models of rationality: low-demanding and high-demanding. Although there is no inherent problem with this, when game-theoretic thinking with its models is imported to other domains like social ontology, this subtle distinction between low-demanding and high-demanding rationality is often missing and generates controversies with conflation of two rationality models.

In the next chapter, we will put game-theoretic notion of convention into the context of *social ontology*, especially of a naturalistic kind, which is a strand of philosophy studying what there is in the social world. We will look at the standard notions proposed by @searle1995, their refinements with game-theoretic conventions by @guala2015 and arrive at a philosophical problem of evolution of social conventions underpinned by a deeper problem of *ontic reference* or *ontic account of scientific explanation* [@craver2014]. Afterwards, in chapter 3, we will sketch a pathway towards resolving the problem of ontic reference in game-theoretically inspired social ontology by building a model of evolution of human conventions from animal ones.

# Chapter 2. The problem of evolution of conventions in naturalistic social ontology: models and their ontic references

<!--rules-in-equilibria theory of social institutions, which implicitly raises the problem of evolution of social conventions-->

<!--## Social conventions and naturalistic social ontology-->
<!---->
<!--- [[14.1_Standard-Model-of-Social-Ontology]]-->
<!--    - [[14.1a_SMOSO-and-Evo-game-theory-as-two-major-models-of-social-ontology-lack-empirical-foundations]]-->
<!--        - [[14.1a1_Mechanism-of-spreading-of-successful-strategies-is-needed-to-apply-evo-game-theory-to-social-ontology]]-->
<!--            - [[14.1a1a_Individual-level-explanations-of-social-ontology-featuring-cognitive-mechanisms-are-not-exhaustive]]-->
<!--- [[14.2_Social-ontology-should-only-assist-inferences-and-not-claim-what-there-is]]-->
<!--- [[14.3_Social-theory-ought-to-be-physically,-computationally-and-cognitively-realistic]]-->
<!--- [[14.4_Social-structural-relations-are-not-causal,-but-conceptual]]-->

<!--A somewhat surprising extension of Lewis's theory is due to Guala and Hindriks [@guala2015; @hindriks2015] as they expand to the field of social ontology and, what is more, make it ontologically fundamental. They propose that social institutions like money, marriage or others can be seen as (sets of) conventions in Lewisian sense. They employ many arguments from our previous discussions like Aumann/Vanderschraaf *correlated equilibrium*, Skyrms/Maynard-Smith *ESS* and emphasize the role of *normative belief* in a similar to Bicchieri/Gintis manner. As we will pose a problem inside their theory later, it is important to carefully present and unpack it, which I will do in this section.-->
<!--- Exposition of theory's components-->
<!--    - [[11.1b_Guala's-explanatory-components-for-theory-of-institutions.md]]-->
<!--    - [[10.1b1_Correlated-equilibrium-instead-of-Nash-highlights-the-variety-of-coordination-devices.md]]-->
<!--    - [[11.2-Institutions-have-etiological-and-teleological-functions.md]]-->
<!--    - [[11.2a-Institutions-are-there-for-they-incentivise-which-is-due-to-gene-culture-coevolution-and-not-only-natural-selection.md]]-->
<!--    - [[11.2b_Norms-both-make-behaviour-more-stable-and-predictable-and-introduce-new-behaviour-by-changing-game-payoffs.md]]-->
<!--- Criticism-->
<!--    - @hedoin2021-->
<!--- https://www.annalsfondazioneluigieinaudi.it/images/LII/R28201801_E-4284-Tieffenbach_Review.pdf-->
<!--- https://ndpr.nd.edu/reviews/understanding-institutions-the-philosophy-and-science-of-living-together/-->
<!--- Problem with correlation — [[003_correlation_as_core_problem]]-->
<!--- Problem with representation — [[006_problem-with-representation]]-->
<!--- Discussion and interim results-->
<!--    - [[11.3_Stable-and-efficient-social-contracts-evolved-due-to-within-group-AND-between-group-dynamics.md]]-->
<!--    - [[10.1a_hard-to-say-coordination-problems-or-socialization-evolved-first.md]]-->
<!---->
<!--# Chapter 3. Evolution of conventions as a problem of scope of actionable signals-->

<!--```mermaid-->
<!--flowchart LR-->
<!--    A[Minimal Minds] --> B[Developmental Plasticity];-->
<!--    B --> C[Robust Tracking & Representation];-->
<!--    C --> D[Situated Intentionality];-->
<!--    D --> E[Epistemic Agency];-->
<!--```-->
<!--***-->
<!--## 2.X The Evolution of Social Conventions: Bridging Evolutionary and Epistemic Agents through a Naturalistic Framework-->
<!---->
<!--### 1. Introduction-->
<!---->
<!--The evolution of social conventions is a central topic in the philosophy of biology, game theory, and cognitive science. Game theory distinguishes between *evolutionary agents*—whose strategies evolve via selection—and *epistemic agents*—who reason about others and update beliefs. Sterelny’s work on the evolution of agency and niche construction provides a graded, naturalistic account that bridges these types. This subsection synthesizes these perspectives, using formal models and philosophical analysis.-->
<!---->
<!------->
<!---->
<!--### 2. Formal Distinctions: Evolutionary vs. Epistemic Agents-->
<!---->
<!--Game-theoretic modeling distinguishes between two archetypes:-->
<!---->
<!--| Feature                  | Evolutionary Agents | Epistemic Agents |-->
<!--|--------------------------|---------------------|------------------|-->
<!--| Decision Basis           | Replicator dynamics, payoff-based selection | Belief/desire reasoning, Bayesian updating |-->
<!--| Information Use          | Local, stimulus-driven | Representation-rich, theory of mind, common knowledge |-->
<!--| Convention Formation     | ESS, population-level stability | Correlated equilibrium, shared intentionality |-->
<!--| Learning/Adaptation      | Imitation, mutation, reinforcement | Deliberation, belief updating, higher-order reasoning |-->
<!---->
<!--#### Evolutionary Game Theory-->
<!---->
<!--Evolutionary agents, as in Maynard Smith’s models, adapt through population-level selection. The replicator equation describes how the frequency $$ x_i $$ of strategy $$ i $$ changes over time:-->
<!---->
<!--$$-->
<!--\frac{dx_i}{dt} = x_i \left( f_i(\vec{x}) - \bar{f}(\vec{x}) \right)-->
<!--$$-->
<!---->
<!--where $$ f_i(\vec{x}) $$ is the fitness of strategy $$ i $$ and $$ \bar{f}(\vec{x}) $$ is the average fitness (@maynardsmith1982).-->
<!---->
<!--#### Epistemic Game Theory-->
<!---->
<!--Epistemic agents, as in Vanderschraaf and Gintis, reason about others’ beliefs and intentions. Social conventions are supported by *common knowledge* and *shared intentionality*, often formalized by Bayesian updating:-->
<!---->
<!--$$-->
<!--P(H|E) = \frac{P(E|H)P(H)}{P(E)}-->
<!--$$-->
<!---->
<!--where $$ P(H|E) $$ is the posterior probability of hypothesis $$ H $$ given evidence $$ E $$ (@vanderschraaf2009; @gintis2009).-->
<!---->
<!------->
<!---->
<!--### 3. Sterelny’s Gradualist, Naturalistic Account-->
<!---->
<!--Sterelny rejects a sharp dichotomy between evolutionary and epistemic agents, instead positing a graded evolution of agency (@sterelny2012; @sterelny2016):-->
<!---->
<!--#### Developmental Plasticity-->
<!---->
<!--Organisms begin as *minimal minds*—simple, stimulus-bound systems. Through *developmental plasticity*, they gain the capacity to flexibly adjust behavior based on environmental and social cues. This plasticity enables robust, context-sensitive behavior and the emergence of representational capacities.-->
<!---->
<!--#### Niche Construction-->
<!---->
<!--Sterelny emphasizes *niche construction*: organisms modify their environments, which in turn shape selection pressures and learning opportunities. Social conventions are not merely responses to static environments but are co-constructed through feedback between agent behavior and the social/cognitive niche.-->
<!---->
<!--#### Agency as a Spectrum-->
<!---->
<!--Sterelny’s framework can be visualized as a spectrum:-->
<!---->
<!--```mermaid-->
<!--flowchart LR-->
<!--    A[Minimal Minds] --> B[Developmental Plasticity]-->
<!--    B --> C[Robust Tracking & Representation]-->
<!--    C --> D[Situated Intentionality]-->
<!--    D --> E[Epistemic Agency]-->
<!--```-->
<!---->
<!------->
<!---->
<!--### 4. Formal Mechanisms Bridging Evolutionary and Epistemic Models-->
<!---->
<!--#### Plasticity as a Bridge-->
<!---->
<!--Plasticity allows agents to move from rigid evolutionary adaptation to flexible, context-sensitive reasoning. In formal models, learning rules (e.g., reinforcement, imitation) are themselves subject to selection and refinement.-->
<!---->
<!--#### Hybrid Models-->
<!---->
<!--Recent models combine replicator dynamics and Bayesian updating, allowing agents to adapt both through selection and belief revision:-->
<!---->
<!--```mermaid-->
<!--flowchart TD-->
<!--    X[Replicator Dynamics] --> Y[Hybrid Agent]-->
<!--    Z[Bayesian Updating] --> Y-->
<!--    Y --> W[Emergence of Social Conventions]-->
<!--```-->
<!---->
<!--#### Niche Construction Feedback-->
<!---->
<!--Agent actions modify the environment (including social norms), which in turn affect future learning and adaptation—a recursive, co-evolutionary process. This is formalized in models where the fitness landscape is endogenously altered by agent behavior (@sterelny2016).-->
<!---->
<!------->
<!---->
<!--### 5. Contemporary Integrative Approaches-->
<!---->
<!--- **Agent-Based Models:** Simulate heterogeneous populations with varying cognitive and social learning abilities, showing how conventions emerge and stabilize.-->
<!--- **Social Niche Construction:** Models explicitly track how conventions, once established, alter the social environment, creating new affordances and constraints for subsequent generations.-->
<!--- **Hybrid Evolutionary-Epistemic Models:** Blend replicator dynamics with Bayesian updating, capturing the transition from reactive to reflective agency.-->
<!---->
<!------->
<!---->
<!--### 6. Philosophical Synthesis-->
<!---->
<!--A naturalistic philosophy of social conventions, informed by Sterelny, recognizes that agency evolves gradually through increasing plasticity, representational capacity, and social cognition, embedded within dynamic feedback loops between agents and their constructed niches. Formal and computational models increasingly reflect this complexity, moving beyond the dichotomy of evolutionary and epistemic agents.-->
<!---->

<!--### Epistemic salience-->
<!--* [[12.1_cognitive-selectivity-helps-coping-with-social-coordination-by-attention-relation-and-behavior.md]]-->
<!--    * [[12.2_Salience-in-focal-points-is-highly-context-dependent-and-intersubjective.md]]-->
<!--        * [[12.2a_Focal-points-work-because-of-pattern-recognition.md]]-->
<!--        * [[12.2b_Focal-points-are-underpinned-by-pragmatic-rationality.md]]-->
<!--* [[@lacroix2020a]]-->
<!--* [[@zachnik2021]]-->
<!--    * variable frame theory-->
<!--    * cognitive hierarchy theory-->
<!---->
<!--### "Natural" (evolutionary) Salience-->
<!--- Skyrms's elimination of salience with evolutionary dynamics-->
<!--    - [[Symmetry-broken-by-chance-events-leads-to-correlated-equilibrium-in-iterated-Hawk-Dove-game]]-->
<!--    - [[@vandrunen2023]]-->
<!--    - [[@alberti2012]]-->
<!--- https://ar5iv.labs.arxiv.org/html/2307.01158-->
<!--What Does It Mean that Agents Become Informational Environments for Each Other?-->
<!--This idea builds from Skyrms and Sterelny, especially from Sterelny’s emphasis on scaffolding and socially-constructed informational environments.-->
<!---->
<!--Key Concept:-->
<!--In stable interactions, an agent’s behavior itself becomes a reliable source of information for others.-->
<!---->
<!--Example in Our Context:-->
<!--Suppose Agent A emits action A1 when it observes signal S0.-->
<!---->
<!--If Agent B learns this association (even tacitly), it starts interpreting signal S0 partly through the lens of A’s behavior.-->
<!---->
<!--Now, Agent A’s behavior encodes structure about the world and reinforces a coordination loop.-->
<!---->
<!--This is informational niche construction:-->
<!---->
<!--The statistical regularities of social behavior themselves become part of the learnable structure of the environment.-->

<!--Our model builds on Sterelny’s account of developmental plasticity and niche construction to explain how cognitively sophisticated agents can emerge from simple, cue-based learners.-->
<!---->
<!--Sterelny argues that organisms actively reshape their environments in ways that buffer developmental noise and amplify learning opportunities. These "constructed niches" allow later generations to develop more complex cognitive architectures by reducing the cost and increasing the benefit of representational complexity.-->
<!---->
<!--In our simulation:-->
<!---->
<!--Agents begin with simple reinforcement learning.-->
<!---->
<!--Through repeated interactions, they stabilize conventions—coordinated behaviors that simplify the signal-action mapping.-->
<!---->
<!--This stabilization feeds back on the environment: signals become biased, introducing a latent structure that rewards inferential sensitivity.-->
<!---->
<!--Over time, agents that "mutate" into conditional learners can exploit this structure and outperform others.-->
<!---->
<!--Thus, inferential behavior emerges not from an exogenous spark but as a response to increasing informational richness in the niche—a hallmark of Sterelny’s view.-->
<!---->
<!--Complexity in the agent grows because complexity in the environment—socially constructed—is scaffolded first.-->

<!--- Evolution of salience as a problem of correlated conventions -->
<!--    - [[@herrmann2021]], @herrmann2022, @vandrunen2023-->

<!--- [[evolutionary-stable-correlation]]-->
<!--    - <https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0136032>-->
<!--    - <https://www.frontiersin.org/journals/ecology-and-evolution/articles/10.3389/fevo.2023.1229093/full#B24>-->
<!--    - <https://mpra.ub.uni-muenchen.de/16926/>-->
<!--    - <https://philpapers.org/rec/TSACE>-->
<!--    - [[@cripps1991]]-->
<!--    - [[@kim2017]]-->
<!--    - [[@metzger2018]]-->
<!--    - [[@lee-penagos2016]]-->
<!--    - [[@foster1997]]-->
<!--- [[📝-(conf)-Formal-analysis-of-the-'scope-of-actionable-signals'-argument-in-rules-in-equilibria-theory-of-social-institutions]]-->
<!--- [[📝-Emergence-of-norm-driven-coordination-from-basic-signaling-games]]-->
<!--- [[10.2_Sender–reciever-systems-represent-both-within--and-between-organism-coordination.md]]-->
<!--    - [[10.2a_Natural-signs-are-structured-world-affairs-that-convey-information-through-their-structure.md]]-->
<!--- [[005_animal_conventions]]-->
<!--- [[10.1b1_Fitness-is-decoupled-from-utility-due-to-growth-of-social-group-size-and,-as-a-consequence,-weakening-of-individual-level-heritability-of-cultural-traits.md]]-->
<!--- :🔥[[@lacroix2020a]]-->

<!--# Conclusion: Implications for social ontology and sociological theory-->
<!--- [disser_test](/blog/disser_test)-->

# References
<!--- There are many equilibrium-based theories in the social science literature, stemming from Lewis's (1969} seminal work on conventions. See, for example, Schotter (1981}, Calvert (1998}, Grief (2006}, Binmore (2010}. The account presented here is close in spirit to Aoki's (2001, 2011} and Grief and Kingston's (2011} "hybrid" theories. The use of the hawk-dove game to represent animal and human conflicts over contested resources goes back to Maynard Smith's (1982} work on evolutionary game theory. See also Sugden (1986} and more recently Gintis (2007}. On correlated equilibria see Aumann (1974, 1987}, as well as Vanderschraaf (1995, 1998, 2001} and Gintis (2007, 2009}. The theory of institutions as rules in equilibrium has been discussed in a symposium recently published in the Journal of Institutional Economics. The commentaries of Aoki (2015}, Binmore (2015}, Sugden (2015}, and Smith (2015}, in particular, address some of the issues discussed in this chapter. Hindriks and Guala (2015b} — location: []() ^ref-37783-->

<!--Bicchieri (2001) discusses in depth the problem of belief formation in coordination games. The idea that society is a gigantic coordination game and that social institutions help people find a solution is already in Hume (1748}, but has been reformulated in gametheoretic fashion by philosophers and social scientists like Lewis (1969}, Ullmann-Margalit (1977}, Schotter (1981}, Sugden (1986}, Skyrms (1996, 2004}, Binmore (1998, 2005}. Knight (1992} discusses the coordinating function of institutions, as well as the competitive aspect of games such as battle of the sexes. The puzzle of cooperation in prisoner's dilemma experiments has generated an enormous literature, but explanations based on social norms are quite common-see for instance UllmannMargalit (1977}, Sober and Wilson (1998}, Binmore (2005}, Bicchieri (2006}, Gintis (2009}. Functional explanations have suffered from a bad press in social science as a consequence of Jon Elster's (1983} influential critique. Pettit's (1996} distinction between explanations of emergence and explanations of resilience is meant to resist this critique. On equilibrium explanations, finally, see Sober (1983 -->

<!--**Core Components & Key Features:**-->
<!---->
<!--1. **Population Dynamics:** EGT models are typically framed as populations of individuals, each playing a specific strategy. The population’s composition changes over time according to a defined selection rule – most commonly, *replicator selection*, where strategies with higher average payoffs in a given environment become more prevalent in the population.-->
<!---->
<!--2. **Payoff Matrices & Fitness:** Strategies are represented by payoff matrices, analogous to those in standard game theory. However, instead of representing a single player’s payoff, the matrix represents the *fitness* of a strategy given the strategies employed by the entire population. Fitness is often interpreted as the average reproductive success or survival rate associated with that strategy.-->
<!---->
<!--3. **Replicator Dynamics:** The core of EGT is the replicator equation, which describes how the frequency of each strategy in the population changes over time. This equation is based on the idea that strategies with higher fitness will, on average, produce more offspring, leading to an increase in their proportion within the population. -->
<!---->
<!--4. **Multiple Equilibria:** A crucial characteristic of EGT is the potential for multiple evolutionary stable strategies (ESS). An ESS is a strategy that, if adopted by a majority of the population, cannot be invaded by any other strategy. This contrasts with the single Nash equilibrium often found in traditional game theory.-->
<!---->
<!--5. **Beyond Rationality:** EGT acknowledges that agents are not necessarily perfectly rational. Instead, it focuses on the *evolutionary* consequences of strategic interactions, recognizing that strategies can emerge and persist through selection pressures, even if they are not individually optimal.-->
<!---->
<!--**Distinction from Traditional Game Theory:**-->
<!---->
<!--| Feature           | Traditional Game Theory | Evolutionary Game Theory |-->
<!--|--------------------|--------------------------|--------------------------|-->
<!--| **Agent Assumption** | Rational, self-interested | Subject to evolutionary selection |-->
<!--| **Focus**          | Static equilibrium        | Dynamic population change |-->
<!--| **Selection**      | Not explicitly modeled    | Central to the model      |-->
<!--| **Equilibria**     | Single Nash equilibrium    | Multiple ESS possible      |-->
<!---->
<!---->
<!---->
<!--**Applications:**-->
<!---->
<!--EGT has been applied to a wide range of phenomena, including:-->
<!---->
<!--*   Animal behavior (e.g., cooperation in social insects, mate choice)-->
<!--*   Economic phenomena (e.g., market competition, innovation)-->
<!--*   Social science (e.g., voting behavior, cultural evolution)-->
<!---->
<!---->
<!---->
<!--**References (for further reading - this is a starting point):**-->
<!---->
<!--*   Nowak, Ronald A., and John E. Smith. "Evolutionary Dynamics: Algorithms, Models, and Applications." *Princeton University Press*, 2007.-->
<!--*   Segal, David. *Evolutionary Game Theory*. *Cambridge University Press*, 2001.-->
<!---->
 <!--@sugden1995 emphasized the critical function of context-specific salience in establishing common knowledge and resolving coordination problems. Salience, stemming from shared community membership and cultural context, operates as a *correlating device*. It correlates expectations of agents regarding each other's next actions and helps to choose an optimal strategy. Salience enables agents to achieve a common understanding and coordinate actions toward a specific equilibrium. In situations with multiple equilibria, salience provides a focal point, influencing individual attention and expectations, thereby disrupting symmetry and facilitating coordination – as exemplified in Schelling’s coordination games where individuals converge on the most intuitively salient option. Crucially, Sugden argued that common understanding, built upon shared modes of reasoning within a community, is constitutive of salience. Shared cultural backgrounds, experiences, and cognitive frameworks among community members influence what is perceived as salient, allowing individuals to anticipate and coordinate with others’ expectations.-->

<!--## Salience, epistemic and "natural"-->
<!---->
<!--## Arbitrariness and normativity-->
<!--* Convention space: mapping conventions theories across two dimensions ↓-->
<!--* [When and why Conventions cannot Be Social Institutions | Philosophia](https://link.springer.com/article/10.1007/s11406-019-00125-0) — 5 dimensions of conventions-->
<!---->
<!---->
<!--### Functionality vs. arbitrariness: "choosing" conventions-->
<!--* [CEEOL - Article Detail](https://www.ceeol.com/search/article-detail?id=694410)-->
<!--* [CEEOL - Article Detail](https://www.ceeol.com/search/article-detail?id=1007657)-->
<!---->
<!--## Evolution of social conventions-->
<!--Skyrms pioneered a path towards dynamic evolutionary models of coordination and convention-->
<!---->
<!--- 🔥 @lutz2023-->
<!---->
<!--- gintis's view of social norms as correlation + ess-->
<!--    - [[private-property-equilibrium-generalizes-Bourgeois-equilibrium-by-endogenizing-costs]]-->
<!--- Guala's social institutions as evolved normatively-driven conventions-->
<!--    - [[11.1-Institutions-are-rules-in-equilibria-represented-symbolically-by-theoretical-terms.md]]-->
<!--        - [[11.1a_Normative-rules-can-transform-cooperation-problem-into-coordination-problem-by-increasing-delta-parameter.md]]-->
<!--            - [[11.1a1_Norm-triggering-signals-(cues)-might-differ-in-distinct-cultures.md]]-->
<!--            - [[11.1a2_Social-norms-might-be-supported-by-a-variety-of-different-mechanisms.md]]-->
<!--- the problem: 🔥 [[10.1b_Human-and-animal-conventions-differ-in-scope-of-actionable-signals.md]]-->
<!--- Naturalization of social conventions: connecting evolution and deliberation-->
<!---->
